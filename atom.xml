<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Eoccc的博客</title>
  
  
  <link href="https://eoccc.gitee.io/atom.xml" rel="self"/>
  
  <link href="https://eoccc.gitee.io/"/>
  <updated>2023-07-26T12:50:11.235Z</updated>
  <id>https://eoccc.gitee.io/</id>
  
  <author>
    <name>Eoccc</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Orika复制对象失败</title>
    <link href="https://eoccc.gitee.io/2023/07/24/Orika%E5%A4%8D%E5%88%B6%E5%AF%B9%E8%B1%A1%E5%A4%B1%E8%B4%A5/"/>
    <id>https://eoccc.gitee.io/2023/07/24/Orika%E5%A4%8D%E5%88%B6%E5%AF%B9%E8%B1%A1%E5%A4%B1%E8%B4%A5/</id>
    <published>2023-07-24T07:25:19.000Z</published>
    <updated>2023-07-26T12:50:11.235Z</updated>
    
    <content type="html"><![CDATA[<p>分析了一个Orika框架拷贝对象失败的场景。</p><span id="more"></span><h1 id="使用方式"><a class="markdownIt-Anchor" href="#使用方式"></a> 使用方式</h1><p>Orika通过映射来实现对象拷贝，在创建新对象的时候，支持通过set方法和反射的方式来设置属性的值。</p><p>使用方式：</p><ol><li><p>创建一个 <code>MapperFacade</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">MapperFactory</span> <span class="variable">mapperFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMapperFactory</span>.Builder().build();</span><br><span class="line"><span class="type">MapperFacade</span> <span class="variable">mapperFacade</span> <span class="operator">=</span> mapperFactory.getMapperFacade();</span><br></pre></td></tr></table></figure></li><li><p>使用该<code>MapperFacade</code>对象进行任意的Bean转换</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 我们默认使用这种方式，复制所有能够映射成功的属性</span></span><br><span class="line"><span class="type">ThisObject</span> <span class="variable">oldObj</span> <span class="operator">=</span> getObj();</span><br><span class="line"><span class="type">ThisObject</span> <span class="variable">newObj</span> <span class="operator">=</span> mapperFacade.map(oldObj, ThisObject.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 也可以映射成另一个对象</span></span><br><span class="line"><span class="type">ThatObject</span> <span class="variable">thatObj</span> <span class="operator">=</span> mapperFacade.map(oldObj, ThatObject.class);</span><br></pre></td></tr></table></figure></li><li><p>可以自定义映射规则</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mapperFactory.classMap(ThisObject.class, ThatObject.class)</span><br><span class="line">  .field(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;fullName&quot;</span>)</span><br><span class="line">  .field(<span class="string">&quot;age&quot;</span>, <span class="string">&quot;currentAge&quot;</span>)</span><br><span class="line">  .exclude(<span class="string">&quot;secretKey&quot;</span>)</span><br><span class="line">  .byDefault()</span><br><span class="line">  .register();</span><br></pre></td></tr></table></figure></li><li><p>可以指定使用特定的构造函数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 生成B对象时，优先使用包含id和name参数的构造函数</span></span><br><span class="line">mapperFactory.classMap(ThisObject.class, ThatObject.class)</span><br><span class="line">  .constructorB(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;name&quot;</span>)</span><br><span class="line">  .register();</span><br></pre></td></tr></table></figure></li><li><p>数组和字段的映射</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mapperFactory.classMap(ThisObject.class, ThatObject.class)</span><br><span class="line">  .field(<span class="string">&quot;nameParts[0]&quot;</span>, <span class="string">&quot;firstName&quot;</span>)</span><br><span class="line">  .field(<span class="string">&quot;nameParts[1]&quot;</span>, <span class="string">&quot;lastName&quot;</span>)</span><br><span class="line">  .register(); </span><br></pre></td></tr></table></figure></li><li><p>嵌套字段映射</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mapperFactory.classMap(ThisObject.class, ThatObject.class) </span><br><span class="line">  .field(<span class="string">&quot;name.first&quot;</span>, <span class="string">&quot;firstName&quot;</span>)</span><br><span class="line">  .register();</span><br></pre></td></tr></table></figure></li><li><p>自定义转换器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mapperFactory.getConverterFactory().registerConverter(<span class="keyword">new</span> <span class="title class_">CustomConverter</span>&lt;ThisObject, ThatObject&gt;() &#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Money <span class="title function_">convert</span><span class="params">(ThisObject source, Type&lt;? extends ThatObject&gt; destinationType, MappingContext mappingContext)</span> &#123;</span><br><span class="line">          <span class="keyword">return</span> ThatObject.of(source.getName());</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure></li></ol><p>更多用法：<a href="https://juejin.cn/post/7032886752528302087">https://juejin.cn/post/7032886752528302087</a></p><h1 id="复制失败的原因"><a class="markdownIt-Anchor" href="#复制失败的原因"></a> 复制失败的原因</h1><p>我们需要被复制的对象：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">Money</span> <span class="keyword">implements</span> <span class="title class_">Comparable</span>&lt;Money&gt;, Serializable &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> BigDecimal amount;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="title function_">Money</span><span class="params">()</span> &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再看下BigDecimal的源码（只看关键属性就行了）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BigDecimal</span> <span class="keyword">extends</span> <span class="title class_">Number</span> <span class="keyword">implements</span> <span class="title class_">Comparable</span>&lt;BigDecimal&gt; &#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> BigInteger intVal;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> scale;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>**现象：**我们使用<code>mapperFacade.map</code>复制之后，生成了一个新的Money对象，但是内部的amount字段没有成功复制。</p><p><strong>原因：</strong></p><blockquote><ol><li>BigDecimal没有提供无参构造方法</li><li>BigDecimal是不可修改的（因为BigDecimal的每个属性都被final修饰）</li></ol></blockquote><p>解决方式：针对不能复制的类型，自定义一个转换器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">MapperFactory</span> <span class="variable">mapperFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMapperFactory</span>.Builder().build();</span><br><span class="line">mapperFactory.getConverterFactory().registerConverter(<span class="keyword">new</span> <span class="title class_">CustomConverter</span>&lt;Money, Money&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Money <span class="title function_">convert</span><span class="params">(Money source, Type&lt;? extends Money&gt; destinationType, MappingContext mappingContext)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Money.of(source.getAmount());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="type">MapperFacade</span> <span class="variable">mapperFacade</span> <span class="operator">=</span> mapperFactory.getMapperFacade();</span><br><span class="line"></span><br><span class="line"><span class="type">Money</span> <span class="variable">copied</span> <span class="operator">=</span> mapperFacade.map(sourceMoney, Money.class);</span><br></pre></td></tr></table></figure><p><code>ma.glasnost.orika.metadata.Type#IMMUTABLE_TYPES</code>维护了一个列表，保存了不可修改的类型，包括：</p><table><thead><tr><th>基本数据类型</th><th>基本数据的包装类型</th><th>jdk6中的不可变数据结构</th><th>jdk8中的不可变数据结构</th></tr></thead><tbody><tr><td>byte</td><td>class java.lang.Byte</td><td>class java.net.URI</td><td>class java.time.chrono.MinguoDate</td></tr><tr><td>char</td><td>class java.lang.Boolean</td><td>class java.util.Currency</td><td>class java.time.LocalDate</td></tr><tr><td>int</td><td>class java.lang.Character</td><td>class java.lang.String</td><td>class java.time.MonthDay</td></tr><tr><td>double</td><td>class java.lang.Double</td><td>class java.util.UUID</td><td>class java.time.YearMonth</td></tr><tr><td>boolean</td><td>class java.lang.Float</td><td>class java.net.URL</td><td>class java.time.Duration</td></tr><tr><td>short</td><td>class java.lang.Short</td><td>class java.net.Inet4Address</td><td>class java.time.Period</td></tr><tr><td>float</td><td>class java.lang.Long</td><td>class java.net.Inet6Address</td><td>class java.time.LocalDateTime</td></tr><tr><td>long</td><td>class java.lang.Integer</td><td>class java.math.BigDecimal</td><td>class java.time.ZonedDateTime</td></tr><tr><td></td><td></td><td>class java.math.BigInteger</td><td>class java.time.Year</td></tr><tr><td></td><td></td><td>class java.util.Locale</td><td>class java.time.OffsetDateTime</td></tr><tr><td></td><td></td><td>class java.io.File</td><td>class java.time.chrono.JapaneseEra</td></tr><tr><td></td><td></td><td>class java.net.InetSocketAddress</td><td>class java.time.LocalTime</td></tr><tr><td></td><td></td><td></td><td>class java.time.chrono.ThaiBuddhistDate</td></tr><tr><td></td><td></td><td></td><td>class java.time.Instant</td></tr><tr><td></td><td></td><td></td><td>class java.time.chrono.HijrahDate</td></tr><tr><td></td><td></td><td></td><td>class java.time.OffsetTime</td></tr><tr><td></td><td></td><td></td><td>class java.time.ZoneOffset</td></tr><tr><td></td><td></td><td></td><td>class java.time.chrono.JapaneseDate</td></tr></tbody></table><h1 id="源码分析"><a class="markdownIt-Anchor" href="#源码分析"></a> 源码分析</h1><p>映射的核心方法：<code>MapperFacade#map</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;S, D&gt; D <span class="title function_">map</span><span class="params">(<span class="keyword">final</span> S sourceObject, <span class="keyword">final</span> Class&lt;D&gt; destinationClass, <span class="keyword">final</span> MappingContext context)</span> &#123;</span><br><span class="line">  <span class="type">MappingStrategy</span> <span class="variable">strategy</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (destinationClass == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">MappingException</span>(<span class="string">&quot;&#x27;destinationClass&#x27; is required&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (sourceObject == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 先看看缓存中是否已经存在映射过的对象，有的话直接从缓存中取</span></span><br><span class="line">  <span class="type">D</span> <span class="variable">result</span> <span class="operator">=</span> context.getMappedObject(sourceObject, TypeFactory.valueOf(destinationClass));</span><br><span class="line">  <span class="keyword">if</span> (result == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="comment">// 核心1，获取映射策略，这里会生成映射的关系</span></span><br><span class="line">    strategy = resolveMappingStrategy(sourceObject, <span class="literal">null</span>, destinationClass, <span class="literal">false</span>, context);</span><br><span class="line">    <span class="comment">// 核心2，进行对象映射</span></span><br><span class="line">    result = (D) strategy.map(sourceObject, <span class="literal">null</span>, context);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>先看下获取映射策略：<code>MapperFacadeImpl#resolveMappingStrategy</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;S, D&gt; MappingStrategy <span class="title function_">resolveMappingStrategy</span><span class="params">(<span class="keyword">final</span> S sourceObject, <span class="keyword">final</span> java.lang.reflect.Type initialSourceType,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> java.lang.reflect.Type initialDestinationType, <span class="keyword">final</span> <span class="type">boolean</span> mapInPlace, <span class="keyword">final</span> MappingContext context)</span> &#123;</span><br><span class="line"><span class="comment">// 如果缓存中已经有了，直接用</span></span><br><span class="line">  <span class="type">Key</span> <span class="variable">key</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Key</span>(getClass(sourceObject), initialSourceType, initialDestinationType, mapInPlace);</span><br><span class="line">  <span class="type">MappingStrategy</span> <span class="variable">strategy</span> <span class="operator">=</span> strategyCache.get(key);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (strategy == <span class="literal">null</span>) &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 生成映射关系，mapper</span></span><br><span class="line">    strategyRecorder.setResolvedMapper(resolveMapper(resolvedSourceType, resolvedDestinationType, context));</span><br><span class="line">...</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Set the resolved types on the current mapping context; this can be</span></span><br><span class="line"><span class="comment">   * used by downstream Mappers to determine the originally resolved types</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  context.setResolvedSourceType(strategy.getAType());</span><br><span class="line">  context.setResolvedDestinationType(strategy.getBType());</span><br><span class="line">  context.setResolvedStrategy(strategy);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> strategy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>解析mapper：<code>MapperFacadeImpl#resolveMapper</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Mapper&lt;Object, Object&gt; <span class="title function_">resolveMapper</span><span class="params">(<span class="keyword">final</span> Type&lt;?&gt; sourceType, <span class="keyword">final</span> Type&lt;?&gt; destinationType, <span class="keyword">final</span> MappingContext context)</span> &#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="type">MapperKey</span> <span class="variable">mapperKey</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MapperKey</span>(sourceType, destinationType);</span><br><span class="line">  <span class="comment">// 查找映射关系</span></span><br><span class="line">  Mapper&lt;Object, Object&gt; mapper = mapperFactory.lookupMapper(mapperKey, context);</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">return</span> mapper;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查找映射关系：<code>DefaultMapperFactory#lookupMapper</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Mapper&lt;Object, Object&gt; <span class="title function_">lookupMapper</span><span class="params">(MapperKey mapperKey, MappingContext context)</span> &#123;</span><br><span class="line">  <span class="comment">// 如果缓存里面有，直接用</span></span><br><span class="line">  Mapper&lt;?, ?&gt; mapper = getRegisteredMapper(mapperKey.getAType(), mapperKey.getBType(), <span class="literal">false</span>);</span><br><span class="line">  <span class="keyword">if</span> (internalMapperMustBeGenerated(mapper, mapperKey)) &#123;</span><br><span class="line">    <span class="comment">// 如果必须创建一个新的，设置为null</span></span><br><span class="line">    mapper = <span class="literal">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 如果缓存中没有获取到mapper，新创建一个</span></span><br><span class="line">  <span class="keyword">if</span> (mapper == <span class="literal">null</span> &amp;&amp; useAutoMapping) &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 加锁，这块逻辑比较消耗性能，避免重复创建映射关系</span></span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="built_in">this</span>) &#123;</span><br><span class="line">      <span class="comment">// 创建mapper</span></span><br><span class="line">      mapper = buildMapper(classMap, <span class="literal">true</span>, context);</span><br><span class="line">      initializeUsedMappers(mapper, classMap, context);</span><br><span class="line">     ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> (Mapper&lt;Object, Object&gt;) mapper;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建mapper：<code>DefaultMapperFactory#buildMapper</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> GeneratedMapperBase <span class="title function_">buildMapper</span><span class="params">(ClassMap&lt;?, ?&gt; classMap, <span class="type">boolean</span> isAutoGenerated, MappingContext context)</span> &#123;</span><br><span class="line">...</span><br><span class="line">  <span class="comment">// 使用mapper生成器，生成mapper</span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">GeneratedMapperBase</span> <span class="variable">mapper</span> <span class="operator">=</span> mapperGenerator.build(classMap, context);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 放到缓存中，可重复使用</span></span><br><span class="line">  classMapRegistry.put(mapperKey, (ClassMap&lt;Object, Object&gt;) classMap);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> mapper;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成mapper：<code>MapperGenerator#build</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> GeneratedMapperBase <span class="title function_">build</span><span class="params">(ClassMap&lt;?, ?&gt; classMap, MappingContext context)</span> &#123;</span><br><span class="line"><span class="comment">// 对属性生成映射关系</span></span><br><span class="line">  mappedFields.addAll(addMapMethod(mapperCode, <span class="literal">true</span>, classMap, logDetails));</span><br><span class="line">  mappedFields.addAll(addMapMethod(mapperCode, <span class="literal">false</span>, classMap, logDetails));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查找映射关系：<code>MapperGenerator#addMapMethod</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Set&lt;FieldMap&gt; <span class="title function_">addMapMethod</span><span class="params">(SourceCodeContext code, <span class="type">boolean</span> aToB, ClassMap&lt;?, ?&gt; classMap, StringBuilder logDetails)</span> &#123;</span><br><span class="line">  Set&lt;FieldMap&gt; mappedFields = <span class="keyword">new</span> <span class="title class_">LinkedHashSet</span>&lt;FieldMap&gt;();</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 创建变量ref</span></span><br><span class="line">  VariableRef source;</span><br><span class="line">  VariableRef destination;</span><br><span class="line">  <span class="keyword">if</span> (aToB) &#123;</span><br><span class="line">      source = <span class="keyword">new</span> <span class="title class_">VariableRef</span>(classMap.getAType(), <span class="string">&quot;source&quot;</span>);</span><br><span class="line">      destination = <span class="keyword">new</span> <span class="title class_">VariableRef</span>(classMap.getBType(), <span class="string">&quot;destination&quot;</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      source = <span class="keyword">new</span> <span class="title class_">VariableRef</span>(classMap.getBType(), <span class="string">&quot;source&quot;</span>);</span><br><span class="line">      destination = <span class="keyword">new</span> <span class="title class_">VariableRef</span>(classMap.getAType(), <span class="string">&quot;destination&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 遍历每个属性</span></span><br><span class="line">  <span class="keyword">for</span> (FieldMap currentFieldMap : classMap.getFieldsMapping()) &#123;</span><br><span class="line"><span class="comment">// 是否需要排除（根据配置）</span></span><br><span class="line">    <span class="keyword">if</span> (currentFieldMap.isExcluded()) &#123;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这个属性已经创建过映射关系了</span></span><br><span class="line">    <span class="keyword">if</span> (isAlreadyExistsInUsedMappers(currentFieldMap, classMap)) &#123;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">FieldMap</span> <span class="variable">fieldMap</span> <span class="operator">=</span> currentFieldMap;</span><br><span class="line">    <span class="keyword">if</span> (!aToB) &#123;</span><br><span class="line">        fieldMap = fieldMap.flip();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 是否忽略字段</span></span><br><span class="line">    <span class="keyword">if</span> (!fieldMap.isIgnored()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (code.aggregateSpecsApply(fieldMap)) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      ...</span><br><span class="line">      mappedFields.add(currentFieldMap);</span><br><span class="line">      <span class="comment">// 处理一下属性的读写权限</span></span><br><span class="line">      <span class="type">String</span> <span class="variable">sourceCode</span> <span class="operator">=</span> generateFieldMapCode(code, fieldMap, classMap, destination, logDetails);</span><br><span class="line">      ...</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (logDetails != <span class="literal">null</span>) &#123;</span><br><span class="line">        code.debugField(fieldMap, <span class="string">&quot;ignored for this mapping direction&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> mappedFields;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>处理变量的访问权限：<code>MapperGenerator#addMapMethod</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> String <span class="title function_">generateFieldMapCode</span><span class="params">(SourceCodeContext code,</span></span><br><span class="line"><span class="params">                                    FieldMap fieldMap,</span></span><br><span class="line"><span class="params">                                    ClassMap&lt;?, ?&gt; classMap,</span></span><br><span class="line"><span class="params">                                    VariableRef destination,</span></span><br><span class="line"><span class="params">                                    StringBuilder logDetails)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    </span><br><span class="line">  <span class="keyword">final</span> <span class="type">VariableRef</span> <span class="variable">sourceProperty</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">VariableRef</span>(fieldMap.getSource(), <span class="string">&quot;source&quot;</span>);</span><br><span class="line">  <span class="keyword">final</span> <span class="type">VariableRef</span> <span class="variable">destinationProperty</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">VariableRef</span>(fieldMap.getDestination(), <span class="string">&quot;destination&quot;</span>);</span><br><span class="line">  destinationProperty.setOwner(destination);</span><br><span class="line"></span><br><span class="line"><span class="comment">// source不可读，直接返回</span></span><br><span class="line">  <span class="comment">// destination没有set方法，并且不能修改，直接返回</span></span><br><span class="line">  <span class="keyword">if</span> (!sourceProperty.isReadable() </span><br><span class="line">      || ((!destinationProperty.isAssignable()) &amp;&amp; destinationProperty.type().isImmutable())) &#123;</span><br><span class="line">      <span class="keyword">if</span> (logDetails != <span class="literal">null</span>) &#123;</span><br><span class="line">          code.debugField(fieldMap, <span class="string">&quot;excluding because &quot;</span>);</span><br><span class="line">          <span class="keyword">if</span> (!sourceProperty.isReadable()) &#123;</span><br><span class="line">              Type&lt;?&gt; sourceType = classMap.getAType().equals(destination.type()) ? classMap.getBType() : classMap.getAType();</span><br><span class="line">              logDetails.append(sourceType + <span class="string">&quot;.&quot;</span> + fieldMap.getSource().getName() + <span class="string">&quot;(&quot;</span> + fieldMap.getSource().getType()</span><br><span class="line">                      + <span class="string">&quot;) is not readable&quot;</span>);</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              logDetails.append(destination.type() + <span class="string">&quot;.&quot;</span> + fieldMap.getDestination().getName() + <span class="string">&quot;(&quot;</span></span><br><span class="line">                      + fieldMap.getDestination().getType() + <span class="string">&quot;) is not assignable and cannot be mapped in-place&quot;</span>);</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Make sure the source and destination types are accessible to the builder</span></span><br><span class="line">  compilerStrategy.assureTypeIsAccessible(sourceProperty.rawType());</span><br><span class="line">  compilerStrategy.assureTypeIsAccessible(destinationProperty.rawType());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> code.mapFields(fieldMap, sourceProperty, destinationProperty);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里就可以知道了，如果一个属性没有set方法，并且这个属性是不可变的，那么就不能被复制。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;分析了一个Orika框架拷贝对象失败的场景。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>redis学习10-集群</title>
    <link href="https://eoccc.gitee.io/2023/07/12/redis%E5%AD%A6%E4%B9%A010-%E9%9B%86%E7%BE%A4/"/>
    <id>https://eoccc.gitee.io/2023/07/12/redis%E5%AD%A6%E4%B9%A010-%E9%9B%86%E7%BE%A4/</id>
    <published>2023-07-12T07:10:35.000Z</published>
    <updated>2023-07-26T08:24:18.402Z</updated>
    
    <content type="html"><![CDATA[<p>Redis集群会将数据库分为16384个槽（slot），集群中的每个节点可以处理0～16384个槽，redis的每个键只会落在其中的一个槽中。当数据库中的每个槽都有redis节点处理的时候，集群才会处于可用状态。</p><span id="more"></span><p>Reids可以用以下命令让一个节点负责处理第0～5000个槽：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLUSTER ADDSLOT 0 1 2 3 ... 5000</span><br></pre></td></tr></table></figure><p>同时，节点会将自己负责处理的槽的信息发送给集群中的其他服务器，集群中的每个节点都知道每个槽是由哪个节点负责。</p><h2 id="执行命令"><a class="markdownIt-Anchor" href="#执行命令"></a> 执行命令</h2><p>Redis中的16384个槽都分配到redis节点处理后，集群就会进入上线状态，开始接收客户端的命令。当集群服务器收到有关数据库的命令后，不会立即开始处理，而是会先计算出命令中的键是处于哪个槽，然后进行分派：</p><blockquote><ul><li><p>如果键所在的槽由自己负责，则开始处理命令</p></li><li><p>如果键所在的槽不是由自己负责，则会向客户端回复一个<code>MOVED</code>命令，指引客户端转向正确的节点，并重新发送命令。（集群模式的客户端收到<code>MOVED</code>命令不会打印错误，只会转向正确的节点，然后打印转向信息）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MOVED &lt;slot&gt; &lt;ip&gt;:&lt;port&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/pCJ2LVQ2h.jpeg" alt="img/pCJ2LVQ2h.jpeg" style="zoom:60%;"><p>Redis使用<code>CRC-16</code>算法对key进行散列：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crc16(key) % 16384</span><br></pre></td></tr></table></figure><p>使用以下命令，可以计算cluster会将key散列到哪个slot中去：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLUSTER KEYSLOT myKey</span><br></pre></td></tr></table></figure><h2 id="重新分片"><a class="markdownIt-Anchor" href="#重新分片"></a> 重新分片</h2><p>Redis集群可以把任意数量已指派给某一节点的槽指派给另一个节点，并且这些槽相关的键也会移到新的节点上。这个操作可以在线进行，并且在重新分片过程中，源节点和目标节点都可以执行命令。</p><h3 id="迁移过程"><a class="markdownIt-Anchor" href="#迁移过程"></a> 迁移过程</h3><p>重新分片由redis集群管理软件<strong>redis-trib</strong>负责操作，单个slot的迁移分为几个步骤：</p><blockquote><ol><li>向目标节点发送<code>CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_id&gt;</code>命令，让目标节点准备好导入新的槽</li><li>向源节点发送<code>CLUSTER SETSLOT &lt;slot&gt; MAGRATING &lt;target_id&gt;</code>命令，让源节点准备好迁移槽</li><li>向源节点发送<code>CLUSTER  GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;</code>命令，获得最多count个属于slot的键</li><li>根据3步骤中获得的键，向源节点发送<code>MIGRATE &lt;target_ip&gt; &lt;target_port&gt; &lt;key_name&gt; 0 &lt;timeout&gt;</code>命令，将键key_name迁移到目标节点</li><li>重复3、4步骤，将属于slot槽的所有键迁移到新节点</li><li>向集群中的任一节点发送<code>CLUSTER SETSLOT &lt;slot&gt; NODE &lt;target_id&gt;</code>命令，将slot槽指派给目标节点，这一指派信息会通过消息发送至集群中的每一个节点</li><li>集群中的节点收到新的指派消息后，更新分片信息</li></ol></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20220501192528800.png" style="zoom:60%;"><h3 id="迁移过程中访问键ask"><a class="markdownIt-Anchor" href="#迁移过程中访问键ask"></a> 迁移过程中访问键（ASK）</h3><p>在迁移过程中，如果客户端向源节点发送一个与数据库有关的命令，而且命令中的键正好在迁移的slot中时：</p><blockquote><ol><li>源节点会在自己的数据库中查找命令中的键，如果找到，执行命令</li><li>如果在源节点的数据库中没有找到命令中的键，说明这个键已经迁移到目标节点，这时源节点会回复一个<code>ASK</code>错误，指引客户端将命令发送给目标节点（客户端会忽略异常信息，只执行转向操作）</li></ol></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20220501193151480.png" style="zoom:60%;"><p>客户端收到<code>ASK</code>错误后，会执行<code>ASKING</code>命令，打开客户端中的<code>REDIS_ASKING</code>标识，然后将新的命令发送给<code>ASK</code>错误信息中的目标节点。如果<code>REDIS_ASKING</code>标识没有打开，目标节点会拒绝执行命令，并且返回一个<code>MOVED</code>错误。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20220501193815198.png" style="zoom:60%;"><h2 id="复制与故障转移"><a class="markdownIt-Anchor" href="#复制与故障转移"></a> 复制与故障转移</h2><p>集群中的主节点负责处理槽，从节点复制主节点。当某个主节点下线时，从其从节点中选择一个成为新的主节点，代替主节点接收并处理客户端命令。</p><p>通过以下命令，让一个节点成为主节点的从节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLUSTER REPLICATE &lt;node_id&gt;</span><br></pre></td></tr></table></figure><h3 id="故障检测"><a class="markdownIt-Anchor" href="#故障检测"></a> 故障检测</h3><p>集群中的每个节点都会定期地向其他节点发送<code>PING</code>命令，检测其他节点是否存活。如果某个节点在指定的时间没没有返回<code>PONG</code>消息，则会认为这个服务器<strong>疑似下线</strong>，然后这个服务器会询问其他<font color="red">主节点</font>是否支持目标服务器下线，当收到半数以上的赞成票时，就会将目标服务器标记为<strong>已下线</strong>，然后会向集群广播一条这个主节点下线的消息。</p><h3 id="故障转移"><a class="markdownIt-Anchor" href="#故障转移"></a> 故障转移</h3><p>当一个<font color="red">从节点</font>发现自己的主节点下线时，将开始故障转移，从其从节点中选择一个节点成为新的主节点：</p><blockquote><ol><li>在从节点中选择一个节点成为主节点</li><li>被选中的节点执行<code>SLAVEOF no one</code>命令，成为主节点</li><li>新的主节点撤销旧的主节点的所有槽指派，并将这些槽指派给自己</li><li>新主节点在集群中广播一条<code>PONE</code>消息，让集群中的其他节点知道自己成为了新的主节点，并已接管了下线节点的槽</li><li>新主节点开始接收和处理请求</li></ol></blockquote><h3 id="选举新的主节点"><a class="markdownIt-Anchor" href="#选举新的主节点"></a> 选举新的主节点</h3><p>当发现某个服务器客观下线，就会开始故障转移，故障转移时要先选择一个新的主节点。选举的方式和Sentinel相似：</p><blockquote><ol><li>集群的纪元自增1</li><li>在一个纪元中，集群中的每个<font color="red">主节点</font>有一次投票机会</li><li>当从节点发现自己的主节点下线时，会向集群广播一条消息，并要求有投票权的<strong>主节点</strong>给自己投票</li><li>如果一个主节点有投票权，且在这个纪元中没有将票投给其他节点，会将票投给第一个请求投票的从节点（先到先得）</li><li>当一个从节点获得的票数过半时，当选成新的主节点</li><li>如果在一个纪元里，没有选举出新的主节点，会进入一个新的纪元（纪元加1），重新开始投票，直到选出新主节点</li></ol></blockquote><p>O</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Redis集群会将数据库分为16384个槽（slot），集群中的每个节点可以处理0～16384个槽，redis的每个键只会落在其中的一个槽中。当数据库中的每个槽都有redis节点处理的时候，集群才会处于可用状态。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习9-哨兵Sentinel</title>
    <link href="https://eoccc.gitee.io/2023/07/10/redis%E5%AD%A6%E4%B9%A09-%E5%93%A8%E5%85%B5Sentinel/"/>
    <id>https://eoccc.gitee.io/2023/07/10/redis%E5%AD%A6%E4%B9%A09-%E5%93%A8%E5%85%B5Sentinel/</id>
    <published>2023-07-10T05:10:32.000Z</published>
    <updated>2023-07-23T14:14:11.729Z</updated>
    
    <content type="html"><![CDATA[<p>哨兵Sentinel是redis集群高可用的解决方案：由一个或多个Sentinel节点组成，监视任意多个主服务器及主服务器下的所有从服务器，当主服务器下线的时候，从其从服务器中选择一个升级成主服务器。</p><span id="more"></span><h1 id="哨兵的作用"><a class="markdownIt-Anchor" href="#哨兵的作用"></a> 哨兵的作用</h1><ul><li><p>监控</p><p>哨兵会不断检查redis的master和slave有没有按照预期正常工作</p></li><li><p>故障恢复</p><p>当master故障时，哨兵会在slaver中选择一个提升为master，原来的master恢复后，变成降为slaver</p></li><li><p>通知</p><p>为客户端提供服务发现，当集群发生故障转移时，会将新的信息推送给客户端。</p></li></ul><h2 id="获取服务器信息"><a class="markdownIt-Anchor" href="#获取服务器信息"></a> 获取服务器信息</h2><p>Sentinel会以10秒每次的频率向主服务器发送<code>INFO</code>命令，通过主服务器返回的信息，可以获得两类信息：</p><blockquote><ol><li>主服务器本身的信息</li><li>主服务器的所有从服务器的信息</li></ol></blockquote><p>同时Sentinel会以10秒每次的频率向从服务器发送<code>INFO</code>命令，获得以下信息：</p><blockquote><ol><li>从服务器的运行ID <code>run_id</code></li><li>从服务器的角色<code>role</code></li><li>主服务器的ip地址<code>master_host</code>，主服务器的端口号<code>master_port</code></li><li>主从服务器的连接状态<code>master_link_status</code></li><li>从服务器的优先级<code>slave_priority</code></li><li>从服务器的复制偏移量<code>slave_repl_offset</code></li></ol></blockquote><p>Sentinel会以2秒每次的频率向主从服务器的<code>__sentinel__:hello</code>频道发送以下信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUBLISH __sentinel__:hello <span class="string">&quot;&lt;s_ip&gt;,&lt;s_port&gt;,&lt;s_runid&gt;,&lt;s_epoch&gt;,&lt;m_name&gt;,&lt;m_ip&gt;,&lt;m_port&gt;,&lt;m_epoch&gt;&quot;</span> </span><br></pre></td></tr></table></figure><table><thead><tr><th>参数</th><th>意义</th></tr></thead><tbody><tr><td>s_ip</td><td>Sentiel 的IP</td></tr><tr><td>s_port</td><td>Sentiel 的端口号</td></tr><tr><td>s_runid</td><td>Sentiel 的运行id</td></tr><tr><td>s_epoch</td><td>Sentiel 的纪元</td></tr><tr><td>m_name</td><td>主服务器的名字</td></tr><tr><td>m_ip</td><td>主服务器的ip</td></tr><tr><td>m_port</td><td>主服务器的端口号</td></tr><tr><td>m_epoch</td><td>主服务器的纪元</td></tr></tbody></table><p>Sentinel与主服务器和从服务器建立连接后，会执行以下命令，订阅<code>__sentiel__:hello</code>频道的信息，解析收到的消息，并更新自己的数据。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SUBSCRIBE __sentiel__:hello</span><br></pre></td></tr></table></figure><p>另外，Sentinel可以通过主服务器或从服务器发送的频道信息，感知到新加入的Sentinel服务器。</p><h2 id="主观下线检测"><a class="markdownIt-Anchor" href="#主观下线检测"></a> 主观下线检测</h2><p>Sentinel会以<strong>每秒一次</strong>的频率向所有的主服务器、从服务器、其他Sentiel服务器发送<code>PING</code>命令，从而判断其他服务器是否在线。如果一个实例在<code>down_after_milliseconds</code>毫秒内没有回复，sentiel就会将这个实例标记为主观下线状态。</p><p>如果对一个sentinel进行了如下配置，那么master在50秒内没有回复<code>PONG</code>命令，sentinel就会认为master主观下线。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sentinel monitor master 127.0.0.1 6379 2</span><br><span class="line">sentinel down_after_milliseconds master 50000</span><br></pre></td></tr></table></figure><p><strong>需要注意的是</strong>：每个sentinel实例可以有不同的配置，一个sentinel认为master主观下线，另一个sentinel不一定认为master主观下线。</p><h2 id="客观下线检测"><a class="markdownIt-Anchor" href="#客观下线检测"></a> 客观下线检测</h2><p>当一个sentinel（记为sentinelA）发现某个节点主观下线后，会向其他sentine发送以下命令，询问这个节点是否下线：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SENTINEL is-master-down-by-addr &lt;ip&gt; &lt;port&gt; &lt;current_epoch&gt; &lt;runid&gt;</span><br></pre></td></tr></table></figure><p>当一个sentinel（记为sentinelB）收到这个命令的时候，会检查命令中的服务器是否下线，并回复是否赞成这个服务器已经下线。</p><p>sentinelA收到其他sentinel的回复以后，会判断其他sentinel是否赞成这个服务器已经下线，如果赞成票达到配置的数量以后，就会将这个服务器标记成客观下线。</p><p>如以下配置表示支持master主观下线的票数达到3票，就会将master标记为客观下线：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentinel monitor master 127.0.0.1 6379 5</span><br></pre></td></tr></table></figure><p>**需要注意的是：**不同的sentinel判断客观下线的条件不同，根据sentinel的配置决定。</p><h2 id="选举领头sentinel"><a class="markdownIt-Anchor" href="#选举领头sentinel"></a> 选举领头Sentinel</h2><p>当一个主服务器下线之后，负责监视的sentinel会进行协商，选举出一个领头的sentinel，由领头的sentinel主持故障转移。选举领头sentinel的规则如下：</p><blockquote><ol><li>每次选举，不论选举是否成功，所有sentinel的纪元都会加1</li><li>在一个纪元里，一个sentinel有一次将某个sentinel设置为leader的机会，而且一旦设置，在这个纪元里就不会再更改</li><li>每个发现主服务器客观下线的sentinel都会要求其他sentinel将自己设置为leader（最终只会有一个成功）</li><li>担任leader的规则是先到先得：最先发现主服务器客观下线的sentinel会率先发起选举投票</li><li>如果有某个sentinel收到半数以上的投票，则成为leader</li><li>如果在限定的时间内没有选举成功，那么各个sentinel会隔一段时间之后再次选举，直到选举出leader</li></ol></blockquote><h2 id="故障转移"><a class="markdownIt-Anchor" href="#故障转移"></a> 故障转移</h2><p>选举出sentinel的leader以后，leader就会主持故障转移：</p><blockquote><ol><li>在主服务器的所有从服务器中选出一个，成为主服务器</li><li>让其他从服务器复制这个新的主服务器</li><li>原来的主服务器恢复以后，成为新的主服务器的从服务器</li></ol></blockquote><h3 id="选举主服务器"><a class="markdownIt-Anchor" href="#选举主服务器"></a> 选举主服务器</h3><p>哨兵leader会把所有从服务器保存在一个列表中，从中选择出一个状态良好、数据完整的服务器，成为新的主服务器：</p><blockquote><ol><li>删除列表中所有处于下线状态的服务器</li><li>删除列表中最近5秒内没有回复sentinel的<code>INFO</code>命令的服务器</li><li>删除与主服务器断开连接超过<code>down_after_milliseconds * 10</code>毫秒的服务器</li><li>选择出列表中剩余的服务器中优先级最高的一个</li><li>如果有多个优先级一样的服务器，选择其中偏移量最大的一个</li><li>如果有多个偏移量一样的服务器，选择其中运行ID最小的一个</li></ol></blockquote><p>向选出的服务器发送以下命令，并以每秒一次的频率向其发送<code>INFO</code>命令，当其<code>role</code>属性由&quot;slave&quot;变成&quot;master&quot;，则成功变成主服务器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SLAVEOF no one</span><br></pre></td></tr></table></figure><h3 id="修改从服务器的复制目标"><a class="markdownIt-Anchor" href="#修改从服务器的复制目标"></a> 修改从服务器的复制目标</h3><p>当新的主服务器出现后，leader会向所有的从服务器发送<code>SLAVEOF</code>命令，让它们复制新的主服务器。</p><h3 id="旧主服务器变成从服务器"><a class="markdownIt-Anchor" href="#旧主服务器变成从服务器"></a> 旧主服务器变成从服务器</h3><p>当旧服务器恢复重连的时候，sentinel会向其发送<code>SLAVEOF</code>命令，让其成为新主服务的从服务器。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;哨兵Sentinel是redis集群高可用的解决方案：由一个或多个Sentinel节点组成，监视任意多个主服务器及主服务器下的所有从服务器，当主服务器下线的时候，从其从服务器中选择一个升级成主服务器。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习8-复制（主从架构）</title>
    <link href="https://eoccc.gitee.io/2023/07/09/redis%E5%AD%A6%E4%B9%A08-%E5%A4%8D%E5%88%B6%EF%BC%88%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84%EF%BC%89/"/>
    <id>https://eoccc.gitee.io/2023/07/09/redis%E5%AD%A6%E4%B9%A08-%E5%A4%8D%E5%88%B6%EF%BC%88%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84%EF%BC%89/</id>
    <published>2023-07-09T06:10:32.000Z</published>
    <updated>2023-07-23T14:14:00.415Z</updated>
    
    <content type="html"><![CDATA[<p>在主从架构的redis集群中，为了保证主从服务器数据的一致性，redis通过复制和广播，尽力保证数据的一致性。本节会介绍reids复制的具体实现。</p><span id="more"></span><p>Redis可以通过如下命令复制一个服务器，或者说成为另一个服务器的从服务器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SLAVEOF &lt;ip&gt; &lt;port&gt;</span><br></pre></td></tr></table></figure><h2 id="旧版复制的实现"><a class="markdownIt-Anchor" href="#旧版复制的实现"></a> 旧版复制的实现</h2><p>Redis的复制功能包括同步和广播两个操作：</p><blockquote><ul><li><p>redis从服务器将数据更新到和主服务器一致的状态</p></li><li><p>主服务器的数据库发生变更的时候，会广播数据库的变化，使从服务器的数据库保持一致</p></li></ul></blockquote><h3 id="同步"><a class="markdownIt-Anchor" href="#同步"></a> 同步</h3><p>当服务器发送<code>SLAVEOF</code>命令成为另一个服务器的从服务器的时候，会先执行同步操作，使数据一致。执行同步操作需要从服务器发送<code>SYNC</code>命令给主服务器：</p><blockquote><ol><li>从服务器向主服务器发送<code>SYNC</code>命令</li><li>主服务器收到<code>SYNC</code>命令，先执行<code>BGSAVE</code>命令生成一个RDB文件，<strong>并使用一个缓冲区记录此时开始执行的所有命令</strong></li><li>主服务器执行完<code>BGSAVE</code>命令生成了一个新的RDB文件，发送给从服务器，从服务器载入文件，使数据库更新至主服务器开始实行<code>BGSAVE</code>命令时的状态</li><li>主服务器将缓冲区中的内容发送给从服务器，从服务器执行这些命令，使数据库更新到主服务器的当前状态</li></ol></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/-AJRbuM9i.jpeg" alt="img" style="zoom:50%;"><h3 id="命令广播"><a class="markdownIt-Anchor" href="#命令广播"></a> 命令广播</h3><p>在执行完同步操作后，主从服务器的数据库达到了一致的状态。这时，如果有新的数据写入，为了让主从数据库保持一致，主服务器会将自己执行的写命令广播给从服务器，从服务器执行收到的命令，使数据库保持一致。</p><h3 id="旧版复制的缺陷"><a class="markdownIt-Anchor" href="#旧版复制的缺陷"></a> 旧版复制的缺陷</h3><p>每次复制都会全量的复制主服务器的数据，而对于断线后的重新复制，大多数情况下是不需要进行全量复制的，只需要复制新增的命令即可。<code>SYNC</code>每次都会进行以下的操作：</p><blockquote><ol><li>主服务器执行<code>BGSAVE</code>生成新的RDB文件，耗费cpu、io和内存资源</li><li>主服务器将新的RDB文件传给从服务器，浪费网络资源</li><li>从服务器载入RDB文件，处于阻塞状态，不能处理客户端传的命令</li></ol></blockquote><h2 id="新版复制的实现"><a class="markdownIt-Anchor" href="#新版复制的实现"></a> 新版复制的实现</h2><p>为了解决旧版每次都会进行全量复制，造成资源浪费的问题。新版复制使用<code>PSYNC</code>替代了<code>SYNC</code>命令，能够进行完整复制个部分复制。</p><p>新版复制添加了主从服务器的复制偏移量和服务器运行ID，以实现部分复制的功能。</p><h3 id="复制偏移量"><a class="markdownIt-Anchor" href="#复制偏移量"></a> 复制偏移量</h3><p>主从服务器都维护了自己的复制偏移量：</p><blockquote><p>主服务器每向从服务器发送N个字节的数据，就会将自己的偏移量加N</p><p>从服务器每收到主服务器发送来的N个字节的数据，就会将自己的偏移量加N</p></blockquote><p>从服务器请求同步的时候，会将自己的偏移量传给主服务器，主服务器只会发送未同步的数据。</p><h3 id="复制积压缓冲区"><a class="markdownIt-Anchor" href="#复制积压缓冲区"></a> 复制积压缓冲区</h3><p>主服务器在将命令广播给所有从服务器时，还会将广播的命令写入到<strong>复制积压缓冲区</strong>，并且记录每个字节的偏移量。</p><p>当从服务器请求同步的时候，主服务器会根据偏移量判断进行何种同步：</p><blockquote><p>如果从服务器偏移量之后的数据仍然存在复制积压缓冲区，主服务器会进行部分同步</p><p>如果从服务器偏移量之后的数据已经不存在复制积压缓冲区，主服务器会进行全量同步</p></blockquote><p>因此，积压缓冲区的大小要进行合理的配置：</p><blockquote><p>积压缓冲区的默认大小为1MB，当写入的频率很高或断线重连的时间较长，这个大小会变得不合理，导致不能进行部分同步。</p><p>为了安全起见，建议将复制积压缓冲区的大小设置成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2 * 断线重连需要的秒数 * 每秒产生的数据平均长度</span><br></pre></td></tr></table></figure></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230716212042551.png" alt="image-20230716212042551" style="zoom:46%;"><h3 id="服务器id"><a class="markdownIt-Anchor" href="#服务器id"></a> 服务器ID</h3><p>Redis的主从服务器都有自己的ID，redis的主服务器会将自己的ID发送给从服务器保存起来，从服务器断线重连时会将之前连接的主服务器的ID发送给主服务器，主服务器据此判断进行何种复制：</p><blockquote><p>如果收到的服务器ID和自己的ID相同，说明从服务器之前就是复制的自己，尝试进行部分复制</p><p>如果收到的服务器ID和自己的ID不同，进行全量复制</p></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/VdjFUt_OMV.jpeg" alt="img" style="zoom:40%;"><h2 id="心跳检测"><a class="markdownIt-Anchor" href="#心跳检测"></a> 心跳检测</h2><p>在广播阶段，从服务器每秒会执行一次以下命令，向服务器发送自己的偏移量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">REPLCONF ACK &lt;replication_offset&gt;</span><br></pre></td></tr></table></figure><h3 id="检测网络连接状态"><a class="markdownIt-Anchor" href="#检测网络连接状态"></a> 检测网络连接状态</h3><p>主从服务器通过发送和接收<code>REPLCONF ACK</code>命令，检查两者之间的网络连接状态，如果超过一秒没有收到从服务器的<code>REPLCONF ACK</code>命令，说明从服务器的连接出现问题了。</p><h3 id="检测从服务器数量"><a class="markdownIt-Anchor" href="#检测从服务器数量"></a> 检测从服务器数量</h3><p>如果我们配置了如下属性，那么从服务器的数量小于3个，或者所有服务器的延迟都大于10秒的时候，主服务器将拒绝执行写命令，集群不可用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write 3   //最少从服务器数量为3</span><br><span class="line">min-slaves-max-lag 10   //最大延迟大于10秒</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;在主从架构的redis集群中，为了保证主从服务器数据的一致性，redis通过复制和广播，尽力保证数据的一致性。本节会介绍reids复制的具体实现。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习7-时钟周期serverCron</title>
    <link href="https://eoccc.gitee.io/2023/07/08/redis%E5%AD%A6%E4%B9%A07-%E6%97%B6%E9%92%9F%E5%91%A8%E6%9C%9FserverCron/"/>
    <id>https://eoccc.gitee.io/2023/07/08/redis%E5%AD%A6%E4%B9%A07-%E6%97%B6%E9%92%9F%E5%91%A8%E6%9C%9FserverCron/</id>
    <published>2023-07-08T04:10:32.000Z</published>
    <updated>2023-07-23T14:20:05.639Z</updated>
    
    <content type="html"><![CDATA[<p>Redis服务器的serverCron方法默认每100ms执行一次，这个方法负责管理redis的资源，保证redis能够良好的运行。本文介绍cerverCron方法的功能。</p><span id="more"></span><h2 id="更新服务器时间缓存"><a class="markdownIt-Anchor" href="#更新服务器时间缓存"></a> 更新服务器时间缓存</h2><p>Redis服务器的不少功能都需要用到时间，每使用一次时间都需要进行一次系统调用，为了减少系统调用的次数，redis缓存了时间。但是由于serverCron每100ms才执行一次，缓存的时间精度不高，只有对时间精度要求不高的功能才会使用缓存的时间，如打印日志、更行服务器LRU时钟、决定是否进行持久化任务、计算服务的上线时间等。而对于对时间精度要求较高的功能，则会直接调用系统的时间，如为键设置过期时间、添加慢查询日志等。</p><h2 id="更新lru时钟"><a class="markdownIt-Anchor" href="#更新lru时钟"></a> 更新LRU时钟</h2><p>Redis服务器的lruclock属性保存了服务器的LRU时钟。redis的每个对象都会有一个lru属性，记录了这个对象最后一次的访问时间。当需要计算键的空转时间时，就会使用服务器的lruclock减去对象的lru。</p><p>lruclock的值可以用过以下命令返回的<code>lru_clock</code>节点查看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO server</span><br></pre></td></tr></table></figure><h2 id="更新服务器每秒执行命令的次数"><a class="markdownIt-Anchor" href="#更新服务器每秒执行命令的次数"></a> 更新服务器每秒执行命令的次数</h2><p>Redis会以100ms一次的频率更新每秒执行命令的次数，计算方式为抽样计算，具体如下：</p><blockquote><ol><li>计算出上次抽样和这次抽样的时间差</li><li>计算出上次抽样和本次抽样已执行的命令数的差值（即这个时间区间执行了多少命令）</li><li>计算出这个时间区间每毫秒执行了多少个命令</li><li>将每秒执行的命令个数乘1000，得到每秒执行的次数，缓存到一个数组中</li><li>当客户端执行<code>INFO</code>命令时，redis会根据数组中记录的值计算出平均每秒执行的命令个数</li></ol></blockquote><h2 id="更新服务器内存峰值记录"><a class="markdownIt-Anchor" href="#更新服务器内存峰值记录"></a> 更新服务器内存峰值记录</h2><p>Redis的<code>stat_peak_memory</code>属性记录了服务器使用内存的峰值。serverCron每次执行都会查看当前服务器使用的内存数量，如果大于当前的<code>stat_peak_memory</code>，就会更新其值。</p><p>通过以下命令返回的<code>used_memory_peak</code>和<code>used_memory_peak_human</code>可以查看内存使用的峰值：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO memory</span><br></pre></td></tr></table></figure><h2 id="处理sigterm信号"><a class="markdownIt-Anchor" href="#处理sigterm信号"></a> 处理SIGTERM信号</h2><p>Redis收到SIGTERM信号（终止信号）时，不会立即执行，而是通过<code>sigtermHandler</code>信号处理器，打开服务器的 <code>shutdown_asap</code>标识。serverCron每次执行都会检查这个标识，决定是否关闭服务器。如果这个标识打开，服务器会先进行RDB持久化，然后再关闭服务器。</p><h2 id="管理客户端资源"><a class="markdownIt-Anchor" href="#管理客户端资源"></a> 管理客户端资源</h2><p>serverCron每次执行都会对一定数量的客户端进行检查：</p><blockquote><ol><li>如果客户端连接已经超时，关闭客户端</li><li>如果客户端上一次执行命令之后，客户端输入缓冲区已经超过一定长度，会释放当前输入缓冲区，并创建一个新的</li></ol></blockquote><h2 id="管理数据库资源"><a class="markdownIt-Anchor" href="#管理数据库资源"></a> 管理数据库资源</h2><p>serverCron每次执行都会触发内存的定期清除策略，对数据库中的key进行抽样检查，删除过期的key，并在需要的时候对字典进行缩容。</p><p>具体见<a href="https://eoccc.gitee.io/blog/2022/03/24/redis%E5%AD%A6%E4%B9%A03-%E8%BF%87%E6%9C%9F%E9%94%AE%E6%B8%85%E9%99%A4%E7%AD%96%E7%95%A5/">过期键的清除策略</a></p><h2 id="执行被延迟的bgrewriteaof"><a class="markdownIt-Anchor" href="#执行被延迟的bgrewriteaof"></a> 执行被延迟的BGREWRITEAOF</h2><p>Redis在执行<code>BGSAVE</code>命令期间，如果收到<code>BGREWRITEAOF</code>的请求，会等到<code>BGSAVE</code>结束后再执行，并把等待标识<code>aof_rewrite_scheduled</code>置为1。</p><p>serverCron每次执行都会检查<code>BGSAVE</code>和<code>BGREWRITEAOF</code>有没有在执行，如果两个命令都没在执行，并且<code>aof_rewrite_scheduled</code>为1，就会执行<code>BGREWRITEAOF</code>命令。</p><h2 id="检查持久化操作状态"><a class="markdownIt-Anchor" href="#检查持久化操作状态"></a> 检查持久化操作状态</h2><p>Redis的<code>rdb_child_pid</code>和<code>aof_child_pid</code>两个属性记录了执行<code>BGSAVE</code> 和<code>BGREWRITEAOF</code>命令的子进程的pid。serverCron每次执行都会检查这两个属性，只要有一个值不为-1，就会检查有没有收到子进程的信号：</p><blockquote><ol><li>如果收到信号，说明RDB或AOF文件已经生成成功，redis会使用新的文件替换旧的文件</li><li>如果没有收到信号，说明持久化未完成，不做任何操作</li></ol></blockquote><p>如果两个值都为-1，则说明没有在执行任何持久化操作，redis会进行以下检查：</p><blockquote><ol><li>检查是否有被延迟的<code>BGREWRITEAOF</code>命令，有的话执行命令</li><li>检查数据库是否达到持久化条件，满足条件会执行<code>BGSAVE</code>命令进行RDB持久化</li><li>检查是否满足AOF重写条件，满足会执行<code>BGREWRITEAOF</code>命令重写AOF文件</li></ol></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/RBxtzVwLN.jpeg" alt="img/RBxtzVwLN.jpeg" style="zoom:50%;"><h2 id="将aof缓冲区的内容写入到文件"><a class="markdownIt-Anchor" href="#将aof缓冲区的内容写入到文件"></a> 将AOF缓冲区的内容写入到文件</h2><p>如果服务器开启了AOF持久化功能，redis每次执行serverCron会检查AOF缓冲区是否有内容，如果有，会持久化到AOF文件。</p><h2 id="关闭异步客户端"><a class="markdownIt-Anchor" href="#关闭异步客户端"></a> 关闭异步客户端</h2><p>关闭那些使用资源超限的客户端，超限的规则包括：</p><blockquote><ol><li>客户端的输出缓冲区一直超过软性限制，并且时间达到指定的时长</li><li>客户端的输出缓冲区超过硬性限制</li><li>客户端的输入缓冲区超过限制（默认1GB）</li><li>客户端的空转时间超过了设置的阈值</li></ol></blockquote><p>注意：</p><blockquote><ol><li>执行lua脚本的伪客户端会一直存在，redis服务关闭才会关闭这个客户端</li><li>用于载入AOF文件的伪客户端，在执行完AOF文件中的命令后关闭</li></ol></blockquote><h2 id="cronloops计数器递增"><a class="markdownIt-Anchor" href="#cronloops计数器递增"></a> cronloops计数器递增</h2><p>执行完serverCron方法后，会对<code>cronloops</code>属性加1，记录执行serverCron方法的次数。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Redis服务器的serverCron方法默认每100ms执行一次，这个方法负责管理redis的资源，保证redis能够良好的运行。本文介绍cerverCron方法的功能。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习6-客户端和服务器</title>
    <link href="https://eoccc.gitee.io/2023/07/07/redis%E5%AD%A6%E4%B9%A06-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    <id>https://eoccc.gitee.io/2023/07/07/redis%E5%AD%A6%E4%B9%A06-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%99%A8/</id>
    <published>2023-07-07T03:20:29.000Z</published>
    <updated>2023-07-23T15:01:13.470Z</updated>
    
    <content type="html"><![CDATA[<p>Redis一个服务器可以与多个客户端进行网络连接，每个客户端可以向服务器发送命令请求，服务器接受并处理客户端发送的命令，并向客户端返回命令回复。</p><span id="more"></span><h2 id="客户端"><a class="markdownIt-Anchor" href="#客户端"></a> 客户端</h2><p>Redis会为每一个客户端创建一个redisClient对象，用来保存客户端的信息，并使用链表来保存多个客户端。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/wM5TR4Y6q.jpeg" alt="img/wM5TR4Y6q.jpeg" style="zoom:50%;"><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisClient</span> &#123;</span></span><br><span class="line">  <span class="type">int</span> fd;        <span class="comment">//套接字</span></span><br><span class="line">  robj *name;    <span class="comment">//客户端名称</span></span><br><span class="line">  <span class="type">int</span> flags;     <span class="comment">//客户端的角色和状态</span></span><br><span class="line">  sds querybuf;  <span class="comment">//输入缓冲区</span></span><br><span class="line">  robj **argv;   <span class="comment">//命令和参数</span></span><br><span class="line">  <span class="type">int</span> argc;      <span class="comment">//命令和参数的长度</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">redisCommand</span> *<span class="title">cmd</span>;</span>   <span class="comment">//执行命令的函数</span></span><br><span class="line">  <span class="type">char</span> buf[REDIS_REPLY_CHUNK_BYTES];  <span class="comment">//固定长度的输出缓冲区</span></span><br><span class="line">  <span class="type">int</span> bufpos;    <span class="comment">//输出缓冲区已使用的长度</span></span><br><span class="line">  <span class="built_in">list</span> *reply;   <span class="comment">//动态长度的输出缓冲区</span></span><br><span class="line">  <span class="type">int</span> authenticated;       <span class="comment">//身份验证</span></span><br><span class="line">  <span class="type">time_t</span> ctime;            <span class="comment">//客户端创建时间</span></span><br><span class="line">  <span class="type">time_t</span> lastinteraction;  <span class="comment">//最后一次交互时间</span></span><br><span class="line">  <span class="type">time_t</span> obuf_soft_limit_reached_time;  <span class="comment">//输出缓冲区第一次达到软性限制的时间</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="redisclient"><a class="markdownIt-Anchor" href="#redisclient"></a> redisClient</h2><h3 id="redisclientfd"><a class="markdownIt-Anchor" href="#redisclientfd"></a> redisClient.fd</h3><p>redisClient.fd记录了客户端正在使用的套接字描述符。根据客户端类型的不同，fd的值可以是-1或者大于-1。</p><blockquote><p>-1：伪客户端。伪客户端是服务器创建的，用来载入AOF文件或者执行Lua脚本，这种客户端不需要网络连接，自然不存在文件描述符。</p><p>大于-1：普通客户端。使用套接字与服务器进行网络通信，fd记录了套接字的文件描述符。</p></blockquote><h3 id="redisclientname"><a class="markdownIt-Anchor" href="#redisclientname"></a> <a href="http://redisClient.name">redisClient.name</a></h3><p>默认情况下，一个普通客户端是没有名字的，Redis可以用以下命令为客户端设置一个名字：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLIENT setname myName</span><br></pre></td></tr></table></figure><p>然后使用以下命令，可以看到name属性：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLIENT list</span><br></pre></td></tr></table></figure><h2 id="redisclientflags"><a class="markdownIt-Anchor" href="#redisclientflags"></a> redisClient.flags</h2><p>redisClient.flags记录了客户端的角色，以及客户端目前的状态。flags可以有一个或多个值，如：</p><blockquote><p>flags = &lt;flag&gt;</p><p>flags = &lt;flag1&gt;|&lt;flag2&gt;|&lt;flag3&gt;|…</p></blockquote><p>flags可以有以下值：</p><table><thead><tr><th style="text-align:left">标志</th><th style="text-align:left">标志代码的含义</th></tr></thead><tbody><tr><td style="text-align:left">REDIS_MASTER</td><td style="text-align:left">客户端是一个主服务器</td></tr><tr><td style="text-align:left">REDIS_SLAVE</td><td style="text-align:left">客户端是一个从服务器</td></tr><tr><td style="text-align:left">REDIS_PRE_PSYNC</td><td style="text-align:left">客户端版本低于2.8，不能使用PSYNC与这个从服务器进行同步，这个标志只能在REDIS_SLAVE标志打开时使用</td></tr><tr><td style="text-align:left">REDIS_LUA_CLIENT</td><td style="text-align:left">用于处理Lua脚本的伪客户端</td></tr><tr><td style="text-align:left">REDIS_MONITOR</td><td style="text-align:left">客户端正在执行MONITOR指令</td></tr><tr><td style="text-align:left">REDIS_UNIX_SOCKET</td><td style="text-align:left">服务器使用UNIX套接字来连接客户端</td></tr><tr><td style="text-align:left">REDIS_BLOCKED</td><td style="text-align:left">客户端处于阻塞状态</td></tr><tr><td style="text-align:left">REDIS_UNBLOCKED</td><td style="text-align:left">客户端从REDIS_BLOCKED状态脱离出来</td></tr><tr><td style="text-align:left">REDIS_MULTI</td><td style="text-align:left">客户端正在执行事务</td></tr><tr><td style="text-align:left">REDIS_DIRTY_CAS</td><td style="text-align:left">事务使用WATCH命令监视的键已经被修改</td></tr><tr><td style="text-align:left">REDIS_DIRTY_EXEC</td><td style="text-align:left">事务在命令入队时出现错误</td></tr><tr><td style="text-align:left">REDIS_CLOSE_ASAP</td><td style="text-align:left">客户端的输出缓冲区超过了服务器允许的范围，服务器在执行下一次sercerCron函数时会关闭这个客户端，积存在输出缓冲区的内容会被释放，不会返回给客户端</td></tr><tr><td style="text-align:left">REDIS_CLOSE_AFTER_REPLY</td><td style="text-align:left">用户对这个客户端执行了<code>CLIENT KILL</code>命令，或者客户端发送给服务器的命令中包含错误的协议内容，服务器会把输出缓冲区的所有内容发送给客户端，然后关闭客户端</td></tr><tr><td style="text-align:left">REDIS_ASKING</td><td style="text-align:left">客户端向集群发送了<code>ASKING</code>命令</td></tr><tr><td style="text-align:left">REDIS_FORCE_AOF</td><td style="text-align:left">强制服务器将当前执行的命令写入到AOF文件</td></tr><tr><td style="text-align:left">REDIS_FORCE_REPL</td><td style="text-align:left">强制主服务器将当前执行的命令复制给所有从服务器</td></tr></tbody></table><h3 id="redisclientquerybuf"><a class="markdownIt-Anchor" href="#redisclientquerybuf"></a> redisClient.querybuf</h3><p>querybuf属性指向了redis输入缓冲区，类型为动态字符串。输入缓冲区的大小可以动态的扩容和缩容，但是它最大不能超过1GB，如果超过1GB，redis会关闭客户端。下图展示了querybuf的结构：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/aEdPJFwbw.jpeg" alt="img/aEdPJFwbw.jpeg" style="zoom:33%;"><h3 id="命令与参数"><a class="markdownIt-Anchor" href="#命令与参数"></a> 命令与参数</h3><p>Redis服务器将客户端发送的命令保存到输入缓冲区后，就会解析请求的内容，并将请求中的命令和参数保存到redisClient的<code>argv</code>和<code>argc</code>中。</p><p>其中<code>argv</code>是一个字符串数组，<code>argv[0]</code>存储了命令，后面的元素是命令的参数。<code>argc</code>则记录了<code>argv</code>的长度。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/zm2WdRfBa.jpeg" alt="img/zm2WdRfBa.jpeg" style="zoom:33%;"><h3 id="执行命令的函数"><a class="markdownIt-Anchor" href="#执行命令的函数"></a> 执行命令的函数</h3><p>Redis维护了一个保存了命令实现函数的字典，服务器解析完命令后，就会根据<code>argv[0]</code>中的命令去这个字典中查找执行命令的函数，然后将指向这个函数的指针赋值给<code>redisClient.cmd</code></p><img src="https://gitee.com/eoccc/pic-shack/raw/master/Rrl7XfhcL.jpeg" alt="img/Rrl7XfhcL.jpeg" style="zoom:33%;"><h3 id="输出缓冲区"><a class="markdownIt-Anchor" href="#输出缓冲区"></a> 输出缓冲区</h3><p>执行命令得到的回复会被保存在客户端的输出缓冲区中，每个redis客户端都有两个输出缓冲区：</p><blockquote><p>redisClient.buf[REDIS_REPLY_CHUNK_BYTES]：是一个REDIS_REPLY_CHUNK_BYTES字节大小的缓冲区，默认是16kb，用于保存那些较短的回复，如ok，另外由<code>redisClient.bufpos</code>保存已经使用的缓冲区大小</p><p>redisClient.reply：是一个可变大小的缓冲区，用来保存比较长的回复</p></blockquote><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/3FqAC4JPx.jpeg" alt="img/3FqAC4JPx.jpeg" style="zoom:33%;"><img src="https://gitee.com/eoccc/pic-shack/raw/master/2Zr_wPq74.jpeg" alt="img" style="zoom:33%;"></p><h3 id="身份验证"><a class="markdownIt-Anchor" href="#身份验证"></a> 身份验证</h3><p>Redis使用<code>redisClient.authenticated</code>字段保存客户端是否通过了身份验证。</p><blockquote><p>authenticated值为0的时候，表示未通过身份验证，除了<code>AUTH</code>指令之外，客户端发送的其他所有指令都会被拒绝执行</p><p>authenticated值为1的时候，表示通过身份验证。</p></blockquote><h3 id="时间"><a class="markdownIt-Anchor" href="#时间"></a> 时间</h3><p>Redis客户端中保存了几个和时间相关的属性：</p><blockquote><p>redisClient.ctime：创建客户端的时间</p><p>redisClient.lastinteraction：客户端与服务器最后一次互动的时间</p><p>redisClient.obuf_soft_limit_reached_time：输出缓冲区第一次达到软性限制的时间</p></blockquote><p><strong>硬性限制：</strong> 客户端的输出缓冲区超过硬性限制之后，服务器会立即关闭这个客户端。</p><p><strong>软性限制：</strong> 如果客户端输出缓冲区达到了软性限制的大小，但还没达到硬性限制的大小，redis会记录一下这个时间。之后服务器会监视这个客户端，如果这个客户端的输出缓冲区一直超过软性限制，并且时间达到指定的时长，服务器就会关闭这个客户端；如果这期间输出缓冲区小于软性限制，则会将时间清零。</p><h2 id="关闭客户端"><a class="markdownIt-Anchor" href="#关闭客户端"></a> 关闭客户端</h2><h3 id="关闭普通客户端"><a class="markdownIt-Anchor" href="#关闭普通客户端"></a> 关闭普通客户端</h3><p>普通客户端关闭原因：</p><blockquote><ol><li>客户端进程退出或被杀死，客户端与服务器之间的网络连接被关闭，造成客户端被关闭</li><li>客户端向服务器发送带有不符合协议格式的命令请求，客户端也会被服务器关闭</li><li>客户端是CLIENT KILL命令的目标，将会被关闭</li><li>用户为服务器设置了timeout配置选项，客户端的空转时间超过timeout设置的值，客户端将被关闭</li><li>客户端发送命令请求超过输入缓冲区的限制大小（默认1GB），客户端就会被服务器关闭</li><li>发送客户端的命令回复的大小超过了输出缓冲区的限制大小，客户端会被关闭</li></ol></blockquote><h3 id="关闭伪客户端"><a class="markdownIt-Anchor" href="#关闭伪客户端"></a> 关闭伪客户端</h3><ol><li><p>执行lua脚本的客户端</p><p>服务器在初始化时创建负责执行lua脚本中redis命令的伪客户端，并将伪客户端关联的服务器记录在redisServer结构中的lua_client属性中，在服务器运行时一直存在，在服务器关闭的时候这个伪客户端才会关闭</p></li><li><p>载入AOF文件的客户端</p><p>服务器在载入AOF文件时，会创建一个伪客户端用于执行AOF文件包含的redis命令，载入完成后关闭伪客户端</p></li></ol><h2 id="服务器"><a class="markdownIt-Anchor" href="#服务器"></a> 服务器</h2><p>服务器与多个客户端建立连接，接收并处理客户端发来的请求，给客户端返回命令的执行结果，并在数据库中保存执行命令产生的数据。</p><h3 id="命令请求执行的过程"><a class="markdownIt-Anchor" href="#命令请求执行的过程"></a> 命令请求执行的过程</h3><blockquote><ol><li>客户端发送命令，将命令转成redis协议(RESP)，然后通过套接字发给服务器</li><li>服务器接收请求，将redis协议的命令存到输入缓冲区</li><li>服务器队输入缓冲区中的内容进行解析，提取出其中的命令以及参数，放到<code>argv</code>和<code>aegc</code>中</li><li>服务器根据命令区查找执行命令的方法，放到<code>cmd</code>中</li><li>服务器调用命令执行器，执行命令</li></ol></blockquote><h3 id="执行命令前的校验"><a class="markdownIt-Anchor" href="#执行命令前的校验"></a> 执行命令前的校验</h3><p>服务器在执行命令之前，还会进行如下的校验，然后才会执行命令：</p><blockquote><ol><li>检查客户端的<code>cmd</code>是否指向null，如果是，说明没有找到客户端请求的命令的执行函数，不能继续执行，给客户端返回错误</li><li>检查请求中命令的参数是否齐全，不齐全就不能执行命令，给客户端返回一个错误</li><li>检查客户端是否通过身份验证，没有通过的客户端只能执行<code>AUTH</code>命令</li><li>如果服务器开通了maxmemory功能，会检查服务器的内存占用情况，需要时进行回收，回收失败不执行命令，并给客户端返回一个错误</li><li>如果上一个<code>BGSAVE</code>命令执行失败，并且服务器打开了<code>stop_writes_on_bgsave_error</code>，服务器会拒绝执行命令，并返回一个错误</li><li>如果服务器正在载入数据，只会执行<code>INFO</code>, <code>SHUTDOWN</code>, <code>PUBLISH</code>命令</li><li>如果服务器正在执行Lua脚本，会处于阻塞状态，只会执行<code>SHUTDOWN nosave</code>和<code>SCRIPT KILL</code>命令，其他命令会被拒绝</li><li>如果服务器真正执行事务，只会执行<code>EXEC</code> <code>DISCARD</code> <code>MULTI</code> <code>WAtCH</code>命令</li><li>如果服务器打开了监视器功能，会将命令和参数发送给监视器</li></ol></blockquote><h3 id="执行命令"><a class="markdownIt-Anchor" href="#执行命令"></a> 执行命令</h3><p>redisClient里面已经包含了执行命令需要的所有信息，redis会直接执行命令，并将命令产生的结果放到输出缓冲区。然后redis还会为客户端套接字关联命令回复处理器，以便将命令的回复发送给客户端。套接字变成可写状态，命令回复处理器将输出缓冲区中的内容写入到套接字，然后清空输出缓冲区。</p><h3 id="执行命令的后续操作"><a class="markdownIt-Anchor" href="#执行命令的后续操作"></a> 执行命令的后续操作</h3><p>执行命令后续操作：</p><blockquote><ol><li>如果服务器开启了慢查询功能，那么慢查询日志模块会判断需不需要为刚才的命令添加一条慢查询日志</li><li>更新刚才的redisCommand的<code>millionsecond</code>属性，记录执行命令的耗时，并将<code>calls</code>属性加1</li><li>如果开启了AOF功能，并且命令修改了数据库，将刚刚执行的命令写入到AOF缓冲区</li><li>如果有其他服务器在复制这台服务器，并且命令修改了数据库，把刚刚执行的命令广播出去</li></ol></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;Redis一个服务器可以与多个客户端进行网络连接，每个客户端可以向服务器发送命令请求，服务器接受并处理客户端发送的命令，并向客户端返回命令回复。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习5-AOF持久化</title>
    <link href="https://eoccc.gitee.io/2023/07/06/redis%E5%AD%A6%E4%B9%A05-AOF%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    <id>https://eoccc.gitee.io/2023/07/06/redis%E5%AD%A6%E4%B9%A05-AOF%E6%8C%81%E4%B9%85%E5%8C%96/</id>
    <published>2023-07-06T07:22:23.000Z</published>
    <updated>2023-07-23T14:13:16.080Z</updated>
    
    <content type="html"><![CDATA[<p>Redis是内存数据库，如果不做持久化，一旦服务器退出，就会丢失所有数据。因此redis提供了两种持久化方式用于持久化数据：RDB和AOF。本篇文章介绍AOF持久化方式。</p><span id="more"></span><p>AOF文件存储的是redis的命令，默认是关闭的，可以通过配置打开（redis.conf）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes   // 是否开启AOF功能，默认no</span><br><span class="line">appendfilename   // AOF文件名</span><br></pre></td></tr></table></figure><h2 id="aof文件的写入"><a class="markdownIt-Anchor" href="#aof文件的写入"></a> AOF文件的写入</h2><p>为了提高写入效率，redis在开启了AOF持久化的情况下，执行了命令之后，会将被执行的命令追加到aof_buf缓冲区的末尾，然后以一定的频率写入到AOF文件中。写入的频率由配置<code>appendfsync</code>来决定：</p><blockquote><ul><li>always：每次执行命令都会将aof_buf中的内容写入到文件中</li><li>everysec：由一个子线程每秒钟进行一次同步，<strong>默认</strong></li><li>no：由操作系统决定何时将aof_buf中的内容写到文件中</li></ul></blockquote><p>效率与数据安全：</p><blockquote><ul><li>always：效率最低，但数据最安全，最多只会丢失一条命令</li><li>everysec：效率与数据安全较均衡，最多只会丢失一秒的数据</li><li>no：效率最高，但是数据最不安全，会丢失上次同步数据之后的所有数据</li></ul></blockquote><p>Redis只会将修改数据库的命令写入到AOF文件，并复制给所有从服务器。如果一个命令不会对数据库进行修改，那redis会认为这个命令是一个只读命令，不会将这个命令写入到服务器，也不会同步给从服务器。</p><p>由于AOF文件存储的是每一个redis命令，因此必然导致AOF文件的体积比较大，因此redis提供了<code>bgrewriteaof</code> 命令来重写AOF文件，通过将多个命令合并成一个命令，从而减少AOF存储的命令的数据，同时<code>bgrewriteaof</code>会对AOF文件进行压缩。 redis会在触发阈值的时候，对AOF文件进行重写，相关的阈值可以在 redis.conf 中配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">auto-aof-rewrite-percent 100   // AOF问件的体积比上次增长了100%时进行重写</span><br><span class="line">auto-aof-rewrite-min-size 64mb // AOF文件的体积达到64mb时进行重写</span><br></pre></td></tr></table></figure><h2 id="aof文件的载入"><a class="markdownIt-Anchor" href="#aof文件的载入"></a> AOF文件的载入</h2><p>AOF文件中保存了所有执行过的命令，所以载入AOF文件的时候，只需要把所有命令执行一遍就行了：</p><blockquote><ol><li>创建一个无连接的伪客户端，因为Redis只能通过客户端执行命令</li><li>从AOF中分析并读取写命令</li><li>使用伪客户端执行每一条命令</li></ol></blockquote><h2 id="aof重写"><a class="markdownIt-Anchor" href="#aof重写"></a> AOF重写</h2><p>由于AOF是通过保存被执行的命令来进行持久化，随着服务器的运行，AOF文件会变得越来越大，如果不进行控制，可能会导致宿主机宕机，并且过大的AOF文件，还原的时间也很长。Redis通过重写AOF文件来解决这个问题，新的AOF文件保存了当前的数据库状态，但是不会保存任何冗余的命令。</p><ul><li>AOF重写不是读取并分析旧的AOF文件，然后重写，而是直接读取数据库，然后生成命令写入AOF文件</li><li>AOF重写会涉及大量的写操作，导致长时间的阻塞，所以redis通过一个子进程并行的写</li></ul><p>由于AOF重写时主进程仍然能够接受客户端的请求，为解决数据一致性的问题，redis在创建子进程的时候会创建一个AOF重写缓冲区，redis会将新的命令同时写入AOF缓冲区和AOF重写缓冲区，然后同时写到新旧AOF文件。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/tdOHJiC5s.jpeg" alt="img/tdOHJiC5s.jpeg" style="zoom:60%;"><p>当AOF文件重写完成后，会向父进程发送一个信号，原子地使用新的AOF文件覆盖旧的AOF文件。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Redis是内存数据库，如果不做持久化，一旦服务器退出，就会丢失所有数据。因此redis提供了两种持久化方式用于持久化数据：RDB和AOF。本篇文章介绍AOF持久化方式。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习4-RDB持久化</title>
    <link href="https://eoccc.gitee.io/2023/07/05/redis%E5%AD%A6%E4%B9%A04-RDB%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    <id>https://eoccc.gitee.io/2023/07/05/redis%E5%AD%A6%E4%B9%A04-RDB%E6%8C%81%E4%B9%85%E5%8C%96/</id>
    <published>2023-07-05T03:32:23.000Z</published>
    <updated>2023-07-23T14:12:56.340Z</updated>
    
    <content type="html"><![CDATA[<p>Redis是内存数据库，如果不做持久化，一旦服务器退出，就会丢失所有数据。因此redis提供了两种持久化方式用于持久化数据：RDB和AOF。本篇文章介绍RDB持久化方式。</p><span id="more"></span><h1 id="rdb文件的生成和载入"><a class="markdownIt-Anchor" href="#rdb文件的生成和载入"></a> RDB文件的生成和载入</h1><p>RDB文件存储的是redis中的数据，Redis可以通过两个命令生成RDB文件：<code>SAVE</code> <code>BGSAVE</code></p><ul><li><p><code>SAVE</code>命令是<strong>阻塞</strong>式的。当执行<code>SAVE</code>命令时，所有的客户端请求都会被拒绝</p></li><li><p><code>BGSAVE</code>是<strong>并行</strong>的，redis会fork一个子进程来执行命令。另外需要注意：</p><p>在执行<code>BGSAVE</code>期间，redis会拒绝执行<code>SAVE</code>命令</p><p>在执行<code>BGSAVE</code>期间，redis会拒绝执行<code>BGSAVE</code>命令</p><p>在执行<code>BGSAVE</code>期间，客户端发送的<code>BGREWRITEAOF</code>命令会等到<code>BGSAVE</code>命令执行完后再执行</p><p>在执行<code>BGREWRITEAOF</code>期间，客户端发送的<code>BGSAVE</code>命令会被拒绝</p></li><li><p>RDB文件载入期间，redis服务器会一直处于阻塞状态</p></li><li><p>如果redis开启了AOF功能，会优先使用AOF文件来还愿数据</p></li></ul><h1 id="redis自动保存"><a class="markdownIt-Anchor" href="#redis自动保存"></a> Redis自动保存</h1><p>Redis允许用户配置save选项，让redis根据配置的规则自动执行<code>BGSAVE</code>持久化。redis每隔100毫秒就会检查一遍save条件是否满足，只要任一条件满足，就会进行持久化。</p><p>save规则可以配置多条（redis.conf）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1     //数据库在900秒内进行了1次修改</span><br><span class="line">save 300 10    //数据库在300秒内进行了10次修改</span><br><span class="line">save 60 100    //数据库在60秒内进行了100次修改</span><br></pre></td></tr></table></figure><p>RDB 的其他配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rdbconpression yes   //是否压缩rdb文件，建议不开启，会降低加载速度，磁盘不值钱</span><br><span class="line"></span><br><span class="line">dbfilename dump.rdb  // rdb文件的文件名</span><br><span class="line"></span><br><span class="line">dir  ./              // rdb文件的存储目录</span><br></pre></td></tr></table></figure><h2 id="bgsave的执行逻辑"><a class="markdownIt-Anchor" href="#bgsave的执行逻辑"></a> bgsave的执行逻辑</h2><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230716183642681.png" alt="image-20230716183642681" style="zoom:50%;"><ol><li><p>fork一个子进程</p><p>在redis中，主进程会维护一个页表，用于保存虚拟内存与物理内存的地址映射。bgsave fork子进程的时候，只需要创建一个子进程，然后将页表复制给子进程即可。</p></li><li><p>在持久化过程中，主进程也需要处理读写请求</p><p>由于子进程和主进程使用同一块物理内存，redis使用 copy-on-write 技术解决这一问题：</p><blockquote><ul><li>当主进程执行读操作的时候，可以使用共享内存</li><li>单主进程执行写操作的时候，会先把需要修改的数据拷贝一份，然后再执行写操作</li></ul></blockquote></li></ol><p><em>问题：在子进程进程持久化的过程中，如果发生了大量的写操作，会产生大量的数据拷贝，从未导致大量的内存占用。</em></p><h1 id="rdb文件结构"><a class="markdownIt-Anchor" href="#rdb文件结构"></a> RDB文件结构</h1><p>RDB文件结构图：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/Ra0t2kSg9.jpeg" alt="img/Ra0t2kSg9.jpeg" style="zoom:50%;"><ul><li>REDIS部分为一个固定值，保存老人&quot;REDIS&quot;的二进制码</li><li>db_version为一个长为4字节的整数，记录了RDB的版本号</li><li>database部分保存了0个或多个数据库，以及各个数据库中的键值对</li><li>EOF为一个长度为1字节的常量，标识RDB正文的结束位置</li><li>check_sum为一个8字节的无符号整数，由REDIS、db_version、database、EOF四个部分的内容计算得出，用于校验RDB文件的完整性</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;Redis是内存数据库，如果不做持久化，一旦服务器退出，就会丢失所有数据。因此redis提供了两种持久化方式用于持久化数据：RDB和AOF。本篇文章介绍RDB持久化方式。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习3-过期键清除策略</title>
    <link href="https://eoccc.gitee.io/2023/07/04/redis%E5%AD%A6%E4%B9%A03-%E8%BF%87%E6%9C%9F%E9%94%AE%E6%B8%85%E9%99%A4%E7%AD%96%E7%95%A5/"/>
    <id>https://eoccc.gitee.io/2023/07/04/redis%E5%AD%A6%E4%B9%A03-%E8%BF%87%E6%9C%9F%E9%94%AE%E6%B8%85%E9%99%A4%E7%AD%96%E7%95%A5/</id>
    <published>2023-07-04T06:21:43.000Z</published>
    <updated>2023-07-23T14:45:49.397Z</updated>
    
    <content type="html"><![CDATA[<p>Redis为了清除过期的键，采用了一定的策略进行清除。为了兼顾cpu占用和内存可用空间，redis对清除策略做了一些巧妙的设计。</p><span id="more"></span><h2 id="设置过期时间"><a class="markdownIt-Anchor" href="#设置过期时间"></a> 设置过期时间</h2><p>Redis可以通过以下四个命令对任意key设置过期时间：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">EXPIRE key seconds          // key将在seconds秒后过期</span><br><span class="line">PEXPIRE key millionSeconds  // key将在millionSeconds毫秒后过期</span><br><span class="line">EXPIREAT key timestamp      // key将在timestamp时过期，单位为秒</span><br><span class="line">PEXPIREAT key timestamp       // key将在timestamp时过期，单位为毫秒</span><br></pre></td></tr></table></figure><p>Redis的底层会将<code>EXPIRE</code> <code>PEXPIRE</code> <code>EXPIREAT</code>三个过期命令转换为<code>PEXPIREAT</code>命令来执行。</p><p>Redis使用一个expires字典保存了所有key的过期时间。字典的key为一个指针，指向了redis中的某一个键；字典的值为一个long类型的整数（对象共享，不会存在浪费空间），保存了这个键过期时间的毫秒级时间戳。</p><p>Redis可以使用以下命令计算或移出过期时间：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">TTL key       // 计算key还剩余多少生存时间，秒级</span><br><span class="line">PTTL key      // 计算key还剩余多少生存时间，毫秒级</span><br><span class="line">PERSIST key   // 移出key的过期时间</span><br></pre></td></tr></table></figure><h2 id="过期删除策略"><a class="markdownIt-Anchor" href="#过期删除策略"></a> 过期删除策略</h2><p>清除策略一般有三种：定时清除、惰性删除、定期删除</p><p><strong>定时清除：</strong> 通过使用定时器，定期清除过期的内存。过期的key过多的时候，会导致cpu占用高，进而导致吞吐量降低。</p><p><strong>惰性删除：</strong> 程序只有在取出key的时候才会进行过期检查，对cpu友好，但是对内存不友好。如果一个键一直不被访问，则即使过期也不会被删除。</p><p><strong>定期删除：</strong> 每隔一段时间执行一次删除动作。需要平衡清除周期和内存占用，清除周期短会导致cpu使用高，清除周期长会导致浪费内存。</p><p>Redis服务器采用了<strong>惰性删除策略</strong>和<strong>定期删除策略</strong>对过期键进行清除，在cpu占用率和避免浪费内存空间之间取得平衡。</p><h3 id="惰性删除策略"><a class="markdownIt-Anchor" href="#惰性删除策略"></a> 惰性删除策略</h3><p>在执行所有的读写操作之前，redis都会执行<code>expireIfNeed</code>方法，判断当前键是否过期。</p><blockquote><ul><li>如果过期，<code>expireIfNeed</code>方法会删除过期的键</li><li>如果没有过期，<code>expireIfNeed</code>不做任何操作</li></ul></blockquote><h3 id="定期删除策略"><a class="markdownIt-Anchor" href="#定期删除策略"></a> 定期删除策略</h3><p>redis会定期地执行<code>activExpireCycle</code>函数，在规定的时间内，从expires字典中随机抽取一定数量的键，检查其过期时间，并将过期的键删除。</p><p>redis默认的定期淘汰过期键策略：</p><blockquote><ol><li>redis每10秒执行一次过期检查</li><li>每次过期检查会从expires字典中随机抽取20个key进行检查</li><li>删除过期的key</li><li>如果删除的key超过25%，立即进行下一次过期检查</li></ol></blockquote><h2 id="aof-rdb和复制功能对过期键的处理"><a class="markdownIt-Anchor" href="#aof-rdb和复制功能对过期键的处理"></a> AOF、RDB和复制功能对过期键的处理</h2><h3 id="rdb对过期键的处理"><a class="markdownIt-Anchor" href="#rdb对过期键的处理"></a> RDB对过期键的处理</h3><p><strong>1. 生成RDB文件时：</strong> 通过<code>SAVE</code>或<code>BGSAVE</code>命令生成RDB文件时，redis会忽略过期的键。</p><p><strong>2. 载入RDB文件时：</strong> 如果redis以主服务器模式运行，会淘汰过期的键；如果以从服务器运行，会载入所有的键（从服务器同步数据库的时候，会先清空所有数据，所以载入所有的键对数据库不会有影响）。</p><h3 id="aof对过期键的处理"><a class="markdownIt-Anchor" href="#aof对过期键的处理"></a> AOF对过期键的处理</h3><p><strong>1. 写入AOF文件时：</strong> 如果一个键已经过期，但是还没有淘汰，AOF不会对这个过期键做任何处理，当过期键被删除后，会向AOF文件追加一条DEL命令，显式删除过期的键。</p><p><strong>1. 重写AOF文件时：</strong> redis会检查键的过期时间，过期的键不会被写入AOF文件。</p><h3 id="复制对过期键的处理"><a class="markdownIt-Anchor" href="#复制对过期键的处理"></a> 复制对过期键的处理</h3><p>当服务器在复制模式下运行时，从服务器删除过期键的操作由主服务器控制，由此保证数据的一致性：</p><ul><li>主服务器删除一个过期键之后，会向从服务器发送一条DEL命令，让从服务器删除过期键</li><li>从服务器在执行读命令时遇到过期键，不会删除过期键，而是像未过期键一样处理</li><li>从服务器只有接收到主服务器的DEL命令时，才会删除过期键</li></ul><h2 id="内存不足时的清除策略"><a class="markdownIt-Anchor" href="#内存不足时的清除策略"></a> 内存不足时的清除策略</h2><blockquote><ol><li>noeviction: 返回错误，并且客户端尝试执行，会让更多内存被使用</li><li>allkeys-lru: 尝试回收最少使用的键(LRU)</li><li>volatile-lru: 尝试回收最少使用的键(LRU)，但仅限于在过期集合的键</li><li>allkeys-random: 随机回收所有键</li><li>volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键</li><li>volatile-ttl: 回收在过期集合中的键，并且优先回收存活时间(TTL)较短的键</li><li>allkeys-lfu: 尝试回收最少使用频率的键(LFU)</li><li>volatile-lfu: 尝试回收最少使用频率的键(LFU)，但仅限于在过期集合的键</li></ol></blockquote><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230723224526012.png" alt="image-20230723224526012"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Redis为了清除过期的键，采用了一定的策略进行清除。为了兼顾cpu占用和内存可用空间，redis对清除策略做了一些巧妙的设计。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习2-五种数据类型实现</title>
    <link href="https://eoccc.gitee.io/2023/07/02/redis%E5%AD%A6%E4%B9%A02-%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AE%9E%E7%8E%B0/"/>
    <id>https://eoccc.gitee.io/2023/07/02/redis%E5%AD%A6%E4%B9%A02-%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AE%9E%E7%8E%B0/</id>
    <published>2023-07-02T10:25:19.000Z</published>
    <updated>2023-07-23T14:22:10.786Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍redis应用层的五种数据结构的实现：string、list、hash、set、zset。</p><span id="more"></span><h2 id="reisobject"><a class="markdownIt-Anchor" href="#reisobject"></a> reisObject</h2><p>上一节我们讲了redis的底层数据结构的实现，如简单动态字符串SDS、链表、字典、跳跃表、整数集合、压缩列表，但是redis并不是直接使用这些数据结构来实现键值对数据库，而是基于这些数据结构创建了一套数据对象，包含：String、List、Hash、Set、ZSet。这些对象由一个或多个redis基本数据结构实现。</p><p>每个对象里面包含了：</p><blockquote><ol><li>对象类型。redis会根据对象类型判断一个对象能否执行给定的命令</li><li>基于引用计数法实现垃圾回收</li><li>对象共享机制，节约内存</li><li>记录访问时间，实现LRU清除内存</li></ol></blockquote><p>redisObject的定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisObject</span> &#123;</span></span><br><span class="line">  <span class="type">unsigned</span> type:<span class="number">4</span>;      <span class="comment">// 类型: string,list,hash,set,zset</span></span><br><span class="line">  <span class="type">unsigned</span> encoding:<span class="number">4</span>;  <span class="comment">// 编码，即ptr指向的对象的编码类型（底层实现）</span></span><br><span class="line">  <span class="type">void</span> *ptr;            <span class="comment">// 指向底层实现数据结构的指针</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Redis五种对象类型的编码方式，可以使用<code>OBJECT ENCODING</code>命令查看，每个类型都使用了至少两种底层数据结构：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/JqcJckTu7_.jpeg" alt="img/JqcJckTu7_.jpeg" style="zoom:30%;"><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2022%2F0721%2F0568c246j00rfd48g0024c000m500qem.jpg&thumbnail=660x2147483647&quality=80&type=jpg" alt="img" style="zoom:75%;"><h2 id="1-string"><a class="markdownIt-Anchor" href="#1-string"></a> 1. String</h2><p>字符串的编码可以是int、embstr和raw。</p><blockquote><ul><li><p>如果一个字符串是整数值，且可以用long表示，那么redisObject的ptr存的是整数，编码为int</p><p>并且，如果数字的大小在LONG_MAX范围内，则不需要SDS，可以将数值直接保存在ptr指针的位置（刚好8字节）</p></li><li><p>如果一个字符串的长度小于44字节，那么编码方式为embstr</p></li><li><p>如果一个字符串的长度大于44字节，那么编码方式为raw</p></li></ul></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230723154646517.png" alt="image-20230723154646517" style="zoom:43%;"><p><strong>embstr和raw的区别：</strong> 两种编码方式都使用redisObject和sdshdr来存储，但是raw会调用两次内存分配，分别创建redisObject和sdshdr对象，而embstr编码只调用一次内存分配，申请一个<strong>连续的内存空间</strong>创建两个对象。</p><p>embstr的优点：</p><blockquote><ol><li>对象头和SDS使用一段连续的内存空间，只调用一次内存空间分配</li><li>embstr的内存只需要释放一次</li><li>embstr使用连续的内存空间，能够更好的利用缓存带来的优势</li></ol></blockquote><p><em>浮点数的存储：</em> 浮点数在redis中也是以字符串的形式存储，但是在有需要的时候，redis会将字符串转换为浮点数。</p><p><em>编码转换：</em> redis对字符串的操作可能会导致编码类型的转换，如执行<code>append</code>命令后，字符串的长度由小于44变成大于44字节，编码会由embstr变为raw。</p><h2 id="2-列表"><a class="markdownIt-Anchor" href="#2-列表"></a> 2. 列表</h2><p>列表的编码可以是压缩列表(ziplist)或链表(linkedlist)。</p><blockquote><ol><li>元素数量小于512个，且每个元素的长度小于64字节，使用压缩列表</li><li>任意一个条件不满足，编码会变为链表linkedList</li><li>两个阈值都可以配置：<code>list-max-ziplist-value</code>，<code>list-max-ziplist-entries</code></li></ol></blockquote><p><strong>基于ziplist实现列表：</strong></p><img src="https://gitee.com/eoccc/pic-shack/raw/master/X4ZibxXj2.jpeg" alt="img/bFSjZeUqZ.jpeg" style="zoom:57%;"><p><strong>基于linkedlist实现列表：</strong> 每个node都是一个StringObject。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/bFSjZeUqZ.jpeg" alt="img/bFSjZeUqZ.jpeg" style="zoom:57%;"><h2 id="3-哈希对象"><a class="markdownIt-Anchor" href="#3-哈希对象"></a> 3. 哈希对象</h2><p>哈希编码可以是压缩列表(ziplist)和字典(hashtable)。</p><blockquote><ol><li>当所有键值对的键和值的长度都小于64字节，且键值对个数小于512个时，使用ziplist实现</li><li>任一条件不满足时，使用hashtable实现</li><li>redis对键值对操作，导致以上条件不满足时，编码会变成hashtable</li><li>以上阈值可以配置：<code>hash-max-ziplist-value</code>，<code>hash-max-ziplist-entries</code></li></ol></blockquote><p>当通过ziplist实现哈希对象时，redis会将键和值对象依此压入压缩列表：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/s4vWvaesd.jpeg" alt="img/s4vWvaesd.jpeg" style="zoom:50%;"><p>当使用hashtable实现哈希对象时，键和值都是StringObject，保存在字典中：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/TteeZPrrT.jpeg" alt="img/TteeZPrrT.jpeg" style="zoom:43%;"><p><em>使用hash可以减少redis的内存占用，因为使用简单的key-value来存储，redis会为key和value都创建一个redisObject，redis的数据类型有很多，不同的数据类型都会有相同的元数据要存储（如编码方式、最后访问时间、被引用次数等），这些元数据会造成空间浪费。</em></p><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2022%2F0721%2F6259cb35j00rfd48g000bc000b7007ym.jpg&thumbnail=660x2147483647&quality=80&type=jpg" alt="img" style="zoom:60%;"><h2 id="4-set集合对象"><a class="markdownIt-Anchor" href="#4-set集合对象"></a> 4. Set集合对象</h2><p>集合对象通过intset或hashtable实现。</p><blockquote><ol><li>所有元素都为整数类型，且数量小于512个，使用intset实现</li><li>不满足任一条件，使用hashtable实现</li><li>redis操作导致不满足条件，编码由intset变成hashtable</li><li>以上阈值可以配置：<code>set-max-tset-tries</code></li></ol></blockquote><p><strong>使用intset实现集合对象的数据结构：</strong></p><img src="https://gitee.com/eoccc/pic-shack/raw/master/QYyoC4LIS.jpeg" alt="img/QYyoC4LIS.jpeg" style="zoom:50%;"><p><strong>使用hashtable实现集合对象的数据结构：</strong> 每个元素都保存在字典的key中，value为null。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/EY3MJnqtR.jpeg" alt="img/EY3MJnqtR.jpeg" style="zoom:43%;"><h2 id="5-zset有序集合"><a class="markdownIt-Anchor" href="#5-zset有序集合"></a> 5. ZSet有序集合</h2><p>有序集合对象通过ziplist或skiplist实现。</p><blockquote><ol><li>当所有键值对的键和值的长度都小于64字节，且键值对个数小于512个时，使用ziplist实现</li><li>任一条件不满足时，使用skiplist实现</li><li>redis对键值对操作，导致以上条件不满足时，编码会变成skiplist</li><li>以上阈值可以配置：<code>zset-max-ziplist-entries</code>和<code>zset-max-ziplist-value</code></li></ol></blockquote><p>当使用ziplist实现有序集合时，每个元素由两个ziplist元素组成，第一个保存元素成员，第二个保存元素分值，并且每个元素按分值由小到大排列：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230723164942510.png" alt="image-20230723164942510" style="zoom:45%;"><p>当有序集合编码为skiplist时，zset同时使用跳表和字典实现。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zset</span> &#123;</span></span><br><span class="line">    zskiplist *zsl;  <span class="comment">//跳表</span></span><br><span class="line">    dict *dict;      <span class="comment">//字典</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>zset的跳表中保存了集合的所有元素，并按分值由小到大排序。除此之外，zset还有一个字典，key保存了元素的值，value保存了元素的分值。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/k655yYYQ2S.jpeg" alt="img/k655yYYQ2S.jpeg" style="zoom:50%;">]]></content>
    
    
    <summary type="html">&lt;p&gt;本文介绍redis应用层的五种数据结构的实现：string、list、hash、set、zset。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习1-底层数据结构</title>
    <link href="https://eoccc.gitee.io/2023/07/01/redis%E5%AD%A6%E4%B9%A01-%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>https://eoccc.gitee.io/2023/07/01/redis%E5%AD%A6%E4%B9%A01-%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2023-07-01T10:25:19.000Z</published>
    <updated>2023-07-22T19:35:53.074Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍redis底层的数据结构，redis通过这些数据结构实现了业务层的五种数据结构：string、list、hash、set、zset。</p><span id="more"></span><h1 id="简单动态字符串"><a class="markdownIt-Anchor" href="#简单动态字符串"></a> 简单动态字符串</h1><p>Redis对简单动态字符串（Simple Dynamic String，SDS）的底层定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* flags字段对应的值 */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SDS_TYPE_5  0</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SDS_TYPE_8  1</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SDS_TYPE_16 2</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SDS_TYPE_32 3</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SDS_TYPE_64 4</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr8</span> &#123;</span></span><br><span class="line">    <span class="type">uint8_t</span> len; <span class="comment">/* 保存buf的长度，即SDS所保存的字符串的长度 */</span></span><br><span class="line">    <span class="type">uint8_t</span> alloc; <span class="comment">/* SDS申请的字节数，不包含header（除了buf的其他字段）和结束表示 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> flags; <span class="comment">/* SDS的类型，用来控制header的大小 */</span></span><br><span class="line">    <span class="type">char</span> buf[];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><img src="/.io//image-20230720014531357.png" alt="image-20230720014531357" style="zoom:43%;"><p><strong>SDS动态扩容</strong>，redis对SDS的内存做了优化：</p><blockquote><ol><li>空间预分配：SDS在free空间不够时进行扩容，并重新分配空间<br>扩容后SDS的长度小于1M时，SDS将为buf分配长度为len的未使用空间，分配后为: len+len+1<br>扩容后SDS的长度大于1M时，SDS将为buf分配长度为1M的未使用空间，分配后为: len+1M+1</li><li>惰性空间释放<br>SDS字符串变短时，并不马上缩短buf长度，而是通过free字段暂时保存着部分字节</li></ol></blockquote><p>SDS的优点：</p><blockquote><ol><li>SDS可以直接重用C字符串的一些库函数</li><li>获取字符串长度的复杂读为O(1)，而C字符串为O(N)</li><li>避免缓存溢出，sdscat函数在追加字符串之前会先检查是否有足够的空间</li><li>避免重新分配内存，由于C字符串没有记录长度，其buf长度为n+1，每次对字符串进行操作的时候都要重新分配内存</li><li>可以存储二进制信息</li></ol></blockquote><h1 id="intset"><a class="markdownIt-Anchor" href="#intset"></a> intset</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">intset</span> &#123;</span></span><br><span class="line">    <span class="type">uint32_t</span> encoding;  <span class="comment">/* 编码方式，支持存放16位（short）、32位（int）、64位（long）整数 */</span></span><br><span class="line">    <span class="type">uint32_t</span> length;    <span class="comment">/* 数组长度 */</span></span><br><span class="line">    <span class="type">int8_t</span> contents[];  <span class="comment">/* 保存元素 */</span></span><br><span class="line">&#125; intset;</span><br></pre></td></tr></table></figure><p>为了方便查找，Redis会将intset中所有的整数按照升序依次保存在contents数组中，结构如图:</p><img src="/.io//image-20230720015833546.png" alt="image-20230720015833546" style="zoom:45%;"><p><strong>intset升级</strong></p><p>由于intset内部的每一个元素的编码方式都是统一的，当新插入的数据超过原来编码方式的范围时，intset会把编码方式升级到合适的编码方式。同时将数组中已有的元素重新根据新的编码方式进行编码。</p><p><strong>注意：</strong></p><blockquote><ol><li>intset查找元素从小到大排列，采用的是二分查找算法</li><li>intset插入数据的时候需要先扩容空间</li><li>intset的数组使用的是连续的空间，插入和删除都会涉及内存空间的移动，当数组中的元素比较多的时候，性能会下降</li></ol></blockquote><h1 id="链表"><a class="markdownIt-Anchor" href="#链表"></a> 链表</h1><img src="https://gitee.com/eoccc/pic-shack/raw/master/bEcyFCzsQ.jpeg" alt="bEcyFCzsQ.jpeg" style="zoom:60%;"><p>在Redis中，链表应用于列表键、发布与订阅、慢查询、监视器。</p><ul><li>采用一个list来持有链表，包含链表长度等信息</li><li>链表的节点使用listNode来实现</li><li>是双向链表</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">list</span> &#123;</span> </span><br><span class="line">   listNode * head;</span><br><span class="line">   listNode * tail;</span><br><span class="line">   <span class="type">unsigned</span> <span class="type">long</span> len;   <span class="comment">// 链表所包含的节点数量</span></span><br><span class="line">   ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> &#123;</span> </span><br><span class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> * <span class="title">prev</span>;</span>    <span class="comment">// 前置节点</span></span><br><span class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> * <span class="title">next</span>;</span>    <span class="comment">// 后置节点</span></span><br><span class="line">   <span class="type">void</span> * value;       <span class="comment">// 节点的值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="压缩列表"><a class="markdownIt-Anchor" href="#压缩列表"></a> 压缩列表</h1><p>压缩列表是为了节约内存而开发的顺序型数据结构。列表键或哈希键只包含少量元素，且每项都是小整数或较短的字符串时，会使用压缩列表ziplist。</p><blockquote><ul><li>zlbytes：4字节，记录压缩列表占用的字节数</li><li>zltail：4字节，记录压缩列表的尾节点距离起始地址的偏移量</li><li>zllen：2字节，记录压缩列表包括的节点数量</li><li>entryX：列表节点</li><li>zlend：1字节，特殊值 0xFF(255)，标识压缩列表的末端</li></ul></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/_fpaLdih4.jpeg" alt="_fpaLdih4.jpeg" style="zoom:60%;"><p><strong>压缩列表节点：</strong></p><blockquote><ul><li><p>previous_entry_length：前一个节点的长度</p><p>如果前一个节点的长度小于254字节：previous_entry_length属性的长度为1字节</p><p>如果前一个节点的长度大于等于254字节：previous_entry_length属性的长度为5字节</p></li><li><p>encoding：保存的数据的数据类型及长度</p></li><li><p>content：字节数组或整数</p></li></ul></blockquote><img src="/.io//wCRzeEOjR.jpeg" alt="img/wCRzeEOjR.jpeg" style="zoom:70%;"><p>通过前一节点长度我们可以从任意位置遍历列表（可能是1字节，可能是5字节，比较trick的技巧），编码由编码前两位决定编码长度，content记录内容；</p><p><strong>压缩列表连锁更新：</strong></p><blockquote><ul><li>删除或新增节点，当新=entry的previous_entry_length节点的字节数与原来这个位置的entry的不一致时， 会导致后面所有entry的previous_entry_length也发生变化，从而造成连锁更新；</li><li>连锁更新的性能虽然比较差，但是出现的几率很小</li></ul></blockquote><h1 id="quicklist"><a class="markdownIt-Anchor" href="#quicklist"></a> quicklist</h1><p>ZipList虽然比较节省内存，但是当元素过多时，会影响效率。Redis采用分片的方式来解决这一问题。</p><p><strong>quicklist</strong>是3.2版本引入的一个新的数据结构，是ziplist和 linkedlist 的组合，它将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230723032028196.png" alt="image-20230723032028196" style="zoom:43%;"><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklist</span> &#123;</span></span><br><span class="line">    quicklistNode *head;</span><br><span class="line">    quicklistNode *tail;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> count;        <span class="comment">/* total count of all entries in all listpacks */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> len;          <span class="comment">/* number of quicklistNodes */</span></span><br><span class="line">    <span class="type">signed</span> <span class="type">int</span> fill : QL_FILL_BITS;       <span class="comment">/* fill factor for individual nodes */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> compress : QL_COMP_BITS; <span class="comment">/* depth of end nodes not to compress;0=off */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> bookmark_count: QL_BM_BITS;</span><br><span class="line">    quicklistBookmark bookmarks[];</span><br><span class="line">&#125; quicklist;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">prev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">next</span>;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *entry;</span><br><span class="line">    <span class="type">size_t</span> sz;             <span class="comment">/* entry size in bytes */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> count : <span class="number">16</span>;     <span class="comment">/* count of items in listpack */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> encoding : <span class="number">2</span>;   <span class="comment">/* RAW==1 or LZF==2 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> container : <span class="number">2</span>;  <span class="comment">/* PLAIN==1 or PACKED==2 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> recompress : <span class="number">1</span>; <span class="comment">/* was this node previous compressed? */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> attempted_compress : <span class="number">1</span>; <span class="comment">/* node can&#x27;t compress; too small */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> dont_compress : <span class="number">1</span>; <span class="comment">/* prevent compression of entry that will be used later */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> extra : <span class="number">9</span>; <span class="comment">/* more bits to steal for future usage */</span></span><br><span class="line">&#125; quicklistNode;</span><br></pre></td></tr></table></figure><p>为了避免QuickList中的每个ZipList中entry过多，Redis提供了一个配置项: <code>list-max-ziplist-size</code>来限制。</p><p>如果值为正，则代表ZipList的允许的entry个数的最大值</p><p>如果值为负，则代表ZipList的最大内存大小，分5种情况：</p><blockquote><p>-1： 每个ZipList的内存占用不能超过4kb</p><p>-2：每个ZipList的内存占用不能超过8kb（默认）</p><p>-3：每个zipList的内存占用不能超过16kb</p><p>-4：每个ZipList的内存占用不能超过32kb</p><p>-5：每个ZipList的内存占用不能超过64kb</p></blockquote><p>除了控制ZipList的大小，QuickList还可以对节点的ZipList做压缩。通过配置项<code>list-compress-depth</code>来控制。因为链表般都是从首尾访问较多，所以首尾是不压缩的。这个参数是控制首尾不压缩的节点个数:</p><blockquote><p>0：特殊值，代表不压缩</p><p>1：首尾各有1个节点不压缩，中间节点压缩</p><p>2：首尾各有2个节点不压缩，中间节点压缩以此类推</p><p>3：以此类推</p></blockquote><h1 id="字典"><a class="markdownIt-Anchor" href="#字典"></a> 字典</h1><p>字典由3层数据结构组成：<code>dict</code>，<code>dictht</code>，<code>dictEntry</code></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dict</span> &#123;</span></span><br><span class="line">  dictType *type;  <span class="comment">// 用于操作特定类型键值对的函数</span></span><br><span class="line">  <span class="type">void</span> *privdata;  <span class="comment">// 需要传给指定函数的可选参数</span></span><br><span class="line">  dictht ht[<span class="number">2</span>];    <span class="comment">// 保存了两个dictht的数组，这两个数组用于rehash</span></span><br><span class="line">  <span class="type">int</span> rehashidx;   <span class="comment">// rehash索引，-1:没有在rehash，0:开始rehash，&gt;0:当前rehash进度</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span> &#123;</span></span><br><span class="line">  dictEntry **table;       <span class="comment">// 哈希表数组</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">long</span> size;      <span class="comment">// 哈希表大小</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">long</span> sizemask;  <span class="comment">// 哈希表大小掩码，用于计算索引值，总是等于size-1</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">long</span> used;      <span class="comment">// 该哈希表已用节点的数量</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> &#123;</span></span><br><span class="line">    <span class="type">void</span> *key;    <span class="comment">// 键</span></span><br><span class="line">    <span class="class"><span class="keyword">union</span>&#123;</span>        <span class="comment">// 值</span></span><br><span class="line">        <span class="type">void</span> *val;</span><br><span class="line">        uint64_tu64;</span><br><span class="line">        int64_ts64;</span><br><span class="line">    &#125; v;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> *<span class="title">next</span>;</span> <span class="comment">// 指向下个哈希表节点，形成链表</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>hash冲突：</strong> 与HashMap的实现类似，数组用于保存键值对节点，当发生冲突时，采用链表法解决冲突</p><p><strong>rehash：</strong> 负载因子 = <code>ht[0].used</code> / <code>ht[0].size</code></p><blockquote><ol><li>服务器<strong>没有执行</strong><code>BGSAVE</code>或<code>BGREWRITEAOF</code>命令，负载因子大于等于1时，进行扩容为原来的2倍</li><li>服务器<strong>正在执行</strong><code>BGSAVE</code>或<code>BGREWRITEAOF</code>命令，负载因子大于等于5时，进行扩容为原来的2倍</li><li>负载因子小于0.1时，进行缩容为原来的1/2</li></ol></blockquote><p><strong>渐进式rehash：</strong> 程序对字典中的key进行添加、查找、删除、更新等操作时，程序会将相应dictEntry上的所有键值对rehash到<code>ht[1]</code>，rehashidx自增1。<code>ht[0]</code>上的所有键值对都rehash到<code>ht[1]</code>上时，将rehashidx置为-1。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/1P3MUzEsz.jpeg" alt="1P3MUzEsz.jpeg" style="zoom:50%;"><h1 id="跳跃表"><a class="markdownIt-Anchor" href="#跳跃表"></a> 跳跃表</h1><p>跳跃表支持平均O(logN)，最差O(N)的复杂度 ，并且可以实现顺序操作。查询效率可以和平衡树媲美，并且实现更简单，所以不少程序使用跳跃表代替平衡树。</p><blockquote><ol><li>redis采用跳跃表作为有序集合<code>zset</code>的底层实现之一；</li><li>跳跃表由<code>zskiplist</code>和<code>zskiplistNode</code>组成。<code>zskiplist</code>用于保存跳跃表的信息，如头节点、尾节点、长度、层高；<code>zskiplistNode</code>保存跳跃表的节点</li><li>每个跳跃表节点的层高都是1至32的随机数（每个节点可以有1～32个指针）</li><li>多个节点的分值可以相同，但是一个节点的分值永远一致</li><li>节点按score由小到大排序，score相同时按成员对象由小到大排序</li></ol></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/O8pUbHusi.jpeg" alt="O8pUbHusi.jpeg" style="zoom:57%;">]]></content>
    
    
    <summary type="html">&lt;p&gt;本文介绍redis底层的数据结构，redis通过这些数据结构实现了业务层的五种数据结构：string、list、hash、set、zset。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Mysql-主从复制</title>
    <link href="https://eoccc.gitee.io/2023/06/26/Mysql-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    <id>https://eoccc.gitee.io/2023/06/26/Mysql-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</id>
    <published>2023-06-26T08:25:19.000Z</published>
    <updated>2023-07-13T17:33:22.729Z</updated>
    
    <content type="html"><![CDATA[<p>主从复制是指将主数据库的DDL和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行(也叫重做)，从而<br>使得从库和主库的数据保持同步。</p><span id="more"></span><p>MySQL支持一台主库同时向多台从库进行复制，从库同时也可以作为其他从服务器的主库，实现链状复制。</p><p><strong>主从复制的用途：</strong></p><blockquote><ol><li>主库出现问题，可以快速切换到从库提供服务</li><li>实现读写分离，降低主库的访问压力</li><li>可以在从库中执行备份，以避免备份期间影响主库服务</li></ol></blockquote><p><strong>主从复制的原理：</strong></p><blockquote><ol><li>Master 主库在事务提交时、会把数据变更记录在二进制日志文件 Binlog 中</li><li>从库读取主库的二进制日志文件 Binlog ，写入到从库的中继日志 Relay Log</li><li>slave重做中继日志中的事件，将记录的变化同步到自己的库中</li></ol></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230714012230317.png" alt="image-20230714012230317" style="zoom:50%;"><p><strong>双主双从</strong></p><blockquote><p>一个主机Master1 用于处理所有写请求，它的从机 Slave1 和另一台主机Master2 还有它的从机 Slave2 负责所有读请求。当Master1主机宕机后，Master2 主机负责写请求，Master1 、Master2 互为备机。架构图如下:</p></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230714013258708.png" alt="image-20230714013258708" style="zoom:50%;">]]></content>
    
    
    <summary type="html">&lt;p&gt;主从复制是指将主数据库的DDL和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行(也叫重做)，从而&lt;br&gt;
使得从库和主库的数据保持同步。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Mysql-事务原理</title>
    <link href="https://eoccc.gitee.io/2023/06/24/Mysql-%E4%BA%8B%E5%8A%A1%E5%8E%9F%E7%90%86/"/>
    <id>https://eoccc.gitee.io/2023/06/24/Mysql-%E4%BA%8B%E5%8A%A1%E5%8E%9F%E7%90%86/</id>
    <published>2023-06-24T08:25:19.000Z</published>
    <updated>2023-07-12T18:53:24.360Z</updated>
    
    <content type="html"><![CDATA[<p>事务是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作<br>要么同时成功，要么同时失败。</p><span id="more"></span><h1 id="事务的特性"><a class="markdownIt-Anchor" href="#事务的特性"></a> 事务的特性</h1><blockquote><p>Atomic（原子性）：事务中的操作，要么都成功，都失败</p><p>Consistency（一致性）：数据从一个正确的状态到另一个正确的状态</p><p>Isolation（隔离性）：事务之间互相影响，保证同时执行的事务互相之间没有干扰</p><p>Durability（持久性）：存到磁盘中，即使机器断电，数据还是有的</p></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230713010333701.png" alt="image-20230713010333701" style="zoom:45%;"><h2 id="持久性的实现原理"><a class="markdownIt-Anchor" href="#持久性的实现原理"></a> 持久性的实现原理</h2><p><strong>Redo Log</strong></p><blockquote><p>重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。</p><p>该日志文件由两部分组成：<strong>重做日志缓冲</strong>(redo log buffer)以及<strong>重做日志文件</strong>(redo log file)。前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中，用于在刷新脏页到磁盘发生错误时进行数据恢复使用。</p></blockquote><p>当提交一个事务时，Mysql会先将事务对记录的修改缓存在Buffer Pool中，然后以一定的频率刷到磁盘。当服务器发生错误的时候，会导致Buffer Pool中的脏页没有刷到磁盘，造成更新丢失。</p><p>在InnoDB中，有两个参数可以控制redo log的刷新频率：</p><blockquote><ol><li>innodb_log_buffer_size：指定redo log缓冲池的大小。当缓冲池中的数据达到一定量时，就会触发刷新操作</li><li>innodb_flush_log_at_trx_commit：指定redo log的刷新策略。有三个可选值：<ul><li>0：表示不进行redo log的刷新操作，性能最高，但是可能会丢失一定量的数据；</li><li>1：表示每次提交事务都会将redo log缓冲池中的数据刷新到磁盘上（默认值），保证数据的持久性，但是性能相对较低；</li><li>2：表示每次提交事务时，只将redo log缓冲池中的数据写入操作系统缓存中，然后由操作系统异步刷新到磁盘上。这个选项可以提高性能，但是可能会丢失一些数据。</li></ul></li></ol></blockquote><p>为了解决这个问题，Mysql提交一个事务时，同时会把事务造成的数据变化缓存在Redolog Buffer中，然后刷到redolog文件中。当系统发生错误的时候，可以从redolog中恢复记录（当刷新策略配置为1时，最多丢失一条记录）。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230713010827085.png" alt="image-20230713010827085" style="zoom:50%;"><h2 id="原子性和一致性的实现原理"><a class="markdownIt-Anchor" href="#原子性和一致性的实现原理"></a> 原子性和一致性的实现原理</h2><p><strong>Undo log</strong></p><blockquote><p>回滚日志，用于记录数据被修改前的信息，作用包含两个：<strong>回滚</strong> 和 <strong>MVCC</strong>（多版本并发控制）</p><p>undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。</p><p>Undo log销毁：undo log在事务执行时产生，事务提交时，并不会立即删除undo log，因为这些日志可能还用于MVCC</p><p>Undo log存储：undo log采用段的方式进行管理和记录，存放在 rolback segment 回滚段中，内部包含1024个undo log segment</p></blockquote><h2 id="mvcc"><a class="markdownIt-Anchor" href="#mvcc"></a> MVCC</h2><p>MVCC实现了事务的隔离性。指维护一个数据的多个版本，使得读写操作没有冲突。MVCC的具体实现，还需要依赖于数据库记录中的三个隐式字段、undo log日志、readView。</p><table><thead><tr><th style="text-align:center">隔离级别</th><th style="text-align:center">脏读</th><th style="text-align:center">不可重复读</th><th style="text-align:center">幻读</th><th>描述</th></tr></thead><tbody><tr><td style="text-align:center">Read Uncommitted</td><td style="text-align:center">y</td><td style="text-align:center">y</td><td style="text-align:center">y</td><td>一个事务可以读取另一个未提交事务的数据</td></tr><tr><td style="text-align:center">Read Committed</td><td style="text-align:center"></td><td style="text-align:center">y</td><td style="text-align:center">y</td><td>一个事务可以读到另一个事务提交后的数据</td></tr><tr><td style="text-align:center">Repeatable Read</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">y</td><td>innoDB默认，在一个事务中多次读取的数据保持一致</td></tr><tr><td style="text-align:center">Serializable</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>事务串行化顺序执行，每次读取数据都会加锁，效率低下</td></tr></tbody></table><blockquote><p><strong>更新丢失:</strong> 两个事务同时更新一行数据，最后一个事务的更新会覆盖掉第一个事务的更新，从而导致第一个事务更新的数据丢失，这是由于没有加锁造成的；<br><strong>脏读:</strong> 事务读取尚未提交的数据;<br><strong>不可重复读:</strong> 更新行导致，在同一事务中，两次读取同一数据，得到内容不同，也就是有其他事务更改了这些数据<br><strong>幻读:</strong> 插入行导致，一个事务在执行过程中读取到了另一个事务已提交的插入数据。</p></blockquote><h3 id="隐式字段"><a class="markdownIt-Anchor" href="#隐式字段"></a> 隐式字段</h3><p>InnoDB在创建字段时，除了我们显式指定的字段，还会为我们添加三个隐式的字段：</p><table><thead><tr><th style="text-align:center">隐式字段</th><th>作用</th></tr></thead><tbody><tr><td style="text-align:center">DB_TRX_ID</td><td>保存最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID</td></tr><tr><td style="text-align:center">DB_ROLL_PTR</td><td>回滚指针，指向这条记录的上一个版本，用于配合undo log，指向上一个版本</td></tr><tr><td style="text-align:center">DB_ROW_ID</td><td>隐藏主键，如果表结构没有指定主键，将会生成该隐藏字段</td></tr></tbody></table><h3 id="undo-log在mvcc中的作用"><a class="markdownIt-Anchor" href="#undo-log在mvcc中的作用"></a> Undo Log在MVCC中的作用</h3><p>回滚日志，在insert、update、delete的时候产生的便于数据回滚的日志。<br>当insert的时候，产生的undo log日志只在回滚时需要，在事务提交后，可被立即删除。<br>而update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读时也需要，不会立即被删除。</p><p>不同事务或相同事务对同一条记录进行修改，会导致该记录的undo log生成一条记录版本链表，链表的头部是最新的旧记录，链表尾部是最早的旧记录：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230713015125895.png" alt="image-20230713015125895" style="zoom:50%;"><h3 id="read-view在mvcc中的作用"><a class="markdownIt-Anchor" href="#read-view在mvcc中的作用"></a> Read View在MVCC中的作用</h3><p>ReadView (读视图)是 快照读时MVCC提取数据的依据，记录并维护系统当前活跃的事务(未提交的) id。<br>ReadView中包含了四个核心字段:</p><table><thead><tr><th>字段</th><th>含义</th></tr></thead><tbody><tr><td>m_ids</td><td>当前活跃的事务ID集合</td></tr><tr><td>min_trx_id</td><td>当前活跃的最小活跃事务ID</td></tr><tr><td>max_trx_id</td><td>预分配事务ID，当前最大事务ID+1（因为事务ID是自增的）</td></tr><tr><td>creator_trx_id</td><td>ReadView创建者的事务ID</td></tr></tbody></table><p>当隔离级别是RC时，版本数据链的访问规则（当前事务ID：trx_id）：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230713025127081.png" alt="image-20230713025127081" style="zoom:48%;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A[版本数据链的访问规则]--&gt;B[trx_id == creator_trx_id]</span><br><span class="line">B--&gt;E[可以访问--说明这个版本的数据是当前事务修改的]</span><br><span class="line">A--&gt;C[trx_id &lt; min_trx_id]</span><br><span class="line">C--&gt;F[可以访问--说明这个版本已经提交了]</span><br><span class="line">A--&gt;D[trx_id &gt; max_trx_id]</span><br><span class="line">D--&gt;G[不可以访问--说明这个事务还没提交]</span><br><span class="line">A--&gt;H[min_trx_id &lt;= trx_id &lt;= max_trx_id]</span><br><span class="line">H--&gt;I[trx_id在m_ids集合中]</span><br><span class="line">I--&gt;K[不可以访问--说明这个事务还处于活跃状态没提交]</span><br><span class="line">H--&gt;J[trx_id不在m_ids集合中]</span><br><span class="line">J--&gt;L[可以访问--说明这个事务已提交]</span><br></pre></td></tr></table></figure><h3 id="rc隔离级别的原理"><a class="markdownIt-Anchor" href="#rc隔离级别的原理"></a> RC隔离级别的原理</h3><p>每次执行快照读都会生成一个readview。</p><h3 id="rr隔离级别的原理"><a class="markdownIt-Anchor" href="#rr隔离级别的原理"></a> RR隔离级别的原理</h3><ul><li><p>仅第一次执行快照读时生成一个readview，后续复用readview。</p></li><li><p>使用间隙锁/临键锁防止产生不可重复读：</p><blockquote><ol><li><p>索引上的等值查询（唯一索引），给不存在的记录加锁时，优化为间隙锁</p><p>因为索引不存在，索引只能加间隙锁，防止在事务执行过程中其他事务插入索引相同的记录</p></li><li><p>索引上的等值查询（普通索引），向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁</p><p>因为普通索引是非唯一索引，如果查数据的时候另一个事务插入了一条索引一样的数据，就会产生幻读</p></li><li><p>索引上的范围查询（唯一索引），会访问到不满足条件的第一个值为止</p></li></ol></blockquote></li></ul><p>注意：间隙锁唯一目的是防止其他事务插入间隙。间隙锁可以共存，一个事务采用的间隙锁不会阻止另一个事务在同一间隙上加间隙锁。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;事务是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作&lt;br&gt;
要么同时成功，要么同时失败。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Mysql- SQL优化</title>
    <link href="https://eoccc.gitee.io/2023/06/23/Mysql-SQL%E4%BC%98%E5%8C%96/"/>
    <id>https://eoccc.gitee.io/2023/06/23/Mysql-SQL%E4%BC%98%E5%8C%96/</id>
    <published>2023-06-23T08:25:19.000Z</published>
    <updated>2023-07-12T19:08:45.843Z</updated>
    
    <content type="html"><![CDATA[<p>数据库insert、order by、group by、limit、count、update操作的优化。</p><span id="more"></span><h1 id="插入优化"><a class="markdownIt-Anchor" href="#插入优化"></a> 插入优化</h1><h2 id="插入"><a class="markdownIt-Anchor" href="#插入"></a> 插入</h2><p><strong>批量插入</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> table_name <span class="keyword">values</span> (<span class="number">1</span>, col) (<span class="number">2</span>, col);</span><br></pre></td></tr></table></figure><p><strong>手动提交事务</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">start</span> transaction;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> table_name <span class="keyword">values</span> (<span class="number">1</span>, col) (<span class="number">2</span>, col);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> table_name <span class="keyword">values</span> (<span class="number">3</span>, col);</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure><p><strong>主键顺序插入</strong></p><p>按照主键顺序插入，效率会比乱序插入高。如果是乱序插入的，会导致页分裂，以及页之间的指针重排。</p><p><strong>大批量插入数据</strong></p><p>如果一次性插入大批量数据，使用insert插入的性能较低，可以使用load指令进行插入。</p><ol><li><p>连接数据库时加上参数 --local-infile</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql <span class="comment">--local-infile -u root -p</span></span><br></pre></td></tr></table></figure></li><li><p>打开加载文件开关（默认关闭）</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> <span class="keyword">local</span><span class="operator">-</span>infile<span class="operator">=</span><span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p>执行load指令</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> infile <span class="string">&#x27;file_path&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> <span class="string">&#x27;table_name&#x27;</span> fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span>;</span><br></pre></td></tr></table></figure></li></ol><h2 id="页分裂"><a class="markdownIt-Anchor" href="#页分裂"></a> 页分裂</h2><p>乱序插入会导致主键索引页分裂。</p><p>如下图，当需要插入新的数据50的时候：</p><ol><li><p>50需要插入到23之后，但是由于page1已经满了，所以需要申请一个新的page3</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230702172225136-8289876.png" alt="image-20230702172225136"></p></li><li><p>将23和47移动到page3，然后把50插入到23之后<br><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230702172612547-20230702172813631.png" alt="image-20230702172612547"></p></li><li><p>将page3移动到page1和page2之间（设置指针即可）</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230702172932009.png" alt="image-20230702172932009"></p></li></ol><h2 id="页合并"><a class="markdownIt-Anchor" href="#页合并"></a> 页合并</h2><p>当删除一行记录时，innodb会将这行记录标记为删除状态，当删除的记录占用的空间达到<code>MERGE_THRESHOLD</code> （默认为50%）时，会查尝试将附近的页合并，以优化空间使用。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230702173309657.png" alt="image-20230702173309657"></p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230702173616680.png" alt="image-20230702173616680"></p><h1 id="主键的优化"><a class="markdownIt-Anchor" href="#主键的优化"></a> 主键的优化</h1><ol><li>尽量降低主键的长度</li><li>插入数据时，尽量顺序插入（使用自增主键）</li><li>尽量不要使用UUID或其他自然主键，如身份证号（因为这些主键是乱序的，而且比较长）</li><li>业务操作时，尽量不要修改主键</li></ol><h1 id="order-by-优化"><a class="markdownIt-Anchor" href="#order-by-优化"></a> order by 优化</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">order</span> <span class="keyword">by</span> age;</span><br></pre></td></tr></table></figure><ul><li><p>Using filesort：不直接通过索引返回排序结果的排序。通过索引或全表扫描，读取满足条件的记录，然后在排序缓冲区sort buffer中排序。</p></li><li><p>Using index：通过有序索引顺序扫描直接返回有序记录，不需要额外排序。</p></li></ul><ol><li><p>如果索引没有覆盖排序字段，会回表查询，使用filesort排序</p></li><li><p>如果我们通过多个字断进行排序，而且排序方式不一样，会导致不使用索引：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> name,phone,age <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">order</span> <span class="keyword">by</span> phone <span class="keyword">asc</span>, age <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><p>我们可以对需要排序的字断以及排序方式建立索引：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> index idx_phone_age <span class="keyword">user</span>(phone <span class="keyword">asc</span>, age <span class="keyword">desc</span>);</span><br></pre></td></tr></table></figure></li></ol><p>总结：</p><blockquote><ol><li>根据排序字段建立合适的索引，多字段排序时，遵循最左前缀原则</li><li>使用覆盖索引</li><li>多字段排序时，一个升序一个降序，创建联合索引时制定排序规则</li><li>不可避免filesort时，可以适当增大排序缓冲区sort_buffer_size（默认256kb）</li></ol></blockquote><h1 id="group-by-优化"><a class="markdownIt-Anchor" href="#group-by-优化"></a> group by 优化</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">User</span> <span class="keyword">group</span> <span class="keyword">by</span> age;</span><br></pre></td></tr></table></figure><p>Using index：使用索引进行分组</p><p>Using temporary：使用临时表进行分组。</p><blockquote><ol><li>进行分组操作时，使用索引提高效率</li><li>通过多字段进行分组时，遵循最左前缀原则</li></ol></blockquote><h1 id="limt-优化"><a class="markdownIt-Anchor" href="#limt-优化"></a> limt 优化</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tb_sku limit <span class="number">100000</span>, <span class="number">10</span>;</span><br></pre></td></tr></table></figure><p>当表的数据量比较大了，对越靠后的记录进行limt操作时，效率越低。</p><p>通过覆盖索引 + 子查询进行优化：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> s.<span class="operator">*</span> form tb_sku s, (<span class="keyword">select</span> id <span class="keyword">from</span> tb_sku limit <span class="number">100000</span>, <span class="number">10</span>) a <span class="keyword">where</span> s.id<span class="operator">=</span>a.id;</span><br></pre></td></tr></table></figure><h1 id="count-优化"><a class="markdownIt-Anchor" href="#count-优化"></a> count 优化</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> tb_sku;</span><br></pre></td></tr></table></figure><ul><li>MyIsam 记录了表的总行数，可以直接返回</li><li>InnoDb 需要查询所有记录，进行计数</li></ul><p>优化：自己计数，如在redis中自己维护一个计数。</p><h1 id="update-优化"><a class="markdownIt-Anchor" href="#update-优化"></a> update 优化</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> age<span class="operator">=</span><span class="number">20</span> <span class="keyword">where</span> name<span class="operator">=</span><span class="string">&#x27;小明&#x27;</span>;</span><br></pre></td></tr></table></figure><p>如果where后面的条件没有使用索引，innodb会锁住整个表。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;数据库insert、order by、group by、limit、count、update操作的优化。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Mysql-架构</title>
    <link href="https://eoccc.gitee.io/2023/06/20/Mysql-%E6%9E%B6%E6%9E%84/"/>
    <id>https://eoccc.gitee.io/2023/06/20/Mysql-%E6%9E%B6%E6%9E%84/</id>
    <published>2023-06-20T08:25:19.000Z</published>
    <updated>2023-07-12T19:09:09.960Z</updated>
    
    <content type="html"><![CDATA[<p>Mysql架构：组件、内存、磁盘、后台线程。</p><span id="more"></span><h1 id="系统组件"><a class="markdownIt-Anchor" href="#系统组件"></a> 系统组件</h1><img src="https://gitee.com/eoccc/pic-shack/raw/master/28d0034482b249a98168aed306faae72.png" alt="28d0034482b249a98168aed306faae72.png" style="zoom:50%;"><p>上来先看Mysql架构图（摘自《MySQL技术内幕 InnoDB存储引擎》）。Mysql主要包括以下组件：</p><blockquote><ol><li>连接器 Connectors</li><li>系统管理&amp;控制工具</li><li>连接池</li><li>Sql接口</li><li>Sql解释器</li><li>Sql优化器</li><li>缓存池</li><li>存储引擎</li><li>文件系统</li></ol></blockquote><p>接下来介绍一下每个组件的简要功能，由于每个组件都可以展开讲很多，这篇文章只会对组件做一个简要的描述，有一个简单的概念。</p><h2 id="连接器connectors"><a class="markdownIt-Anchor" href="#连接器connectors"></a> 连接器(Connectors)</h2><blockquote><p>Connectors组件是Mysql向外提供的交互组件，支持多种语言与Mysql的交互，如java, .net, php等。</p></blockquote><h2 id="系统管理控制工具management-service-utilities"><a class="markdownIt-Anchor" href="#系统管理控制工具management-service-utilities"></a> 系统管理&amp;控制工具(Management Service &amp; Utilities)</h2><blockquote><p>提供对Mysql的集成管理，如备份与恢复、安全管理、集群、配置等。</p></blockquote><h2 id="连接池connection-pool"><a class="markdownIt-Anchor" href="#连接池connection-pool"></a> 连接池(Connection Pool)</h2><blockquote><p>负责监听对客户端向Mysql Server端的各种请求，接收请求，转发请求到目标模块。Mysql会为每个成功连接Mysql Server的客户端创建或分配一个线程，该线程负责客户端与Mysql Server端的通信，接收客户端发送的命令，传递服务端的结果信息等。<br><font color="red">想必大家都听说过数据库连接数过多，就是会导致连接池不够用，造成拒绝。</font><br>查看及设置最大连接数：</p> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;%max_connections%&#x27;</span>;</span><br><span class="line"><span class="keyword">set</span> <span class="keyword">GLOBAL</span> max_connections<span class="operator">=</span><span class="number">500</span>;  <span class="operator">/</span><span class="operator">/</span>重启后失效</span><br></pre></td></tr></table></figure><p>通过配置文件修改最大连接数：my.conf -&gt; <code>max_connections=512</code><br>连接数不能过大，因为Mysql会为每个连接提供连接缓冲区。</p></blockquote><h2 id="sql接口sql-interface"><a class="markdownIt-Anchor" href="#sql接口sql-interface"></a> SQL接口(SQL Interface)</h2><blockquote><p>接受用户的sql命令，如DML、DDL、存储过程等，并且返回用户需要查询的结果。</p></blockquote><h2 id="sql解释器parser"><a class="markdownIt-Anchor" href="#sql解释器parser"></a> SQL解释器(Parser)</h2><blockquote><p>分析SQL命令语法的合法性，并尝试将sql命令分解成数据结构，若解析失败，则提示SQL语句不合法。主要功能是将sql语句分解成数据结构，并将这个结构传递到后续步骤，以后SQL语句的传递和处理就是基于这个结构的。</p></blockquote><h2 id="sql优化器optimizer"><a class="markdownIt-Anchor" href="#sql优化器optimizer"></a> SQL优化器(Optimizer)</h2><blockquote><p>查询优化器，SQL语句在查询之前会使用查询优化器对查询进行优化。他使用的是“选取-投影-联接”策略进行查询</p></blockquote><h2 id="缓冲池caches-buffers"><a class="markdownIt-Anchor" href="#缓冲池caches-buffers"></a> 缓冲池(Caches &amp; Buffers)</h2><blockquote><p>查询缓存，如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。通过LRU算法将数据的冷端溢出，未来得及刷新到磁盘的数据页，叫脏页。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等。</p></blockquote><h2 id="存储引擎pluggable-storage-engines"><a class="markdownIt-Anchor" href="#存储引擎pluggable-storage-engines"></a> 存储引擎(Pluggable Storage Engines)</h2><blockquote><p>插件式存储引擎。提供各种存储引擎，真正的负责MySQL中数据的存储和提取。<br>Mysql支持的存储引擎：InnoDB、MyISAM、MEMORY、CSV、BLACKHOLE、FEDERATED、MRG_MYISAM、ARCHIVE、PERFORMANCE_SCHEMA。其中BDB和InnoDB提供事务安全表，其他存储引擎都是非事务安全表。</p></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/20230701172516383.png" alt="20230701172516383.png" style="zoom:77%;"><h2 id="文件系统"><a class="markdownIt-Anchor" href="#文件系统"></a> 文件系统</h2><blockquote><p>数据存储层，主要是将数据存储到设备的文件系统中，并完成与存储引擎的交互。</p></blockquote><p><strong>了解完Mysql的系统架构后，我们就可以知道SQL的执行流程：</strong></p><blockquote><p>数据库通常不会被单独使用，而是由其它编程语言通过SQL支持接口调用MySQL。由MySQL处理并返回执行结果。</p><ol><li>编程语言通过SQL支持接口调用MySQL，</li><li>MySQL收到请求后，会将该请求暂时放在连接池，并由管理服务与工具进行管理。</li><li>当该请求从等待队列进入到处理队列时，管理器会将该请求传给SQL接口，SQL接口接收到请求后，它会将请求进行hash处理并与缓存中的数据进行对比，如果匹配则通过缓存直接返回处理结果；否则，去文件系统查询</li><li>由SQL接口传给后面的解析器，解析器会判断SQL语句是否正确，若正确则将其转化为数据结构。</li><li>解析器处理完毕后，便将处理后的请求传给优化器控制器，它会产生多种执行计划，最终数据库会选择最优的方案去执行。</li><li>确定最优执行计划后，SQL语句交由存储引擎处理，存储引擎将会到文件系统中取得相应的数据，并原路返回。</li></ol></blockquote><h1 id="innodb存储结构"><a class="markdownIt-Anchor" href="#innodb存储结构"></a> InnoDB存储结构</h1><h2 id="逻辑存储结构"><a class="markdownIt-Anchor" href="#逻辑存储结构"></a> 逻辑存储结构</h2><img src="https://gitee.com/eoccc/pic-shack/raw/master/v2-e44f8f9761bdbceca13dff1df91a2232_1440w.jpg" alt="v2-e44f8f9761bdbceca13dff1df91a2232_1440w.jpg" style="zoom:60%;"><h3 id="表空间"><a class="markdownIt-Anchor" href="#表空间"></a> 表空间</h3><p>表空间（Tablespace）用于存储记录、索引等数据，一个mysql实例可以有多个表空间，表空间的信息存储在<strong>ibd</strong>文件中。</p><p>如果用户启用了参数<code>innodb_file_per_table</code>，则每张表内的数据（包括数据、索引和插入缓冲Bitmap页）可以单独放到一个表空间内，但是其他数据，如回滚信息、插入缓冲索引页、系统事务信息等还是存放在原来的共享表空间内。</p><h3 id="段"><a class="markdownIt-Anchor" href="#段"></a> 段</h3><p>段（segment），常见的段有数据段、索引段、回滚段等。innoDB是索引组织表，数据段就是索引B+树的叶子节点，索引段即为B+树的非叶子节点。</p><h3 id="区"><a class="markdownIt-Anchor" href="#区"></a> 区</h3><p>区（Extent），表空间的单元结构，每个区的大小为1M，默认情况下，一个区中包含64个连续的页。</p><h3 id="页"><a class="markdownIt-Anchor" href="#页"></a> 页</h3><p>页（Page），innoDB磁盘管理的最小单元，每个页默认16kb，为了保证页的连续性，innoDB每次从磁盘中申请4～5个区。</p><h3 id="行"><a class="markdownIt-Anchor" href="#行"></a> 行</h3><p>行（Row），innoDB存储记录的最小单元，除了显式申明的字段，innoDB还会默认加入两个字段：</p><blockquote><p>事务id（Trx Id）：每次新增或修改记录时，会把对应的事物id保存到Trx Id隐藏列</p><p>回滚id（Roll pointer）：每次对记录进行修改时，innoDB会把旧版写入到undo log，然后通过Roll pointer隐藏列指向旧版的记录。</p></blockquote><h2 id="内存架构"><a class="markdownIt-Anchor" href="#内存架构"></a> 内存架构</h2><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230710151651642.png" alt="image-20230710151651642" style="zoom:50%;"><h3 id="缓冲池"><a class="markdownIt-Anchor" href="#缓冲池"></a> 缓冲池</h3><p>缓冲池（Buffer Pool）是主内存中的一个区域，用于存储磁盘上经常进行操作的数据，在执行增删改查操作时，先操作缓冲池中的数据（若缓冲池中没有需要的数据，则从磁盘加载并缓存），然后再以一定的频率刷新到磁盘，从而减少磁盘IO，提升效率。</p><p>缓冲池中的数据以page为单位，并使用双向链表（page内部的记录使用单向链表连接）管理数据。根据page的状态，将page分为三种：</p><blockquote><p>gree page：空闲的page，未被使用</p><p>clean page：被使用过，但是没有被修改过</p><p>dirty page：数据被修改过，数据与磁盘中的数据不一致，需要刷到磁盘</p></blockquote><p><strong>缓冲池的LRU算法</strong></p><p>实际生产环境中会存在全表扫描的情况，如果数据量较大，可能会将Buffer Pool中存下来的热点数据给全部替换出去，而这样就会导致该段时间MySQL性能断崖式下跌——<strong>缓冲池污染</strong>。</p><p>为了解决这一问题，Mysql将缓冲池分成了两个部分：New Sublist 和 Old Sublist，分别占用了 Buffer Pool 的3/4和1/4。当新页插入的时候，会把新页放到New Sublist 和 Old Sublist 之间，该位置叫<strong>MidPoint</strong>。当这些数据被访问过后，会被移动到 New Sublist 的头部。这样一来，虽然这些页数据在链表中了，但是由于没有被访问过，就会被移动到后1/4的 Old Sublist中去，直到被清理掉。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230710154147502.png" alt="image-20230710154147502" style="zoom:43%;"><p>通常来说，宿主机80%的内存都应该分配给Buffer Pool，因为Buffer Pool越大，其能缓存的数据就更多，更多的操作都会发生在内存，从而达到提升效率的目的。</p><h3 id="修改缓冲区"><a class="markdownIt-Anchor" href="#修改缓冲区"></a> 修改缓冲区</h3><p>更改缓冲区 （Change Buffer，针对于非唯一二级索引页），在执行DML语句时，如果这些数据Page没有在Buffer Pool中，不会直接操作磁盘，而会将数据变更存在更改缓冲区 Change Buffer 中，在未来数据被读取时，再将数据合并恢复到Buffer Pool中，再将合并后的数据刷新到磁盘中。</p><p>是新增或者删除记录时，很有可能会影响二级索引的不相邻的页（Buffer Pool中没有二级索引），导致磁盘IO，Mysql将对二级索引的操作先缓存在 Change Buffer 中，以一定的频率（或当 Change Buffer 中的记录被访问时）合并到 Buffer Pool 中，再由 Buffer Pool 刷新到磁盘。</p><h3 id="自适应hash索引"><a class="markdownIt-Anchor" href="#自适应hash索引"></a> 自适应hash索引</h3><p>自适应hash索引（Adaptive Hash Index）用于优化对 Buffer Pool 数据的查询。lnnoDB存储引擎会监控对表上各索引页的查询，如果观察到hash索引可以提升速度，则建立hash索引，称之为自适应hash索引。</p><h3 id="日志缓冲区"><a class="markdownIt-Anchor" href="#日志缓冲区"></a> 日志缓冲区</h3><p>日志缓冲区（Log Buffer）用来存储那些即将被刷入到磁盘文件中的日志，例如Redo Log、Undo Log。Log Buffer的默认值为16M，可以通过配置参数<code>innodb_log_buffer_size</code>来进行调整。</p><p>当Log Buffer如果较大，就可以存储更多的Redo Log，这样一来在事务提交之前我们就不需要将Redo Log刷入磁盘，只需要丢到Log Buffer中去即可。因此较大的Log Buffer就可以更好的支持较大的事务运行；同理，如果有事务会大量的更新、插入或者删除行，那么适当的增大Log Buffer的大小，也可以有效的减少部分磁盘I/O操作。</p><p>在InnoDB中，有两个参数可以控制redo log刷入到磁盘的频率：</p><blockquote><ol><li>innodb_log_buffer_size：指定redo log缓冲池的大小。当缓冲池中的数据达到一定量时，就会触发刷新操作</li><li>innodb_flush_log_at_trx_commit：指定redo log的刷新策略。有三个可选值：<ul><li>0：表示不进行redo log的刷新操作，性能最高，但是可能会丢失一定量的数据；</li><li>1：表示每次提交事务都会将redo log缓冲池中的数据刷新到磁盘上（默认值），保证数据的持久性，但是性能相对较低；</li><li>2：表示每次提交事务时，只将redo log缓冲池中的数据写入操作系统缓存中，然后由操作系统异步刷新到磁盘上。这个选项可以提高性能，但是可能会丢失一些数据。</li></ul></li></ol></blockquote><h2 id="磁盘结构"><a class="markdownIt-Anchor" href="#磁盘结构"></a> 磁盘结构</h2><h3 id="系统表空间"><a class="markdownIt-Anchor" href="#系统表空间"></a> 系统表空间</h3><p>系统表空间（System Tablespace）是更改缓冲区的存储区域。如果表是在系统表空间而不是每个表文件或通用表空间中创建的，它也可能包含表和索引数据。(在MySQL5.x版本中还包含InnoDB数据字典、undolog等)<br>参数: innodb_data file_path</p><h3 id="独立表空间"><a class="markdownIt-Anchor" href="#独立表空间"></a> 独立表空间</h3><p>独立表空间（File-Per-Table Tablespaces）包含单个InnoDB表的数据和索引，并存储在文件系统上的单个数据文件中。<br>参数: innodb_file_per_table，默认开启</p><h3 id="通用表空间"><a class="markdownIt-Anchor" href="#通用表空间"></a> 通用表空间</h3><p>通用表空间（GeneralTablespaces）需要通过 CREATE TABLESPACE 语法创建，然后在创建表时指定使用该表空间。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span>space table_space_name <span class="keyword">add</span> datafile<span class="string">&#x27;file_name.ibd&#x27;</span> engine <span class="operator">=</span> innodb;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> a(id <span class="type">int</span> <span class="keyword">primary</span> key auto increment, name <span class="type">varchar</span>(<span class="number">10</span>)) engine<span class="operator">=</span>innodb tablespace table_space_name;</span><br></pre></td></tr></table></figure><h3 id="撤销表空间"><a class="markdownIt-Anchor" href="#撤销表空间"></a> 撤销表空间</h3><p>撤销表空间（Undo Tablespaces）用于存储undo log日志，MySQL实例在初始化时会自动创建两个默认的 undo 表空间（初始大小16M）。</p><h3 id="临时表空间"><a class="markdownIt-Anchor" href="#临时表空间"></a> 临时表空间</h3><p>临时表空间（Temporary Tablespaces）存储用户创建的临时表等数据，InnoDB 使用会话临时表空间和全局临时表空间。</p><h3 id="双写缓冲区"><a class="markdownIt-Anchor" href="#双写缓冲区"></a> 双写缓冲区</h3><p>双写缓冲区（Doublewrite Buffer Files），innoDB引擎将数据页从Buffer Pool刷新到磁盘前，先将数据页写入双写缓冲区文件中，便于系统异常时恢复数据。</p><h3 id="重做日志"><a class="markdownIt-Anchor" href="#重做日志"></a> 重做日志</h3><p>重做日志（Redo Log）是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log），前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都会存到该日志中，用于在刷新脏页到磁盘发生错误时，进行数据恢复。</p><h2 id="后台线程"><a class="markdownIt-Anchor" href="#后台线程"></a> 后台线程</h2><h3 id="master-thread"><a class="markdownIt-Anchor" href="#master-thread"></a> Master Thread</h3><p>核心后台线程，负责：</p><blockquote><ol><li>调度其他线程</li><li>将缓冲池中的数据异步刷新到磁盘中，保持数据的一致性</li><li>脏页的刷新、合并插入缓存、undo页的回收</li></ol></blockquote><h3 id="io-thread"><a class="markdownIt-Anchor" href="#io-thread"></a> IO Thread</h3><p>在InnoDB存储引擎中大量使用了AIO来处理IO请求，这样可以极大地提高数据库的性能，而IO Thread主要负责这些IO请求的回调。包括4个线程：</p><table><thead><tr><th>线程类型</th><th>默认个数</th><th>职责</th></tr></thead><tbody><tr><td>Read thread</td><td>4</td><td>负责读操作</td></tr><tr><td>Write thread</td><td>4</td><td>负责写操作</td></tr><tr><td>Log thread</td><td>1</td><td>负责将日志缓冲区刷新到磁盘</td></tr><tr><td>Insert buffer thread</td><td>1</td><td>负责将写缓冲区内容刷新到磁盘</td></tr></tbody></table><h3 id="purge-thread"><a class="markdownIt-Anchor" href="#purge-thread"></a> Purge Thread</h3><p>主要用于回收事务已经提交了的undo log，在事务提交之后，undo log可能不用了，就用它来回收。</p><h3 id="page-cleaner-thread"><a class="markdownIt-Anchor" href="#page-cleaner-thread"></a> Page Cleaner Thread</h3><p>协助 Master Thread 刷新脏页到磁盘的线程，它可以减轻 Master Thread 的工作压力，减少阻塞。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Mysql架构：组件、内存、磁盘、后台线程。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Queue 之 help gc</title>
    <link href="https://eoccc.gitee.io/2023/06/14/Queue%20%E4%B9%8B%20help%20gc/"/>
    <id>https://eoccc.gitee.io/2023/06/14/Queue%20%E4%B9%8B%20help%20gc/</id>
    <published>2023-06-14T10:25:19.000Z</published>
    <updated>2023-07-11T08:49:30.434Z</updated>
    
    <content type="html"><![CDATA[<p><code>java.util.concurrent.LinkedBlockingQueue#dequeue</code>有一行代码<code>h.next = h</code> 被注释上了help gc，那么它到底是怎么帮助gc的呢？</p><span id="more"></span><p><code>LinkedBlockingQueue#dequeue</code>源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> E <span class="title function_">dequeue</span><span class="params">()</span> &#123;</span><br><span class="line">    Node&lt;E&gt; h = head;</span><br><span class="line">    Node&lt;E&gt; first = h.next;</span><br><span class="line">    h.next = h; <span class="comment">// help GC</span></span><br><span class="line">    head = first;</span><br><span class="line">    <span class="type">E</span> <span class="variable">x</span> <span class="operator">=</span> first.item;</span><br><span class="line">    first.item = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码移除并返回了队列的头节点，具体分成几个步骤：</p><ol><li>h指向head节点</li><li>first指向第一个node</li></ol><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624225338150.png" alt="640-20230624225338150.png" style="zoom:65%;"><ol start="3"><li>h.next 指向自己 (help gc)</li></ol><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624225534349.png" alt="640-20230624225534349.png" style="zoom:65%;"><ol start="4"><li>将 head 指向 first</li><li>取到 first 的 value （作为返回值）</li><li>将 first 的value 置为 null</li></ol><p>这段代码执行完之后，链表的变化：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624230007345.png" alt="640-20230624230007345.png" style="zoom:67%;"><p>那么，如果说没有 <code>h.next = h</code> 这行代码，执行之后会变成：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624230206795.png" alt="640-20230624230206795.png" style="zoom:67%;"><p>这时，头节点已经没有任何引用指向它了，也就是GC不可达，理论上会被垃圾回收器回收。</p><p>JVM大佬讲了，如果没有这行代码，会造成跨代引用，从而导致不可回收（直到发生FGC），视频第23分钟：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.infoq.com/presentations/twitter-services/</span><br></pre></td></tr></table></figure><p><strong>过程分析：</strong></p><ol><li>我们创建了一个队列，由于队列是一个大对象，或者生命比较长，被分配在了老年代，合情合理</li><li>往队列里面添加了两个新元素A、B。由于是新对象，所以被分配在了年轻代，完全ok</li></ol><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624231339106.png" alt="640-20230624231339106.png"></p><ol start="3"><li>然后插入新的元素C、D、E，干掉A、B。这时A、B已经GC不可达，会被垃圾回收器回收，没问题</li></ol><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624231640223.png" alt="640-20230624231640223.png"></p><ol start="3"><li>经过几轮的ygc之后，C节点由于一直没有被移除，晋升到老年代</li></ol><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624235930226.png" alt="640-20230624235930226.png"></p><ol start="4"><li>这时C出队，由于C在老年代，ygc时不会被回收，直到fgc</li><li>如果接着出队D，此时老年代的C还指向D，D也不会被回收</li></ol><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230625000229506.png" alt="640-20230625000229506.png"></p><p>因此，在出队的时候，一定需要断开头节点和下一个节点的连接。</p><p><strong>那么为什么一定要指向它自己呢？改成<code>h.next = null</code>行不行？</strong></p><p>答案是不行，LinkedBlokingQueue的迭代器 java.util.concurrent.LinkedBlockingQueue.Itr 的next实现（jdk17）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> E <span class="title function_">next</span><span class="params">()</span> &#123;</span><br><span class="line">    Node&lt;E&gt; p;</span><br><span class="line">    <span class="keyword">if</span> ((p = next) == <span class="literal">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">NoSuchElementException</span>();</span><br><span class="line">    lastRet = p;</span><br><span class="line">    <span class="type">E</span> <span class="variable">x</span> <span class="operator">=</span> nextItem;</span><br><span class="line">    fullyLock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="type">E</span> <span class="variable">e</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">for</span> (p = p.next; p != <span class="literal">null</span> &amp;&amp; (e = p.item) == <span class="literal">null</span>; )</span><br><span class="line">            p = succ(p);</span><br><span class="line">        next = p;</span><br><span class="line">        nextItem = e;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        fullyUnlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Used for any element traversal that is not entirely under lock.</span></span><br><span class="line"><span class="comment"> * Such traversals must handle both:</span></span><br><span class="line"><span class="comment"> * - dequeued nodes (p.next == p)</span></span><br><span class="line"><span class="comment"> * - (possibly multiple) interior removed nodes (p.item == null)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">Node&lt;E&gt; <span class="title function_">succ</span><span class="params">(Node&lt;E&gt; p)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == (p = p.next))</span><br><span class="line">        p = head.next;</span><br><span class="line">    <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在<code>such(Node&lt;E&gt; p)</code>中判断了 <code>p = p.next</code>，其目的是在多线程对队列进行操作的时候，避免出现迭代异常退出的情况。接下来就具体分析一下：</p><p>假设我们由两个线程对queue进行操作，第一个线程进行迭代，第一次迭代current指向了节点1：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230711161810180.png" alt="640-20230711161810180.png" style="zoom:65%;"><p>此时第二个线程删除了1、2、3节点：</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230711161810280.png" alt="640-20230711161810280.png" style="zoom:65%;"><p>如果不是使用 <code>h.next = null</code>，那么会发生这样的情况：</p><p>​线程1继续进行迭代，但是item1.next 已经被线程2置为null了，那么线程1就会认为已经迭代到了队列尾部了，也就是队列已经断开了，后面还存在的节点将不会被迭代到。</p><p>解决方案就是让 <code>h.next = h</code> ：</p><p>​线程2删除了1，2，3节点，那么 item1.next 就会指向自己，线程1继续进行迭代的时候，发现 item1.next 指向了自己，说明后面的节点被其他线程删除了，那么直接返回 head.next 即可完美解决。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;java.util.concurrent.LinkedBlockingQueue#dequeue&lt;/code&gt;有一行代码&lt;code&gt;h.next = h&lt;/code&gt; 被注释上了help gc，那么它到底是怎么帮助gc的呢？&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>协程-小试牛刀</title>
    <link href="https://eoccc.gitee.io/2023/06/06/%E5%8D%8F%E7%A8%8B-%E5%B0%8F%E8%AF%95%E7%89%9B%E5%88%80/"/>
    <id>https://eoccc.gitee.io/2023/06/06/%E5%8D%8F%E7%A8%8B-%E5%B0%8F%E8%AF%95%E7%89%9B%E5%88%80/</id>
    <published>2023-06-06T14:53:04.949Z</published>
    <updated>2023-07-01T09:14:59.601Z</updated>
    
    <content type="html"><![CDATA[<p>JDK还不支持协程，终究是一大遗憾。好消息是jdk19引入了虚线程，弥补了这一遗憾，但是还需要经历一定时间的验证，公司生产环境的jdk一般也没有使用这么高版本的jdk。</p><span id="more"></span><h1 id="协程的优势"><a class="markdownIt-Anchor" href="#协程的优势"></a> 协程的优势</h1><p>纤程（Fiber）是一种轻量级的并发执行单元，与线程（Thread）相比具有以下优点和缺点：</p><p><strong>优点：</strong></p><blockquote><ol><li><strong>更轻量级</strong>：纤程相对于线程更加轻量级，占用的内存资源更少，可以实现更高密度的并发执行。</li><li><strong>更高效</strong>：纤程的上下文切换比线程更加高效，因为它们是在应用程序内部进行切换，不需要进入内核态，也不需要切换地址空间。</li><li><strong>更灵活</strong>：纤程可以通过应用程序自己的调度算法进行管理和调度，因此可以实现更灵活的并发编程模型。</li><li><strong>更容易实现协作式调度</strong>：纤程可以更容易地实现协作式调度，即在纤程自己主动让出CPU资源的情况下进行切换，这可以避免线程之间的竞争和锁等并发编程中常见的问题。</li></ol></blockquote><p><strong>缺点：</strong></p><blockquote><ol><li><strong>无法充分利用多核CPU</strong>：由于纤程只能在单个线程中执行，因此不能充分利用多核CPU的能力。</li><li><strong>需要特定的编程模型</strong>：纤程需要使用特定的编程模型（比如协程）进行编程，这对于一些开发者来说可能需要一定的学习成本。</li><li><strong>可能会引起资源竞争问题</strong>：由于纤程是在应用程序内部进行调度和切换，因此可能会引起资源竞争问题，比如在纤程之间共享状态时需要进行同步和互斥处理。</li></ol></blockquote><h1 id="协程适用的场景"><a class="markdownIt-Anchor" href="#协程适用的场景"></a> 协程适用的场景</h1><p>与线程相比，纤程的上下文切换更加高效，可以更快地进行切换和恢复，因此在 I/O 密集型的应用场景下，使用纤程可以提高并发性能和吞吐量。</p><ol><li>协程更加轻量，对于IO密集型任务，使用协程可以减少资源占用</li><li>协程的上下文切换都是在用户态进行的，不需要进行内核态和用户态的切换，效率更高，因此需要进行频繁切换的任务也适合使用协程（其实改成单线程执行或许效率更高）</li></ol><p>对于CPU密集型任务，应该充分利用计算机多核的特性，使用多行程并行计算，提升处理速度。</p><h1 id="协程框架"><a class="markdownIt-Anchor" href="#协程框架"></a> 协程框架</h1><p>目前支持 java 的协程框架：</p><blockquote><ol><li>Quasar：一个基于 ASM 的轻量级协程框架，提供了完整的协程支持，包括协程调度、协程间通信等功能。</li><li>Project Reactor：一个基于 Reactive Stream 的响应式编程框架，提供了完整的反应式编程支持，包括异步、并发、流处理等功能。</li><li>Akka：一个基于 Actor 模型的分布式系统框架，提供了完整的 Actor 模型支持，包括并发、消息传递、容错等功能。</li><li>Vert.x：一个基于异步、事件驱动的应用框架，提供了完整的异步编程支持，包括网络编程、数据库操作、消息传递等功能。</li><li>Kotlin 协程：Kotlin 官方支持的协程框架，提供了完整的协程支持，包括协程调度、协程间通信等功能。</li></ol></blockquote><h1 id="协程使用示例"><a class="markdownIt-Anchor" href="#协程使用示例"></a> 协程使用示例</h1><p>这里基于 Quasar 实现一个协程的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.demo.my;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> co.paralleluniverse.fibers.Fiber;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">QuasarCoroutine</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> &#123;</span><br><span class="line">        tryFiber();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">tryFiber</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">        <span class="type">CountDownLatch</span> <span class="variable">countDownLatch</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CountDownLatch</span>(COUNT);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; COUNT; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Fiber</span>&lt;&gt;(countDownLatch::countDown).start();</span><br><span class="line">        &#125;</span><br><span class="line">        countDownLatch.await();</span><br><span class="line">        System.out.printf(<span class="string">&quot;fiber cost: %s\n&quot;</span>, System.currentTimeMillis() - start);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><em>jdk17有更严格的安全限制，不能通过反射获得对象，可配置参数开启指定包的访问权限：</em></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--add-opens java.base/java.lang=ALL-UNNAMED</span><br></pre></td></tr></table></figure><h1 id="协程与线程性能对比"><a class="markdownIt-Anchor" href="#协程与线程性能对比"></a> 协程与线程性能对比</h1><p>从执行速度和资源占用对协程和线程进行比较。</p><p>todo…</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;JDK还不支持协程，终究是一大遗憾。好消息是jdk19引入了虚线程，弥补了这一遗憾，但是还需要经历一定时间的验证，公司生产环境的jdk一般也没有使用这么高版本的jdk。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kafka-4 日志存储</title>
    <link href="https://eoccc.gitee.io/2023/04/09/kafka-4%20%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6/"/>
    <id>https://eoccc.gitee.io/2023/04/09/kafka-4%20%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6/</id>
    <published>2023-04-09T14:52:41.000Z</published>
    <updated>2023-06-06T14:53:05.080Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka中，一个分区对应一个日志，为了防止日志过大，又引入了日志段的概念（LogSegment），将日志切分为多个日志段，以便于维护和清理。一个LogSegment对应磁盘上的一个日志文件和两个索引文件。</p><span id="more"></span><h1 id="日志文件"><a class="markdownIt-Anchor" href="#日志文件"></a> 日志文件</h1><h2 id="日志分段"><a class="markdownIt-Anchor" href="#日志分段"></a> 日志分段</h2><p>在 Kafka 中，一个 topic 的消息被存储在一个或多个 partition 中，每个 partition 可以看作是一个有序、不可变的消息日志。为了便于管理和优化磁盘空间的利用，Kafka 中的每个 partition 被分成多个 segment，每个 segment 包含一段连续的消息。</p><p>当一个新消息写入 partition 时，Kafka 会将该消息追加到当前最新的 segment 中。当当前 segment 达到一定大小或者存储时间达到一定阈值时，Kafka 会自动将该 segment 封存（close）并创建一个新的 segment，作为 partition 的新的写入位置。</p><p>封存的 segment 不可修改，这就保证了 Kafka 中的消息具有不可变性和顺序性。同时，封存的 segment 可以被压缩（compaction），即删除已经过期或者被标记为删除的消息，以便更好地管理磁盘空间和减少数据复制的数据量。</p><p>Kafka 中的 segment 大小和存储时间可以通过配置文件进行设置。默认情况下，Kafka 会根据时间和大小两个因素来控制 segment 的滚动，以平衡性能和磁盘空间的利用。</p><p>需要注意的是，segment 大小和存储时间的设置应该根据业务需求和硬件资源情况进行调整。如果 segment 大小设置过小，可能会导致 segment 的切换频繁，影响 Kafka 的性能。如果 segment 存储时间设置过长，可能会导致数据的实时性下降，影响业务应用。</p><h2 id="日志文件结构"><a class="markdownIt-Anchor" href="#日志文件结构"></a> 日志文件结构</h2><img src="https://gitee.com/eoccc/pic-shack/raw/master/o9Qyhuqff.jpeg" alt="o9Qyhuqff.jpeg" style="zoom:60%;"><p>日志的文件夹的命名规则为：tpoic-partition。</p><p>向Log追加消息时是顺序写入的，只有最后一个LogSegment才能写入新的消息，最后一个LogSegment即活跃日志段。</p><p>日志段中包含一个 <strong>.log</strong> 的日志文件，一个 <strong>.index</strong> 的偏移量索引文件，一个 <strong>.timeIndex</strong> 的时间戳索引文件。日志文件和两个索引文件都是根据基准偏移量（固定为20位数字）命名的，即这个LogSegment的第一条日志的偏移量，如第一个LogSegment的基准偏移量为0，则日志文件名为 00000000000000000000.log。</p><p>LogSegment还包括 .deleted, .cleaned, .swap等临时文件，以及 .snapshot, .txnindex, leader-epoch-checkpoint等文件。</p><p>另外，kafka第一次启动的时候，还会创建以下文件：</p><blockquote><ol><li>cleaner-offset-checkpoint</li><li>log-start-offset-checkpoint</li><li>recovery-point offset-checkpoint</li><li>replicat ion-offset-checkpoint</li><li>meta.properties</li></ol></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/l6y5sq3gO.jpeg" alt="img/l6y5sq3gO.jpeg" style="zoom:60%;"><h1 id="kafka日志压缩"><a class="markdownIt-Anchor" href="#kafka日志压缩"></a> Kafka日志压缩</h1><p>Kafka 中的日志压缩可以通过参数配置来设置触发压缩的条件。Kafka 支持基于消息大小和时间的压缩触发机制，即：</p><blockquote><ol><li>消息大小触发压缩：当日志分段文件中待写入消息的大小超过了配置参数 <code>log.segment.bytes</code>，即分段文件的大小时，Kafka 会触发日志的压缩操作。</li><li>时间触发压缩：当日志分段文件中待写入消息的时间距离上一次日志压缩的时间超过了配置参数 <code>log.roll.ms</code>，即分段文件的滚动时间时，Kafka 会触发日志的压缩操作。</li></ol></blockquote><p>Kafka 提供了多种数据压缩技术，可以在不影响数据实时性的前提下，最大限度地利用磁盘空间。Kafka 支持以下三种数据压缩技术：</p><blockquote><ol><li>GZIP：GZIP 是一种基于 DEFLATE 压缩算法的数据压缩技术，可以实现较高的压缩比。GZIP 压缩后的数据体积更小，可以节省磁盘空间，但是解压缩会消耗一定的 CPU 资源，可能会影响数据的处理性能。</li><li>Snappy：Snappy 是一种基于 Google 的 Zippy 压缩算法的数据压缩技术，可以实现较快的压缩和解压缩速度。Snappy 压缩后的数据体积相对较小，可以在不影响数据处理性能的前提下，实现数据的压缩和解压缩。</li><li>LZ4：LZ4 是一种基于 Lempel-Ziv 算法的数据压缩技术，可以实现较高的压缩和解压缩速度。LZ4 压缩后的数据体积相对较小，可以在不影响数据处理性能的前提下，实现数据的压缩和解压缩。</li></ol></blockquote><p>Kafka 中的数据压缩技术可以通过配置文件中的 <code>compression.type</code> 参数进行设置，支持多种压缩算法。需要注意的是，不同的压缩算法适用于不同的场景和数据类型，需要根据实际情况选择合适的压缩算法，以达到最优的压缩效果和数据处理性能。</p><p><strong><font color="red">注意：</font>活跃的日志分段不会参与日志压缩。</strong></p><h1 id="日志清理"><a class="markdownIt-Anchor" href="#日志清理"></a> 日志清理</h1><p>Kafka通过三种策略来清理日志文件：基于时间、基于日志大小、基于日志起始偏移量。</p><h2 id="基于时间清理日志"><a class="markdownIt-Anchor" href="#基于时间清理日志"></a> 基于时间清理日志</h2><p>日志删除任务会检查当前日志文件中是否有保留时间超过阈值的日志分段集合，保留时间可以配置毫秒、分钟和小时，优先级依次降低：</p><blockquote><p>log.retention.hours  默认为168，即7天</p><p>log.retention.minutes</p><p><a href="http://log.retention.ms">log.retention.ms</a></p></blockquote><p>查找过期日志分段文件时，先从 .timeindex 时间戳索引文件中获取最后一条索引的时间戳，如果时间戳大于0，则取其值，否则取最后修改时间。</p><p>如果所有的日志分段都已经过期，会先切出一个新的日志分段作为活跃日志分段，再把过期的日志分段删除。</p><p>删除日志分段时，会先从Log对象所维护的日志分段跳跃表中移除待删除的日志分段，以保证没有线程会读取这些日志，然后对日志分段的所有文件添加上 <strong>.deleted</strong> 后缀，最后由 <strong>delete-file</strong> 删除任务删除这些文件。delete-file 任务的执行周期通过 <code>file.delete.delay.ms</code> 配置，默认为1分钟。</p><h2 id="基于大小清理日志"><a class="markdownIt-Anchor" href="#基于大小清理日志"></a> 基于大小清理日志</h2><p>如果Log总size大于 <code>log.retention.bytes</code> 配置的阈值（默认为-1，即不限制），则会先计算需要删除的日志文件的大小，即总size和阈值的差值，然后从第一个日志分段开始计算，找出需要删除的日志分段，然后由删除任务执行删除。</p><p>单个日志分段的大小由 <code>log.segment.bytes</code> 配置，默认为1GB。</p><h2 id="基于起始偏移量清理日志"><a class="markdownIt-Anchor" href="#基于起始偏移量清理日志"></a> 基于起始偏移量清理日志</h2><p>kafka有一个logStartOffset记录了日志文件的起始偏移量，一般是第一个日志文件的 baseOffset，但是可能会改变。可以使用 KafkaAdminClient 的 <code>deleteRecords()</code> 方法、或使用 <a href="http://kafka-delete-records.sh">kafka-delete-records.sh</a> 脚本修改。</p><p>kafka会将偏移量小于 logStartOffset 的日志分段删除。如下图会将日志分段1和2删除。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/kFXC6GPCV.jpeg" alt="img/kFXC6GPCV.jpeg" style="zoom:50%;"><h1 id="零拷贝"><a class="markdownIt-Anchor" href="#零拷贝"></a> 零拷贝</h1><p>所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序，减少了内核和用户模式之间的上下文切换 。</p><p>一般情况下，如果我们要把一个数据发送给用户，会经过4次复制，进行了4次上下文切换：</p><blockquote><ol><li>调用 read() 方法，将文件中的内容被复制到内核模式下的 ReadBuffer 中；</li><li>CPU 控制将内核模式数据复制到用户模式下；</li><li>调用 write() 方法，将用户模式下的内容复制到内核模式下的 Socket Buffer 中；</li><li>将 SocketBuffer 中的数据复制到网卡设备中传迭。</li></ol></blockquote><p>在零拷贝中，直接将 SocketBuffer 中的数据复制到网卡设备中传迭，只需要进行2次复制，进行了2次上下文切换：</p><blockquote><ol><li>read() 方法，将文件的内容复制到内核模式下的 ReadBuffer 中；</li><li>将<strong>包含数据的位置和长度信息的文件描述符</strong>添加到 Socket Buffer 中；</li><li>将 SocketBuffer 中的数据复制到网卡设备中传送。</li></ol></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;Kafka中，一个分区对应一个日志，为了防止日志过大，又引入了日志段的概念（LogSegment），将日志切分为多个日志段，以便于维护和清理。一个LogSegment对应磁盘上的一个日志文件和两个索引文件。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>写出整洁代码的tips</title>
    <link href="https://eoccc.gitee.io/2023/04/04/%E5%86%99%E5%87%BA%E6%95%B4%E6%B4%81%E4%BB%A3%E7%A0%81%E7%9A%84tips/"/>
    <id>https://eoccc.gitee.io/2023/04/04/%E5%86%99%E5%87%BA%E6%95%B4%E6%B4%81%E4%BB%A3%E7%A0%81%E7%9A%84tips/</id>
    <published>2023-04-04T14:52:41.000Z</published>
    <updated>2023-07-11T06:56:20.522Z</updated>
    
    <content type="html"><![CDATA[<p>一开始就要写整洁的代码，如果有不整洁的代码就要及时的整改，绝对不要有以后再改,以后再说的想法，因为**<font color="red">letter equals never!</font>**</p><span id="more"></span><p>不整洁的代码随着时间的增加而增加时，生产力会随之降低，导致的结果就是：</p><ul><li>代码不易扩展或扩展容易引发其他问题</li><li>程序崩溃</li><li>加班</li></ul><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230404210606658.png" alt="image-20230404210606658"></p><h1 id="命名"><a class="markdownIt-Anchor" href="#命名"></a> 命名</h1><p>好的命名可提高代码的可读性，让人见码知意，降低理解成本，提高效率，减少加班！</p><p><strong>1. 无意义的命名</strong></p><p>从命名上完全看不出方法或类的功能，没有任何意义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ABC</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">abc</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好的命名可以直接看出功能，开发者不需要阅读代码细节就能知道其作用。good case：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Animal</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">walk</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>2. 混淆的命名</strong></p><p>命名前后不一致，相同的功能，在不同的方法中使用不同的命名，造成混淆：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">StudentRepository</span> &#123;</span><br><span class="line">    </span><br><span class="line">    Student <span class="title function_">findOneById</span><span class="params">(<span class="meta">@Param(&quot;id&quot;)</span> String id)</span>;</span><br><span class="line"></span><br><span class="line">    List&lt;Student&gt; <span class="title function_">queryAllStudent</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>两个方法都是查Student，唯一的区别就是查一个和查全部，但是用了<font color=" #DB7093">find</font>和<font color=" #DB7093">query</font>命名。优化后：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">StudentRepository</span> &#123;</span><br><span class="line">   </span><br><span class="line">    Student <span class="title function_">findOne</span><span class="params">(<span class="meta">@Param(&quot;id&quot;)</span> String id)</span>;</span><br><span class="line"></span><br><span class="line">    List&lt;Student&gt; <span class="title function_">findAll</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="单一职责"><a class="markdownIt-Anchor" href="#单一职责"></a> 单一职责</h1><p><strong>类应该短小，类或模块应有且只有一条加以修改的理由</strong>，如果一个类过于庞大的话,那么说明它承担的职责过多了。</p><p>类的名称描述其全责，如果无法为某个类命以准确的名称，这个类大概就太长了，类名越含糊，可能拥有越多的职责。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">UpdateDB</span> &#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insertUser</span><span class="params">(User user)</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insertOrder</span><span class="params">(Order order)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个类的职责太大了，从类名不能直接看出这个类操作的是哪个数据库，将职责抽开：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">UpdateUserDB</span> &#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insertUser</span><span class="params">(User user)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="开闭原则"><a class="markdownIt-Anchor" href="#开闭原则"></a> 开闭原则</h1><p>开闭原则：面向修改关闭，面向扩展开放。</p><p>面向修改关闭意味着增加新的逻辑不会修改原有的代码，降低了出错的可能性。</p><p>面向扩展开放则是提高了代码的可扩展性，可很容易的增加新的代码逻辑。</p><p>不满足开闭原则的例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insert</span><span class="params">(User user)</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">(User user)</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">delete</span><span class="params">(User user)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果我们要新增查询操作，就得修改这个类，没有做到面向修改关闭。优化后：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">invoke</span><span class="params">(User user)</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">InsertSql</span> <span class="keyword">extends</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">invoke</span><span class="params">(User user)</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UpdateSql</span> <span class="keyword">extends</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">invoke</span><span class="params">(User user)</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用：</span></span><br><span class="line"><span class="meta">@Resource</span></span><br><span class="line">Sql insertSql;</span><br><span class="line"></span><br><span class="line">insertSql.invoke(user);</span><br></pre></td></tr></table></figure><h1 id="高内聚低耦合"><a class="markdownIt-Anchor" href="#高内聚低耦合"></a> 高内聚低耦合</h1><p>将一个复杂的系统分解成更小的、可管理的部分，并通过将这些部分彼此隔离来降低它们之间的耦合度。</p><p>函数的第一规则是短小，第二规则是更短小，短小到只做一件事情。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String <span class="title function_">upload</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">// 校验图片的方法 代码80行</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 压缩图片的方法 代码50行</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 返回成功或失败标识 0,1 代码5行</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;0&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>原有的upload方法做了很多的事情，重构后只做了一件事情：<strong>把大一些的概念拆分为另一抽象层上的一系列步骤：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String <span class="title function_">upload</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">// 校验图片的方法</span></span><br><span class="line">    check();</span><br><span class="line">    <span class="comment">// 压缩图片的方法</span></span><br><span class="line">    compress();</span><br><span class="line">    <span class="comment">// 返回成功或失败标识 0,1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;0&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="函数命名"><a class="markdownIt-Anchor" href="#函数命名"></a> 函数命名</h1><p>函数要有描述性的名称，不要害怕长名称。</p><p>不好的命名方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String <span class="title function_">addCharacter</span><span class="params">(String originString, <span class="type">char</span> ch)</span>;</span><br></pre></td></tr></table></figure><p>从函数字面意思看是给某个字符串添加一个字符。但是到底是在原有字符串首部添加，还是在原有字符串末尾追加呢？亦或是在某个固定位置插入呢？从函数名字完全看不出来这个函数的真正意图，只能继续往下读这个函数的具体实现才知道。</p><p>优化后：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 追加到末尾</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">appendCharacter</span><span class="params">(String originString, <span class="type">char</span> ch)</span>;   </span><br><span class="line"></span><br><span class="line"><span class="comment">// 插入指定位置</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">insertCharacter</span><span class="params">(String originString, <span class="type">char</span> ch, <span class="type">int</span> insertPosition)</span>;</span><br></pre></td></tr></table></figure><h1 id="参数"><a class="markdownIt-Anchor" href="#参数"></a> 参数</h1><p><strong>参数越少越好</strong></p><p>参数越少，越容易理解，参数超过三个可以将参数进行封装，要按参数的语义进行封装，不一定封装成一个大而全的参数，可以封装为多个，原则是按语义补充。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;Student&gt; <span class="title function_">findStudent</span><span class="params">(<span class="type">int</span> age, String name, String country, <span class="type">int</span> gender)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//封装参数</span></span><br><span class="line"><span class="keyword">public</span> List&lt;Student&gt; <span class="title function_">findStudent</span><span class="params">(Student student)</span>;</span><br></pre></td></tr></table></figure><p><strong>不要使用标识参数</strong></p><p>标识参数是参数为 Boolean 类型，用户传递 true or false。不要使用标识参数因为这意味着你的函数违背了单一职责(true false 两套逻辑)。正确的做法是拆分为两个方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//标识参数方法</span></span><br><span class="line">order4User(<span class="type">boolean</span> isNewUser);</span><br><span class="line"></span><br><span class="line"><span class="comment">//重构为两个方法</span></span><br><span class="line">order4NewUser();</span><br><span class="line">order4OldUser();</span><br></pre></td></tr></table></figure><p><strong>不要使用输出参数</strong></p><p>输出参数就是将变量作为参数传入方法，并且将变量返回。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">findStudent</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">Student</span> <span class="variable">student</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Student</span>();</span><br><span class="line">    doSomething(student);</span><br><span class="line">    <span class="keyword">return</span> student;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> Student <span class="title function_">doSomething</span><span class="params">(Student student)</span>&#123;</span><br><span class="line">    <span class="comment">// 省略一些student逻辑</span></span><br><span class="line">    <span class="keyword">return</span> student;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果只看方法名称，我们不知道doSomething做了些什么，返回的参数和传入的参数是不是同一个，需要看具体的逻辑才知道。</p><p>正确的方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将doSomething()方法内聚到student对象本身</span></span><br><span class="line">student.doSomething();</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;一开始就要写整洁的代码，如果有不整洁的代码就要及时的整改，绝对不要有以后再改,以后再说的想法，因为**&lt;font color=&quot;red&quot;&gt;letter equals never!&lt;/font&gt;**&lt;/p&gt;</summary>
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>kafka-3 客户端</title>
    <link href="https://eoccc.gitee.io/2023/04/03/kafka-3%20%E5%AE%A2%E6%88%B7%E7%AB%AF/"/>
    <id>https://eoccc.gitee.io/2023/04/03/kafka-3%20%E5%AE%A2%E6%88%B7%E7%AB%AF/</id>
    <published>2023-04-03T14:52:41.000Z</published>
    <updated>2023-06-06T14:53:05.083Z</updated>
    
    <content type="html"><![CDATA[<p>总结kafka客户端的分区策略、幂等性和事务。</p><span id="more"></span><h1 id="消费者分区分配策略"><a class="markdownIt-Anchor" href="#消费者分区分配策略"></a> 消费者分区分配策略</h1><p>消费者消费消息之前，首先得进行分区分配，kafka提供了三种分区分配策略。</p><ol><li><p><strong>RangeAssignor 按跨度进行分配</strong></p><p>kafka会先按照分区总数和消费者总数进行整除，获得一个跨度，然后按照分区跨度进行平均分配，确保分区尽可能平均的分配给所有的消费者。对于剩余的分区（分区总数 % 消费者总数），则前面的消费者（消费者名称按字典序排序）会多分配一个分区。</p><p>假设 n=分区数/消费者数量， m=分区数%消费者数量，那么前 m 个消费者每个分配 n+1 个 分区，后面的(消费者数量～m)个消费者每个分配 n个分区。</p><p>这种分配方式存在一个问题，如果存在多个topic的分区不是消费者总数的整数倍，那么排在前面的消费者会被多分配多个分区。</p><blockquote><p>假设有两个topic，每个topic有4个分区，分配结果为：</p><p>Consumer0:  t0p0,t0p1, t1p0,t1p1</p><p>Consumer1:  t0p2,t0p3, t1p2,t1p3</p><p>但是如果有两个topic，且个topic有3个分区，分配结果为：</p><p>Consumer0:  t0p0,tp1, t1p0,t1p1</p><p>Consumer1:  t0p2,t1p2</p></blockquote></li><li><p><strong>RoundRobinAssignor 按顺序分配</strong></p><p>将消费组内所有的消费者及消费者订阅的所有topic的分区按照字典序排序，然后通过轮询的方式将分区依此分配给每个消费者。</p><p>这种分配方式如果消费组内所有的消费者订阅的topic都是相同的，那么分区会被很均匀的分配给每个消费者，但是如果消费者订阅的topic不同，就会导致分配不均匀。</p><blockquote><p>假设消费者C0订阅了主题t0；假设消费者C1订阅了主题t0和t1；假设消费者C2订阅了主题t0，t1和t2。t0、t1、t2的分区数分别为1、2、3。此时分配结果为：</p><p>C0: t0p0</p><p>C1: t1p0</p><p>C2: t1p1, t2p0,t2p1,t2p2</p><p>这种分配方式不完美，因为可以将 t1p1分配给C1。</p></blockquote></li><li><p><strong>StickyAssignor 粘性分配</strong></p><p>这是目前最优秀的分区分配策略。Kafka从0.11x开始引入这种分配策略，尽可能保证：分区分配均匀，分区分配尽可能与上一次分配相同</p><p>再分配的时候，会将需要分配的分区平均的分配给消费者。</p><blockquote><p>RoundRobinAssignor中提到的例子，使用StickyAssignor的分配结果为：</p><p>C0: t0p0</p><p>C1: t1p0, <strong>t1p1</strong></p><p>C2: t2p0,t2p1,t2p2</p><p>假设StickyAssignor当前的分区分配为：</p><p>C0: t0p0, t1p1, t3p0</p><p>C1: t0p1, t2p1, t3p1</p><p>C2: t1p0, t2p1</p><p>消费者C1脱离了消费组，则分配结果为：</p><p>C0: t0p0, t1p1, t3p0, <strong>t201</strong></p><p>C2: t1p0, t2p1, <strong>t0p1, t3p1</strong></p></blockquote></li><li><p>自定义分区分配策略</p><p>实现PartitionAssignor接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">PartitionAssignor</span> &#123;</span><br><span class="line">  <span class="comment">//提供订阅的消息</span></span><br><span class="line">  Subscription <span class="title function_">subscription</span><span class="params">(Set&lt;String&gt; topics)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//实现具体的分配逻辑</span></span><br><span class="line">  Map&lt;String, Assignment&gt; <span class="title function_">assign</span><span class="params">(Cluster metadata, Map&lt;String, Subscription&gt; subscriptions)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//执行分配的时候会调用这个方法</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onAssignment</span><span class="params">(Assignment assignment)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">default</span> <span class="keyword">void</span> <span class="title function_">onAssignment</span><span class="params">(Assignment assignment, <span class="type">int</span> generation)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.onAssignment(assignment);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//这个分配策略的名字</span></span><br><span class="line">  String <span class="title function_">name</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h1 id="幂等"><a class="markdownIt-Anchor" href="#幂等"></a> 幂等</h1><p>kafka开启幂等性功能：</p><blockquote><ol><li>将生产者的<code>enable.idempotence</code>配置为true，默认为false</li><li>生产者客户端的retries必须大于0</li><li><code>max.in.flight.requests.per.connection</code>不能大于5</li><li>acks设置为-1，即所有副本都同步完成，才给生产者返回成功</li></ol></blockquote><p>为了实现幂等性，kafka引入了producer id（PID）和sequence number的概念。kafka会为每个producer分配一个id，每个生产者发送到每个分区的每条消息都有一个序列号，每发送一条消息，&lt;PID，分区&gt;对应的序列号就会加1。</p><p>broker端会为每个&lt;PID，分区&gt;维护一个序列号：</p><blockquote><p>当收到消息时，只有序列号（SN_new）比旧的序列号（SN_old）大1时，即<code>SN_new = SN_old+1</code>，才会接受它</p><p>如果<code>SN_new &lt; SN_old</code>，则说明这是重复消息，会被丢弃</p><p>如果<code>SN_new &gt; SN_old+1</code>，则说明中间有消息没有写入，出现乱序，即有消息丢失，会抛出OutOfOrderSequenceException异常</p></blockquote><h1 id="事务"><a class="markdownIt-Anchor" href="#事务"></a> 事务</h1><p>要开启事务功能，首先必须开启生产者的幂等性功能。</p><p>通过事务，可以保证跨生产者会话的消息幂等发送和事务恢复。</p><p>需要手动的指定transactionalId，transactionalld与PID一一对应，同时通过一个单调递增的producer epoch保证transactionalld的唯一性。</p><p>Kafka 并不能保证己提交的事务中的所有消息都能够被消费 :</p><blockquote><ol><li>对采用日志压缩策略的主题而言，事务中的某些消息有可能被清理(相同 key 的消息， 后写入的消息会覆盖前面写入的消息)。</li><li>事务中消息可能分布在同一个分区的多个日志分段(LogSegment)中，当老的日志分段被删除时，对应的消息可能会丢失。</li><li>消费者可以通过 seek() 方法访问任意offset的消息，从而可能遗漏事务中的部分消息。</li><li>消费者在消费时可能没有分配到事务内的所有分区，因此它也就不能读取事务中的所有消息。</li></ol></blockquote>]]></content>
    
    
    <summary type="html">kafka客户端的一些细节。</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
</feed>
