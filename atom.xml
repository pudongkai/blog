<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Eoccc的博客</title>
  
  
  <link href="https://eoccc.gitee.io/atom.xml" rel="self"/>
  
  <link href="https://eoccc.gitee.io/"/>
  <updated>2023-04-11T13:08:26.124Z</updated>
  <id>https://eoccc.gitee.io/</id>
  
  <author>
    <name>Eoccc</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>kafka-4 日志存储</title>
    <link href="https://eoccc.gitee.io/2023/04/09/kafka-4%20%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6/"/>
    <id>https://eoccc.gitee.io/2023/04/09/kafka-4%20%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6/</id>
    <published>2023-04-09T14:52:41.000Z</published>
    <updated>2023-04-11T13:08:26.124Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka中，一个分区对应一个日志，为了防止日志过大，又引入了日志段的概念（LogSegment），将日志切分为多个日志段，以便于维护和清理。一个LogSegment对应磁盘上的一个日志文件和两个索引文件。</p><span id="more"></span><h1 id="日志文件"><a class="markdownIt-Anchor" href="#日志文件"></a> 日志文件</h1><h2 id="日志分段"><a class="markdownIt-Anchor" href="#日志分段"></a> 日志分段</h2><p>在 Kafka 中，一个 topic 的消息被存储在一个或多个 partition 中，每个 partition 可以看作是一个有序、不可变的消息日志。为了便于管理和优化磁盘空间的利用，Kafka 中的每个 partition 被分成多个 segment，每个 segment 包含一段连续的消息。</p><p>当一个新消息写入 partition 时，Kafka 会将该消息追加到当前最新的 segment 中。当当前 segment 达到一定大小或者存储时间达到一定阈值时，Kafka 会自动将该 segment 封存（close）并创建一个新的 segment，作为 partition 的新的写入位置。</p><p>封存的 segment 不可修改，这就保证了 Kafka 中的消息具有不可变性和顺序性。同时，封存的 segment 可以被压缩（compaction），即删除已经过期或者被标记为删除的消息，以便更好地管理磁盘空间和减少数据复制的数据量。</p><p>Kafka 中的 segment 大小和存储时间可以通过配置文件进行设置。默认情况下，Kafka 会根据时间和大小两个因素来控制 segment 的滚动，以平衡性能和磁盘空间的利用。</p><p>需要注意的是，segment 大小和存储时间的设置应该根据业务需求和硬件资源情况进行调整。如果 segment 大小设置过小，可能会导致 segment 的切换频繁，影响 Kafka 的性能。如果 segment 存储时间设置过长，可能会导致数据的实时性下降，影响业务应用。</p><h2 id="日志文件结构"><a class="markdownIt-Anchor" href="#日志文件结构"></a> 日志文件结构</h2><img src="https://gitee.com/eoccc/pic-shack/raw/master/o9Qyhuqff.jpeg" alt="o9Qyhuqff.jpeg" style="zoom:60%;"><p>日志的文件夹的命名规则为：tpoic-partition。</p><p>向Log追加消息时是顺序写入的，只有最后一个LogSegment才能写入新的消息，最后一个LogSegment即活跃日志段。</p><p>日志段中包含一个 <strong>.log</strong> 的日志文件，一个 <strong>.index</strong> 的偏移量索引文件，一个 <strong>.timeIndex</strong> 的时间戳索引文件。日志文件和两个索引文件都是根据基准偏移量（固定为20位数字）命名的，即这个LogSegment的第一条日志的偏移量，如第一个LogSegment的基准偏移量为0，则日志文件名为 00000000000000000000.log。</p><p>LogSegment还包括 .deleted, .cleaned, .swap等临时文件，以及 .snapshot, .txnindex, leader-epoch-checkpoint等文件。</p><p>另外，kafka第一次启动的时候，还会创建以下文件：</p><blockquote><ol><li>cleaner-offset-checkpoint</li><li>log-start-offset-checkpoint</li><li>recovery-point offset-checkpoint</li><li>replicat ion-offset-checkpoint</li><li>meta.properties</li></ol></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/l6y5sq3gO.jpeg" alt="img/l6y5sq3gO.jpeg" style="zoom:60%;"><h1 id="kafka压缩算法"><a class="markdownIt-Anchor" href="#kafka压缩算法"></a> Kafka压缩算法</h1><p>Kafka 提供了多种数据压缩技术，可以在不影响数据实时性的前提下，最大限度地利用磁盘空间。Kafka 支持以下三种数据压缩技术：</p><ol><li>GZIP：GZIP 是一种基于 DEFLATE 压缩算法的数据压缩技术，可以实现较高的压缩比。GZIP 压缩后的数据体积更小，可以节省磁盘空间，但是解压缩会消耗一定的 CPU 资源，可能会影响数据的处理性能。</li><li>Snappy：Snappy 是一种基于 Google 的 Zippy 压缩算法的数据压缩技术，可以实现较快的压缩和解压缩速度。Snappy 压缩后的数据体积相对较小，可以在不影响数据处理性能的前提下，实现数据的压缩和解压缩。</li><li>LZ4：LZ4 是一种基于 Lempel-Ziv 算法的数据压缩技术，可以实现较高的压缩和解压缩速度。LZ4 压缩后的数据体积相对较小，可以在不影响数据处理性能的前提下，实现数据的压缩和解压缩。</li></ol><p>Kafka 中的数据压缩技术可以通过配置文件中的 compression.type 参数进行设置，支持多种压缩算法。需要注意的是，不同的压缩算法适用于不同的场景和数据类型，需要根据实际情况选择合适的压缩算法，以达到最优的压缩效果和数据处理性能。</p><p><strong><font color="red">注意：</font>活跃的日志分段不会参与日志压缩。</strong></p><h1 id="日志清理"><a class="markdownIt-Anchor" href="#日志清理"></a> 日志清理</h1><p>Kafka通过三种策略来清理日志文件：基于时间、基于日志大小、基于日志起始偏移量。</p><h2 id="基于时间清理日志"><a class="markdownIt-Anchor" href="#基于时间清理日志"></a> 基于时间清理日志</h2><p>日志删除任务会检查当前日志文件中是否有保留时间超过阈值的日志分段集合，保留时间可以配置毫秒、分钟和小时，优先级依次降低：</p><blockquote><p>log.retention.hours  默认为168，即7天</p><p>log.retention.minutes</p><p><a href="http://log.retention.ms">log.retention.ms</a></p></blockquote><p>查找过期日志分段文件时，先从 .timeindex 时间戳索引文件中获取最后一条索引的时间戳，如果时间戳大于0，则取其值，否则取最后修改时间。</p><p>如果所有的日志分段都已经过期，会先切出一个新的日志分段作为活跃日志分段，再把过期的日志分段删除。</p><p>删除日志分段时，会先从Log对象所维护的日志分段跳跃表中移除待删除的日志分段，以保证没有线程会读取这些日志，然后对日志分段的所有文件添加上 <strong>.deleted</strong> 后缀，最后由 <strong>delete-file</strong> 删除任务删除这些文件。delete-file 任务的执行周期通过 <code>file.delete.delay.ms</code> 配置，默认为1分钟。</p><h2 id="基于大小清理日志"><a class="markdownIt-Anchor" href="#基于大小清理日志"></a> 基于大小清理日志</h2><p>如果Log总size大于 <code>log.retention.bytes</code> 配置的阈值（默认为-1，即不限制），则会先计算需要删除的日志文件的大小，即总size和阈值的差值，然后从第一个日志分段开始计算，找出需要删除的日志分段，然后由删除任务执行删除。</p><p>单个日志分段的大小由 <code>log.segment.bytes</code> 配置，默认为1GB。</p><h2 id="基于起始偏移量清理日志"><a class="markdownIt-Anchor" href="#基于起始偏移量清理日志"></a> 基于起始偏移量清理日志</h2><p>kafka有一个logStartOffset记录了日志文件的其实偏移量，一般是第一个日志文件的baseOffset，但是可能会改变。可以使用 KafkaAdminClient 的 <code>deleteRecords()</code> 方法、或使用 kafka-delete-records.sh脚本修改。</p><p>kafka会将偏移量小于logStartOffset的日志分段删除。如下图会将日志分段1和2删除。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/kFXC6GPCV.jpeg" alt="img/kFXC6GPCV.jpeg" style="zoom:50%;"><h1 id="零拷贝"><a class="markdownIt-Anchor" href="#零拷贝"></a> 零拷贝</h1><p>所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序，减少了内核和用户模式之间的上下文切换 。</p><p>一般情况下，如果我们要把一个数据发送给用户，会经过4次复制，进行了4次上下文切换：</p><blockquote><ol><li>调用 read() 方法，将文件中的内容被复制到内核模式下的 ReadBuffer 中；</li><li>CPU 控制将内核模式数据复制到用户模式下；</li><li>调用 write() 方法，将用户模式下的内容复制到内核模式下的 Socket Buffer 中；</li><li>将 SocketBuffer 中的数据复制到网卡设备中传迭。</li></ol></blockquote><p>在零拷贝中，直接将 SocketBuffer 中的数据复制到网卡设备中传迭，只需要进行2次复制，进行了2次上下文切换：</p><blockquote><ol><li>read() 方法，将文件的内容复制到内核模式下的 ReadBuffer 中；</li><li>将<strong>包含数据的位置和长度信息的文件描述符</strong>添加到 Socket Buffer 中；</li><li>将 SocketBuffer 中的数据复制到网卡设备中传送。</li></ol></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;Kafka中，一个分区对应一个日志，为了防止日志过大，又引入了日志段的概念（LogSegment），将日志切分为多个日志段，以便于维护和清理。一个LogSegment对应磁盘上的一个日志文件和两个索引文件。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>写出整洁代码的tips</title>
    <link href="https://eoccc.gitee.io/2023/04/04/%E5%86%99%E5%87%BA%E6%95%B4%E6%B4%81%E4%BB%A3%E7%A0%81%E7%9A%84tips/"/>
    <id>https://eoccc.gitee.io/2023/04/04/%E5%86%99%E5%87%BA%E6%95%B4%E6%B4%81%E4%BB%A3%E7%A0%81%E7%9A%84tips/</id>
    <published>2023-04-04T14:52:41.000Z</published>
    <updated>2023-04-05T11:39:44.483Z</updated>
    
    <content type="html"><![CDATA[<p>一开始就要写整洁的代码，如果有不整洁的代码就要及时的整改，绝对不要有以后再改,以后再说的想法，因为：</p><p><strong><font color="red">letter equals never!</font></strong></p><span id="more"></span><p>不整洁的代码随着时间的增加而增加时，生产力会随之降低，导致的结果就是：</p><ul><li>代码不易扩展或扩展容易引发其他问题</li><li>程序崩溃</li><li>加班</li></ul><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230404210606658.png" alt="image-20230404210606658"></p><h1 id="命名"><a class="markdownIt-Anchor" href="#命名"></a> 命名</h1><p>好的命名可提高代码的可读性，让人见码知意，降低理解成本，提高效率，减少加班！</p><p><strong>1. 无意义的命名</strong></p><p>从命名上完全看不出方法或类的功能，没有任何意义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ABC</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">abc</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好的命名可以直接看出功能，开发者不需要阅读代码细节就能知道其作用。good case：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Animal</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">walk</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>2. 混淆的命名</strong></p><p>命名前后不一致，相同的功能，在不同的方法中使用不同的命名，造成混淆：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">StudentRepository</span> &#123;</span><br><span class="line">    </span><br><span class="line">    Student <span class="title function_">findOneById</span><span class="params">(<span class="meta">@Param(&quot;id&quot;)</span> String id)</span>;</span><br><span class="line"></span><br><span class="line">    List&lt;Student&gt; <span class="title function_">queryAllStudent</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>两个方法都是查Student，唯一的区别就是查一个和查全部，但是用了<font color=" #DB7093">find</font>和<font color=" #DB7093">query</font>命名。优化后：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">StudentRepository</span> &#123;</span><br><span class="line">   </span><br><span class="line">    Student <span class="title function_">findOne</span><span class="params">(<span class="meta">@Param(&quot;id&quot;)</span> String id)</span>;</span><br><span class="line"></span><br><span class="line">    List&lt;Student&gt; <span class="title function_">findAll</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="单一职责"><a class="markdownIt-Anchor" href="#单一职责"></a> 单一职责</h1><p><strong>类应该短小，类或模块应有且只有一条加以修改的理由</strong>，如果一个类过于庞大的话,那么说明它承担的职责过多了。</p><p>类的名称描述其全责，如果无法为某个类命以准确的名称，这个类大概就太长了，类名越含糊，可能拥有越多的职责。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">UpdateDB</span> &#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insertUser</span><span class="params">(User user)</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insertOrder</span><span class="params">(Order order)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个类的职责太大了，从类名不能直接看出这个类操作的是哪个数据库，将职责抽开：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">UpdateUserDB</span> &#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insertUser</span><span class="params">(User user)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="开闭原则"><a class="markdownIt-Anchor" href="#开闭原则"></a> 开闭原则</h1><p>开闭原则：面向修改关闭，面向扩展开放。</p><p>面向修改关闭意味着增加新的逻辑不会修改原有的代码，降低了出错的可能性。</p><p>面向扩展开放则是提高了代码的可扩展性，可很容易的增加新的代码逻辑。</p><p>不满足开闭原则的例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insert</span><span class="params">(User user)</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">(User user)</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">delete</span><span class="params">(User user)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果我们要新增查询操作，就得修改这个类，没有做到面向修改关闭。优化后：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">invoke</span><span class="params">(User user)</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">InsertSql</span> <span class="keyword">extends</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">invoke</span><span class="params">(User user)</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UpdateSql</span> <span class="keyword">extends</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">invoke</span><span class="params">(User user)</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用：</span></span><br><span class="line"><span class="meta">@Resource</span></span><br><span class="line">Sql insertSql;</span><br><span class="line"></span><br><span class="line">insertSql.invoke(user);</span><br></pre></td></tr></table></figure><h1 id="高内聚低耦合"><a class="markdownIt-Anchor" href="#高内聚低耦合"></a> 高内聚低耦合</h1><p>将一个复杂的系统分解成更小的、可管理的部分，并通过将这些部分彼此隔离来降低它们之间的耦合度。</p><p>函数的第一规则是短小，第二规则是更短小，短小到只做一件事情。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String <span class="title function_">upload</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">// 校验图片的方法 代码80行</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 压缩图片的方法 代码50行</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 返回成功或失败标识 0,1 代码5行</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;0&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>原有的upload方法做了很多的事情，重构后只做了一件事情：<strong>把大一些的概念拆分为另一抽象层上的一系列步骤：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String <span class="title function_">upload</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">// 校验图片的方法</span></span><br><span class="line">    check();</span><br><span class="line">    <span class="comment">// 压缩图片的方法</span></span><br><span class="line">    compress();</span><br><span class="line">    <span class="comment">// 返回成功或失败标识 0,1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;0&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="函数命名"><a class="markdownIt-Anchor" href="#函数命名"></a> 函数命名</h1><p>函数要有描述性的名称，不要害怕长名称。</p><p>不好的命名方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String <span class="title function_">addCharacter</span><span class="params">(String originString, <span class="type">char</span> ch)</span>;</span><br></pre></td></tr></table></figure><p>从函数字面意思看是给某个字符串添加一个字符。但是到底是在原有字符串首部添加，还是在原有字符串末尾追加呢？亦或是在某个固定位置插入呢？从函数名字完全看不出来这个函数的真正意图，只能继续往下读这个函数的具体实现才知道。</p><p>优化后：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 追加到末尾</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">appendCharacter</span><span class="params">(String originString, <span class="type">char</span> ch)</span>;   </span><br><span class="line"></span><br><span class="line"><span class="comment">// 插入指定位置</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">insertCharacter</span><span class="params">(String originString, <span class="type">char</span> ch, <span class="type">int</span> insertPosition)</span>;</span><br></pre></td></tr></table></figure><h1 id="参数"><a class="markdownIt-Anchor" href="#参数"></a> 参数</h1><p><strong>参数越少越好</strong></p><p>参数越少，越容易理解，参数超过三个可以将参数进行封装，要按参数的语义进行封装，不一定封装成一个大而全的参数，可以封装为多个，原则是按语义补充。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;Student&gt; <span class="title function_">findStudent</span><span class="params">(<span class="type">int</span> age, String name, String country, <span class="type">int</span> gender)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//封装参数</span></span><br><span class="line"><span class="keyword">public</span> List&lt;Student&gt; <span class="title function_">findStudent</span><span class="params">(Student student)</span>;</span><br></pre></td></tr></table></figure><p><strong>不要使用标识参数</strong></p><p>标识参数是参数为 Boolean 类型，用户传递 true or false。不要使用标识参数因为这意味着你的函数违背了单一职责(true false 两套逻辑)。正确的做法是拆分为两个方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//标识参数方法</span></span><br><span class="line">order4User(<span class="type">boolean</span> isNewUser);</span><br><span class="line"></span><br><span class="line"><span class="comment">//重构为两个方法</span></span><br><span class="line">order4NewUser();</span><br><span class="line">order4OldUser();</span><br></pre></td></tr></table></figure><p><strong>不要使用输出参数</strong></p><p>输出参数就是将变量作为参数传入方法，并且将变量返回。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">findStudent</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">Student</span> <span class="variable">student</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Student</span>();</span><br><span class="line">    doSomething(student);</span><br><span class="line">    <span class="keyword">return</span> student;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> Student <span class="title function_">doSomething</span><span class="params">(Student student)</span>&#123;</span><br><span class="line">    <span class="comment">// 省略一些student逻辑</span></span><br><span class="line">    <span class="keyword">return</span> student;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果只看方法名称，我们不知道doSomething做了些什么，返回的参数和传入的参数是不是同一个，需要看具体的逻辑才知道。</p><p>正确的方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将doSomething()方法内聚到student对象本身</span></span><br><span class="line">student.doSomething();</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;一开始就要写整洁的代码，如果有不整洁的代码就要及时的整改，绝对不要有以后再改,以后再说的想法，因为：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;font color=&quot;red&quot;&gt;letter equals never!&lt;/font&gt;&lt;/strong&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>kafka-3 客户端</title>
    <link href="https://eoccc.gitee.io/2023/04/03/kafka-3%20%E5%AE%A2%E6%88%B7%E7%AB%AF/"/>
    <id>https://eoccc.gitee.io/2023/04/03/kafka-3%20%E5%AE%A2%E6%88%B7%E7%AB%AF/</id>
    <published>2023-04-03T14:52:41.000Z</published>
    <updated>2023-04-11T12:43:34.446Z</updated>
    
    <content type="html"><![CDATA[<p>总结kafka客户端的分区策略、幂等性和事务。</p><span id="more"></span><h1 id="消费者分区分配策略"><a class="markdownIt-Anchor" href="#消费者分区分配策略"></a> 消费者分区分配策略</h1><p>消费者消费消息之前，首先得进行分区分配，kafka提供了三种分区分配策略。</p><ol><li><p><strong>RangeAssignor 按跨度进行分配</strong></p><p>kafka会先按照分区总数和消费者总数进行整除，获得一个跨度，然后按照分区跨度进行平均分配，确保分区尽可能平均的分配给所有的消费者。对于剩余的分区（分区总数 % 消费者总数），则前面的消费者（消费者名称按字典序排序）会多分配一个分区。</p><p>假设 n=分区数/消费者数量， m=分区数%消费者数量，那么前 m 个消费者每个分配 n+1 个 分区，后面的(消费者数量～m)个消费者每个分配 n个分区。</p><p>这种分配方式存在一个问题，如果存在多个topic的分区不是消费者总数的整数倍，那么排在前面的消费者会被多分配多个分区。</p><blockquote><p>假设有两个topic，每个topic有4个分区，分配结果为：</p><p>Consumer0:  t0p0,t0p1, t1p0,t1p1</p><p>Consumer1:  t0p2,t0p3, t1p2,t1p3</p><p>但是如果有两个topic，且个topic有3个分区，分配结果为：</p><p>Consumer0:  t0p0,tp1, t1p0,t1p1</p><p>Consumer1:  t0p2,t1p2</p></blockquote></li><li><p><strong>RoundRobinAssignor 按顺序分配</strong></p><p>将消费组内所有的消费者及消费者订阅的所有topic的分区按照字典序排序，然后通过轮询的方式将分区依此分配给每个消费者。</p><p>这种分配方式如果消费组内所有的消费者订阅的topic都是相同的，那么分区会被很均匀的分配给每个消费者，但是如果消费者订阅的topic不同，就会导致分配不均匀。</p><blockquote><p>假设消费者C0订阅了主题t0；假设消费者C1订阅了主题t0和t1；假设消费者C2订阅了主题t0，t1和t2。t0、t1、t2的分区数分别为1、2、3。此时分配结果为：</p><p>C0: t0p0</p><p>C1: t1p0</p><p>C2: t1p1, t2p0,t2p1,t2p2</p><p>这种分配方式不完美，因为可以将 t1p1分配给C1。</p></blockquote></li><li><p><strong>StickyAssignor 粘性分配</strong></p><p>这是目前最优秀的分区分配策略。Kafka从0.11x开始引入这种分配策略，尽可能保证：分区分配均匀，分区分配尽可能与上一次分配相同</p><p>再分配的时候，会将需要分配的分区平均的分配给消费者。</p><blockquote><p>RoundRobinAssignor中提到的例子，使用StickyAssignor的分配结果为：</p><p>C0: t0p0</p><p>C1: t1p0, <strong>t1p1</strong></p><p>C2: t2p0,t2p1,t2p2</p><p>假设StickyAssignor当前的分区分配为：</p><p>C0: t0p0, t1p1, t3p0</p><p>C1: t0p1, t2p1, t3p1</p><p>C2: t1p0, t2p1</p><p>消费者C1脱离了消费组，则分配结果为：</p><p>C0: t0p0, t1p1, t3p0, <strong>t201</strong></p><p>C2: t1p0, t2p1, <strong>t0p1, t3p1</strong></p></blockquote></li><li><p>自定义分区分配策略</p><p>实现PartitionAssignor接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">PartitionAssignor</span> &#123;</span><br><span class="line">  <span class="comment">//提供订阅的消息</span></span><br><span class="line">  Subscription <span class="title function_">subscription</span><span class="params">(Set&lt;String&gt; topics)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//实现具体的分配逻辑</span></span><br><span class="line">  Map&lt;String, Assignment&gt; <span class="title function_">assign</span><span class="params">(Cluster metadata, Map&lt;String, Subscription&gt; subscriptions)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//执行分配的时候会调用这个方法</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onAssignment</span><span class="params">(Assignment assignment)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">default</span> <span class="keyword">void</span> <span class="title function_">onAssignment</span><span class="params">(Assignment assignment, <span class="type">int</span> generation)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.onAssignment(assignment);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//这个分配策略的名字</span></span><br><span class="line">  String <span class="title function_">name</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h1 id="幂等"><a class="markdownIt-Anchor" href="#幂等"></a> 幂等</h1><p>kafka开启幂等性功能：</p><blockquote><ol><li>将生产者的<code>enable.idempotence</code>配置为true，默认为false</li><li>生产者客户端的retries必须大于0</li><li><code>max.in.flight.requests.per.connection</code>不能大于5</li><li>acks设置为-1</li></ol></blockquote><p>为了实现幂等性，kafka引入了producer id（PID）和sequence number的概念。kafka会为每个producer分配一个id，每个生产者发送到每个分区的每条消息都有一个序列号，每发送一条消息，&lt;PID，分区&gt;对应的序列号就会加1。</p><p>broker端会为每个&lt;PID，分区&gt;维护一个序列号：</p><blockquote><p>当收到消息时，只有序列号（SN_new）比旧的序列号（SN_old）大1时，即SN_new=SN_old+1，才会接受它</p><p>如果新的序列号小于旧的序列号，则说明这是重复消息，会被丢弃</p><p>如果SN_new&gt;SN_old+1，则说明中间有消息没有写入，出现乱序，即有消息丢失，会抛出OutOfOrderSequenceException异常</p></blockquote><h1 id="事务"><a class="markdownIt-Anchor" href="#事务"></a> 事务</h1><p>要开启事务功能，首先必须开启生产者的幂等性功能。</p><p>通过事务，可以保证跨生产者会话的消息幂等发送和事务恢复。</p><p>需要手动的指定transactionalId，transactionalld与PID一一对应，同时通过一个单调递增的producer epoch保证transactionalld的唯一性。</p><p>Kafka 并不能保证己提交的事务中的所有消息都能够被消费 :</p><blockquote><ol><li>对采用日志压缩策略的主题而言，事务中的某些消息有可能被清理(相同 key 的消息， 后写入的消息会覆盖前面写入的消息)。</li><li>事务中消息可能分布在同一个分区的多个日志分段(LogSegment)中，当老的日志分段被删除时，对应的消息可能会丢失。</li><li>消费者可以通过 seek()方法访问任意offset的消息，从而可能遗漏事务中的部分消息。</li><li>消费者在消费时可能没有分配到事务内的所有分区，因此它也就不能读取事务中的所有消息。</li></ol></blockquote>]]></content>
    
    
    <summary type="html">kafka客户端的一些细节。</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka-2 消费者</title>
    <link href="https://eoccc.gitee.io/2023/03/30/kafka-2%20%E6%B6%88%E8%B4%B9%E8%80%85/"/>
    <id>https://eoccc.gitee.io/2023/03/30/kafka-2%20%E6%B6%88%E8%B4%B9%E8%80%85/</id>
    <published>2023-03-30T14:52:41.000Z</published>
    <updated>2023-04-06T15:12:42.293Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka的消费者负责订阅topic，并从订阅的topic上拉取消息。kafka的消费层还有一个消费组（consumer group），每个consumer都有一个消费组，消息会发给订阅了这个topic的<strong>所有</strong>消费组，并由消费组中的<strong>一个</strong>消费者进行消费。</p><span id="more"></span><h1 id="消费者与消费组"><a class="markdownIt-Anchor" href="#消费者与消费组"></a> 消费者与消费组</h1><p>某个主题中共有4个分区(Partition)：P0、P1、P2、P3。有两个消费组A和B都订阅了这个主题，消费组A中有4个消费者(C0、C1、C2和C3)，消费组B中有2个消费者C4和C5)。按照Kafka默认的规则，最后的分配结果是消费组A中的每一个消费者分配到1个分区，消费组B中的每一个消费者分配到2个分区，两个消费组之间互不影响。每个消费者只能消费所分配到的分区中的消息。换言之，每一个分区只能被一个消费组中的一个消费者所消费。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20220803203252462.png" alt="image-20220803203252462" style="zoom:65%;"><p>如果消费者的个数大于分区的个数，则有的消费者会分配不到分区。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20220803203324669.png" alt="image-20220803203324669" style="zoom:50%;"><p>一个消费者只会属于一个消费组，消费模式可以分为点对点模式和发布订阅模式：</p><blockquote><ul><li><p>点对点模式：</p><p>所有消费者都属于同一个消费组，partition会均衡地分配给每一个消费者，从而消息会均衡地发送给消费者，每条消息只会被消费一次</p></li><li><p>发布/订阅模式（广播）：</p><p>每个消费者属于一个单独的消费组，每个消费组都订阅topic，消息会发送给所有的消费组，即一条消息会被每个消费者都消费一遍</p></li></ul></blockquote><h1 id="订阅消息"><a class="markdownIt-Anchor" href="#订阅消息"></a> 订阅消息</h1><p>Kafka一个消费者可以订阅一个或多个消息主题，支持多种订阅消息的方式。</p><ul><li><p>订阅一个或多个topic</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">subscribe</span><span class="params">(Collection&lt;String&gt; topics)</span></span><br></pre></td></tr></table></figure></li><li><p>根据正则表达式订阅主题</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">subscribe</span><span class="params">(Pattern pattern)</span></span><br></pre></td></tr></table></figure></li><li><p>订阅指定的分区</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">assign</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br></pre></td></tr></table></figure><p>TopicPartition对象中包含了topic和partation两个参数。</p></li></ul><p>如果我们需要知道某个topic的分区信息，可以通过<code>KafkaConsumer.partitionsFor(String tpoic)</code>进行查询，返回一个<code>List&lt;PartitionInfo&gt;</code>列表，PartitionInfo包含了这个topic的分区信息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Part</span>工tioninfo &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> String topic;              <span class="comment">//topic</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> partition;             <span class="comment">//分区</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Node leader;               <span class="comment">//这个分区的leader节点</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span>  Node[] replicas;          <span class="comment">//所有副本 ASR</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span>  Node[] inSyncReplicas;    <span class="comment">//同步副本 ISR</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Node[] offlineReplicas;    <span class="comment">//离线副本 OSR</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="消费消息"><a class="markdownIt-Anchor" href="#消费消息"></a> 消费消息</h1><p>Kafka采用poll的方式从服务端拉取消息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> ConsumerRecords&lt;K, V&gt; <span class="title function_">poll</span><span class="params">(<span class="keyword">final</span> Duration timeout)</span></span><br></pre></td></tr></table></figure><p>ConsumerRecords的内部包括了ConsumerRecord，用来存储一次拉取获得的消息集，提供了一个iterator来遍历消息集内部的消息。</p><p>我们可以通过下面的方法获取一个分区的消息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;ConsumerRecord&lt;K, V&gt; <span class="title function_">records</span><span class="params">(TopicPartition partition)</span></span><br></pre></td></tr></table></figure><p>ConsumerRecord中比较关键的属性：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConsumerRecord</span>&lt;K, V&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;                 <span class="comment">//主题</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> partition;                <span class="comment">//分区</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> offset;                  <span class="comment">//这个消息在分区中的偏移量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> timestamp;               <span class="comment">//时间戳</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> TimestampType timestampType;  <span class="comment">//时间戳的类型，有CreateTime和LogAppendTime两种类型</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> serializedKeySize;        <span class="comment">//key序列化器</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> serializedValueSize;      <span class="comment">//value序列化器</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers headers;              <span class="comment">//</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;                        <span class="comment">//消息的key</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> V value;                      <span class="comment">//消息的value</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Optional&lt;Integer&gt; leaderEpoch;<span class="comment">//leader的纪元</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> Long checksum;             <span class="comment">//CRC32校验值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="位移提交"><a class="markdownIt-Anchor" href="#位移提交"></a> 位移提交</h1><p>Kafka中每条消息都有唯一的offset，用来表示消息在分区中的位置。消费者也保存了一个offset，用来记录消费到分区中某个消息所在的位置。</p><p>在旧的消费者客户端中，offset是保存在zookeeper中的，而在新的消费者客户端中，是保存在kafka的内部主题__consumer_offsets中。</p><p>如果消费者当前消费到了x，需要提交的位移为x+1。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/ktk3vy8Mu.jpeg" alt="ktk3vy8Mu.jpeg"></p><p><strong>消费者提交偏移量的时机</strong></p><p>消费者提交偏移量，有可能会造成重复消费和消息丢失现象。</p><blockquote><ul><li>拉取到消息立即提交offset，如果这批消息消费的过程中出现了异常，导致部分消息没有消费，就会导致消息丢失</li><li>消息消费完再提交offset，如果这批消息消费的过程中出现了异常，消费了部分消息，但是由于没有消费完，没有提交offset，就会导致消息重复消费</li></ul></blockquote><p>kafka默认是自动提交的，即定期提交，默认是5s提交一次。<code>enable.auto.commit</code>开启自动提交，<code>auto.commit.interval.ms</code>配置提交的时间。自动提交的操作是在KafkaConsumer#poll()中完成的。消费者每隔5秒就会拉取每个分区中的最小offset进行提交，另外，每次向服务端发起拉取消息的请求的时候，都会检查是否可以提交offset，如果可以，就会提交。</p><p>自动提交存在的问题：</p><blockquote><ul><li>重复消费：消费者拉取了一批消息x+1～x+5，消费到x+3的时候，自动提交了一次offset，这一批消息消费完了，但是拉取消息的时候没有提交offset（条件不满足，还不可以自动提交），然后消费者继续消费，消费到x+7的时候，消费者崩溃了，就需要重新从x+3的offset处开始消费，就会导致重复消费。可以减小自动提交的时间窗口。</li><li>消息丢失：异步拉取消息，并发消费这种情况下会导致消息丢失。比如有一个异步线程一直在拉取消息，然后保存在本地，然后有两个线程并发的消费消息，线程A消费x+1～x+5的batch，线程B消费x+6～x+10的batch，消费者自动提交了x+8的offset，但是线程A才消费到了x+3，这是线程A发生了异常，重新消费的时候，就会从x+6的位置开始消费，x+3～x+5的消息就会丢失，而且x+6～x+10的消息会被重复消费。</li></ul></blockquote><p>kafka可以手动提交偏移量，需要将配置<code>enable.auto.commit</code>关闭，然后使用<code>commitSync()</code>方法提交offset。</p><p>一个示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (isRunning.get()) &#123;</span><br><span class="line">ConsumerRecords&lt;String, String&gt; records= consumer.poll(<span class="number">1000</span>);</span><br><span class="line">  <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line"><span class="comment">//do some logical processing .</span></span><br><span class="line">&#125;</span><br><span class="line">  consumer.commitSync();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="控制消费"><a class="markdownIt-Anchor" href="#控制消费"></a> 控制消费</h1><p>KafkaConsumer可以使用pause方法暂停消费，使用resume方法恢复消费：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">pause</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">resume</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br></pre></td></tr></table></figure><p>关闭客户端：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">(Duration timeout)</span></span><br></pre></td></tr></table></figure><h1 id="指定消费位移"><a class="markdownIt-Anchor" href="#指定消费位移"></a> 指定消费位移</h1><p>当一个新的消费组建立的时候，或订阅一个新的tpoic的时候，或当__consumer_offsets主题中关于这个消费组的偏移量消息过期后，没有可以查找的offset，这时会根据消费者的<code>auto.offset.reset</code>配置来决定从什么地方开始消费：</p><blockquote><ul><li>latest：默认值，从下一条写入的消息开始消费</li><li>earliest：从起始处开始消费</li><li>none：抛出NoOffsetForPartitionException异常</li></ul></blockquote><p>kafka还可以通过seek()方法，更细粒度的从指定的位置开始消费。seek()只能重置分配到分区的消费者的位置，所以在重置之前，还得先poll()一次。</p><p>kafka还提供了两个快速seek的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">seekToBeginning</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">seekToEnd</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br></pre></td></tr></table></figure><p>另外可以通过offsetsForTimes方法获取指定时间的offset：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Map&lt;TopicPartition, OffsetAndTimestamp&gt; <span class="title function_">offsetsForTimes</span><span class="params">(Map&lt;TopicPartition, Long&gt; timestampsToSearch)</span></span><br></pre></td></tr></table></figure><p>kafka有再均衡监听器ConsumerRebalanceListener，可以在再均衡之前和重新分配分区之后做一些操作，如在再均衡之前提交当前的offset</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ConsumerRebalanceListener</span> &#123;</span><br><span class="line">  <span class="comment">//再均衡之前调用</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; var1)</span>;</span><br><span class="line"><span class="comment">//重新分配分区之后调用</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; var1)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="消费者拦截器"><a class="markdownIt-Anchor" href="#消费者拦截器"></a> 消费者拦截器</h1><p>消费者拦截器可以在消费消息或者提交偏移量的时候做一些操作，实现ConsumerInterceptor接口即可：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ConsumerInterceptor</span>&lt;K, V&gt; <span class="keyword">extends</span> <span class="title class_">Configurable</span>, AutoCloseable &#123;</span><br><span class="line">  <span class="comment">//消费消息之前会调用这个方法</span></span><br><span class="line">  <span class="comment">//我们可以通过这个方法修改消息，或者做一些过滤等</span></span><br><span class="line">  ConsumerRecords&lt;K, V&gt; <span class="title function_">onConsume</span><span class="params">(ConsumerRecords&lt;K, V&gt; var1)</span>;</span><br><span class="line">  <span class="comment">//提交偏移量之前会调用</span></span><br><span class="line">  <span class="comment">//我们可以通过这个方法获取一些偏移量提交的细节</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onCommit</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; var1)</span>;</span><br><span class="line">  <span class="comment">//关闭的时候会调用</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;Kafka的消费者负责订阅topic，并从订阅的topic上拉取消息。kafka的消费层还有一个消费组（consumer group），每个consumer都有一个消费组，消息会发给订阅了这个topic的&lt;strong&gt;所有&lt;/strong&gt;消费组，并由消费组中的&lt;strong&gt;一个&lt;/strong&gt;消费者进行消费。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka-1 生产者</title>
    <link href="https://eoccc.gitee.io/2023/03/29/kafka-1%20%E7%94%9F%E4%BA%A7%E8%80%85/"/>
    <id>https://eoccc.gitee.io/2023/03/29/kafka-1%20%E7%94%9F%E4%BA%A7%E8%80%85/</id>
    <published>2023-03-29T14:52:41.000Z</published>
    <updated>2023-04-03T15:20:56.712Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka的生产者发送数据时，先将数据缓存到记录收集器RecordAccumulator中，再由发送线程Sender将消息批量地发送给服务端。</p><span id="more"></span><p>Kafka生产者的客户端是KafkaProducer。发送消息的入口是KafkaProducer.send，提供了同步和异步的方式，异步的方式支持回调功能：</p><blockquote><p>同步：send(ProducerRecord&lt;K, V&gt; record)</p><p>异步：send(ProducerRecord&lt;K, V&gt; record, Callback callback)</p></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20220731211734632.png" alt="image-20220731211734632" style="zoom:45%;"><h1 id="序列化"><a class="markdownIt-Anchor" href="#序列化"></a> 序列化</h1><p>Kafka在发送消息之前，会先进行序列化，key和value可以使用不同的序列化器：</p><blockquote><ul><li>key的序列化器通过<code>key.serializer</code>配置，默认使用JsonSerializer</li><li>value的序列化器通过<code>value.serializer</code>配置，默认使用JsonSerializer</li></ul></blockquote><p>JsonSerializer底层使用的是<code>com.fasterxml.jackson.databind.ObjectMapper</code>进行序列化。</p><p>手动指定序列化方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;10.0.55.229:9092&quot;</span>);</span><br><span class="line">props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(props);</span><br></pre></td></tr></table></figure><h2 id="自定义序列化"><a class="markdownIt-Anchor" href="#自定义序列化"></a> 自定义序列化</h2><p>和内置的StringSerializer字符串序列化一样，如果要自定义序列化方式，需要实现接口<strong>Serializer</strong>。下面是一个简单的自定义实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySerializer</span> <span class="keyword">implements</span> <span class="title class_">Serializer</span>&lt;Order&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; configs, <span class="type">boolean</span> isKey)</span> &#123;</span><br><span class="line">        Serializer.<span class="built_in">super</span>.configure(configs, isKey);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">byte</span>[] serialize(String s, Order order) &#123;</span><br><span class="line">        <span class="keyword">return</span> JSON.toJSONString(order).getBytes();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">byte</span>[] serialize(String topic, Headers headers, Order data) &#123;</span><br><span class="line">        <span class="keyword">return</span> JSON.toJSONString(data).getBytes();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">        Serializer.<span class="built_in">super</span>.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="自定义反序列化"><a class="markdownIt-Anchor" href="#自定义反序列化"></a> 自定义反序列化</h2><p>和内置的StringDeserializer字符串反序列化一样，如果要自定义反序列化方式，需要实现接口<strong>Deserializer</strong>。下面是一个简单的自定义实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyDeserializer</span> <span class="keyword">implements</span> <span class="title class_">Deserializer</span>&lt;Order&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map configs, <span class="type">boolean</span> isKey)</span> &#123;</span><br><span class="line">        Deserializer.<span class="built_in">super</span>.configure(configs, isKey);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Order <span class="title function_">deserialize</span><span class="params">(String s, <span class="type">byte</span>[] bytes)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">json</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(bytes);</span><br><span class="line">        <span class="keyword">return</span> JSON.parseObject(json, Order.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Order <span class="title function_">deserialize</span><span class="params">(String topic, Headers headers, <span class="type">byte</span>[] data)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">json</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(data);</span><br><span class="line">        <span class="keyword">return</span> JSON.parseObject(json, Order.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">        Deserializer.<span class="built_in">super</span>.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="选择分区"><a class="markdownIt-Anchor" href="#选择分区"></a> 选择分区</h1><p>Kafka的消息分为有key和没有key两种，通常情况下是没有key的。针对两种情况，有不同的分区逻辑。</p><p><strong>有key的消息</strong></p><p>对于有key的消息，kafka会根据key进行散列，key相同的消息会发送到相同的分区中。</p><p><strong>没有key的消息</strong></p><p>当消息没有指定key时，如果是第一次向服务端发送消息（这个topic还没有分配过分区），则随机分配一个分区，否则采用轮询的方式分配分区。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes, Cluster cluster)</span> &#123;</span><br><span class="line">  List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">  <span class="type">int</span> <span class="variable">numPartitions</span> <span class="operator">=</span> partitions.size();</span><br><span class="line">  <span class="comment">// 没有key的时候，随机分配分区</span></span><br><span class="line">  <span class="keyword">if</span> (keyBytes == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="comment">// 选择分区</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">nextValue</span> <span class="operator">=</span> nextValue(topic);</span><br><span class="line">    List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">    <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="type">int</span> <span class="variable">part</span> <span class="operator">=</span> Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">      <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">      <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 有key的时候直接根据key的hash值进行散列</span></span><br><span class="line">    <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">    <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="title function_">nextValue</span><span class="params">(String topic)</span> &#123;</span><br><span class="line">  <span class="type">AtomicInteger</span> <span class="variable">counter</span> <span class="operator">=</span> topicCounterMap.get(topic);</span><br><span class="line">  <span class="keyword">if</span> (<span class="literal">null</span> == counter) &#123;</span><br><span class="line">    <span class="comment">// 如果这个topi是第一次推送消息，随机分配一个分区</span></span><br><span class="line">    counter = <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(ThreadLocalRandom.current().nextInt());</span><br><span class="line">    <span class="type">AtomicInteger</span> <span class="variable">currentCounter</span> <span class="operator">=</span> topicCounterMap.putIfAbsent(topic, counter);</span><br><span class="line">    <span class="keyword">if</span> (currentCounter != <span class="literal">null</span>) &#123;</span><br><span class="line">      counter = currentCounter;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 轮询分配分区</span></span><br><span class="line">  <span class="keyword">return</span> counter.getAndIncrement();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>直接指定分区</strong></p><p>Kafka支持直接指定分区，可以在创建ProducerRecord的时候，直接指定分区。ProducerRecord提供了多个指定分区的构造方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(ProducerRecord&lt;K, V&gt; record, <span class="type">byte</span>[] serializedKey, <span class="type">byte</span>[] serializedValue, Cluster cluster)</span> &#123;</span><br><span class="line">  <span class="type">Integer</span> <span class="variable">partition</span> <span class="operator">=</span> record.partition();</span><br><span class="line">  <span class="comment">// 优先使用指定的分区</span></span><br><span class="line">  <span class="keyword">return</span> partition != <span class="literal">null</span> ?</span><br><span class="line">    partition :</span><br><span class="line">  partitioner.partition(</span><br><span class="line">    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>**注意：**分配分区的时候，会过滤掉不健康的分区。</p><p>kafka节点健康的标准：</p><ol><li>存在于ISR集合中（保持正常的同步）</li><li>与zookeeper保持心跳（健康检查）</li></ol><h1 id="客户端消息收集器"><a class="markdownIt-Anchor" href="#客户端消息收集器"></a> 客户端消息收集器</h1><p>Kafka的生产者发送数据时，先将数据缓存到记录收集器RecordAccumulator中，再由发送线程Sender将消息批量地发送给服务端。</p><p>每个分区都有一个<strong>双端队列</strong>来缓存客户端的消息，队列中的每个元素是一个批记录（ProducerBatch），如果一个批记录满了，就会创建一个新的批记录，并将已经满的批记录交给sender线程发送到服务端。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RecordAccumulator.<span class="type">RecordAppendResult</span> <span class="variable">result</span> <span class="operator">=</span> accumulator.append(tp, timestamp, serializedKey,</span><br><span class="line">                    serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line"><span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">  <span class="comment">// 如果批记录满了，唤醒sender线程</span></span><br><span class="line">  <span class="built_in">this</span>.sender.wakeup();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>批记录的大小通过<code>batch.size</code>来配置，默认是16kb。如果一条消息的大小超过了16kb，会创建一个能够容纳这条消息的批记录。</p><p>另外，如果一个批记录很长时间没有满，sender线程会定时的将批记录发送给服务端，避免过长的延时。延时通过<code>linger.ms</code>来配置，默认是0ms，即有消息就会马上发送到服务端。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20220727101124764.png" alt="image-20220727101124764" style="zoom:50%;"><h1 id="客户端消息发送线程"><a class="markdownIt-Anchor" href="#客户端消息发送线程"></a> 客户端消息发送线程</h1><p>Kafka发送消息时，为了减少网络的开销，会将属于一个节点的所有partation的消息放在一个批次，同时进行发送。如果我们有两台服务器，topic有6个partation，每台服务器有3个partation，如果迭代每个partation的批记录，直接发送到主副本节点，则会有6次请求；如果把属于同一个节点的所有partation放在一起发送，就只会有2次请求。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/_REu1TGqm.jpeg" alt="_REu1TGqm.jpeg" style="zoom:80%;"><p>消息发送线程发送消息的步骤：</p><blockquote><ol><li>获取可以发送的批记录（每个批记录属于一个partation）</li><li>遍历每个批记录，获取每个批记录对应的主副本节点：nodeId</li><li>将所有的批记录以nodeId为key，group成一个map：modeId -&gt; List&lt;ProducerBatch&gt;</li><li>发送消息到每个主副本节点</li></ol></blockquote><p>客户端发送完消息后，会执行<code>KafkaClient#poll</code>方法，执行回调方法以及一些后续的处理。回调方法时保存在ClientRequest中的，为了在收到服务端返回后能够执行回调方法，发送线程会保存目标节点到客户端请求的映射关系。</p><ul><li><p>**不需要响应的流程 ：**开始发送请求→添加客户端请求到队列→发送请求→请求发送成功→从队列中删除发送请求→构造客户端响应。</p></li><li><p>**需要晌应的流程：**开始发送请求→添加客户端请求到队列→发送请求→请求发送成功→等待接收响应→接收响应→接收到完整的响应→从队列中删除客户端请求→构造客户端响应。</p></li></ul><p>整体流程：</p><blockquote><ol><li>KafkaProducer将消息存到消息收集器RecordAccumulator中</li><li>Sender从RecordAccumulator获取消息</li><li>Sender将需要发送的批记录根据目标节点进行分类</li><li>Sender创建ClientRequest</li><li>Sender调用KafkaClient.send方法发送消息（具体实现是NetworkClient）</li><li>NetworkClient调用Selector.send</li><li>Selector创建KafkaChanel，并将请求写入通道</li><li>Sender调用KafkaClient.poll方法触发KafkaChanel真正执行发送，并执行回调方法</li></ol></blockquote><h1 id="生产者拦截器"><a class="markdownIt-Anchor" href="#生产者拦截器"></a> 生产者拦截器</h1><p>生产者拦截器既可以用来在消息发送前做一些准备工作， 比如按照某个规则过滤不符合要求的消息、修改消息的内容等， 也可以用来在执行回调逻辑前做一些定制化的需求，比如统计类工作。</p><p>使用生产者拦截器，只需要实现Producerlnterceptor，然后配置<code>interceptor.classes </code>即可，包含三个方法：</p><ol><li>onSend()方法：在将消息序列化和计算分区之前会调用，对消息进行相应的定制化操作；</li><li>onAcknowledgement()方法：在消息被应答(Acknowledgement)之前或消息发送失败时调用，在callback之前。<strong>这个方法在producer的I/O线程中，所以逻辑应该尽量简单，否则会影响消息的发送。</strong></li><li>close()方法：在关闭拦截器时执行一些资源的清理工作。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ProducerInterceptor</span>&lt;K, V&gt; <span class="keyword">extends</span> <span class="title class_">Configurable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> ProducerRecord&lt;K, V&gt; <span class="title function_">onSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="重要的消费者参数"><a class="markdownIt-Anchor" href="#重要的消费者参数"></a> 重要的消费者参数</h1><ol><li><p>acks</p><blockquote><ul><li>acks=1。默认值。生产者需要收到服务端的响应才算发送消息成功。<em>如果服务端leader收到数据，但是follower还没有同步数据，此时leader副本崩溃，会丢失消息。如果发生leader选举，会返回一个错误消息。</em></li><li>acks=0。生产者发送消息之后不需要等待服务端响应。</li><li>acks=-1或acks=all。生产者发送消息之后，需要等待ISR中所有副本都成功写入消息之后，才能收到服务端的成功响应。<em>ISR中只有一个副本时，还是会丢失消息</em></li></ul></blockquote></li><li><p>max.request.size</p><blockquote><p>生产者客户端能发送消息的最大值，默认1MB。修改这个参数的时候还需要修改broker<code>message.max.bytes</code>参数，比如生产者的<code>max.request.size</code>配置成20，但是broker的<code>message.max.bytes</code>配置成10，此时发送了一个15B的消息，服务端就接收不了。</p></blockquote></li><li><p><a href="http://xn--retriesretry-4l2u.backoff.ms">retries和retry.backoff.ms</a></p><blockquote><ul><li><code>retries</code>用来配置生产者的重试次数，默认为0，即发生异常时不重试。如果重试的次数超过配置的次数，仍然失败，就会返回异常</li><li><code>retry.backoff.ms</code>用来配置两次重试之间的时间间隔，默认为100。</li></ul></blockquote><p>Kafka的同一个topic中的消息时有序的，生产者会按照发送的顺序发送给服务端，消费者也可以按照同样的顺序进行消费。如果配置了重试，而且配置的发送消息的并发数大于1（max.in.flight.requests.per.connection），此时第一批消息写入失败，而第二批消息写入成功，就会导致消息的顺序不一致。</p></li><li><p>batch.size</p><blockquote><p>生产者客户端发送消息，一个批次的大小，一个批次满了以后，就会发送到服务端。</p></blockquote></li><li><p><a href="http://linger.ms">linger.ms</a></p><blockquote><p>生产者客户端等待发送一批消息的最长时间，默认为0。即有消息就会发送到服务端。</p></blockquote></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;Kafka的生产者发送数据时，先将数据缓存到记录收集器RecordAccumulator中，再由发送线程Sender将消息批量地发送给服务端。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo远程调用将对象转成了Map</title>
    <link href="https://eoccc.gitee.io/2023/03/23/Dubbo%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E5%B0%86%E5%AF%B9%E8%B1%A1%E8%BD%AC%E6%88%90%E4%BA%86Map/"/>
    <id>https://eoccc.gitee.io/2023/03/23/Dubbo%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E5%B0%86%E5%AF%B9%E8%B1%A1%E8%BD%AC%E6%88%90%E4%BA%86Map/</id>
    <published>2023-03-23T06:10:32.000Z</published>
    <updated>2023-03-26T08:43:20.713Z</updated>
    
    <content type="html"><![CDATA[<p>Dubbo远程调用返回结果后，反序列化的时候将对象反序列化成了Map，对象的属性作为key。</p><span id="more"></span><p>事情是这样的，在一个正常的dubbo接口升级过程中，我们升级了下游系统的jar包，然后调用下游接口的时候，拿到的返回结果中，有一个对象转成了HashMap。离了大谱。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230324102621382.png" alt="image-20230324102621382"></p><p>对比了一番线上代码和本地代码，发下这个<strong>对象中多了一个字段，而且这个字段对应的类在本地代码中没有</strong>。</p><p>然后又找下游系统沟通，发现这个类其实是在另一个jar包中！也就是说这个接口的返回值中的对象来自于两个jar包，但是这两个jar包在我们系统中是分别单独引用的，而又只升级了其中的一个，所以导致新节点的对象不存在。</p><p>随后就简单了，升级另一个jar包，重新部署就解决问题了。</p><p><strong>那么</strong></p><p><font color="red"><strong>为什么少了类会导致对象反序列化成了HashMap？</strong></font></p><p>Hassian反序列化的入口是<code>Hessian2Input#readObject()</code>。</p><ol><li><code>readObject</code>执行反序列化</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Object <span class="title function_">readObject</span><span class="params">(List&lt;Class&lt;?&gt;&gt; expectedTypes)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">tag</span> <span class="operator">=</span> _offset &lt; _length ? (_buffer[_offset++] &amp; <span class="number">0xff</span>) : read();</span><br><span class="line">    <span class="keyword">switch</span> (tag) &#123;</span><br><span class="line">        ...</span><br><span class="line">      <span class="keyword">case</span> <span class="number">0x6f</span>: &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">ref</span> <span class="operator">=</span> tag - <span class="number">0x60</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (_classDefs == <span class="literal">null</span>)</span><br><span class="line">                <span class="keyword">throw</span> error(<span class="string">&quot;No classes defined at reference &#x27;&#123;0&#125;&#x27;&quot;</span> + tag);</span><br><span class="line"></span><br><span class="line">            <span class="type">ObjectDefinition</span> <span class="variable">def</span> <span class="operator">=</span> (ObjectDefinition) _classDefs.get(ref);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> readObjectInstance(<span class="literal">null</span>, def);</span><br><span class="line">        &#125;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>接着调用<code>Hessian2Input#readObjectInstance</code></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Object <span class="title function_">readObjectInstance</span><span class="params">(Class cl, ObjectDefinition def)</span></span><br><span class="line">        <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">type</span> <span class="operator">=</span> def.getType();</span><br><span class="line">    String[] fieldNames = def.getFieldNames();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cl != <span class="literal">null</span>) &#123;</span><br><span class="line">        Deserializer reader;</span><br><span class="line">        reader = findSerializerFactory().getObjectDeserializer(type, cl);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> reader.readObject(<span class="built_in">this</span>, fieldNames);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> findSerializerFactory().readObject(<span class="built_in">this</span>, type, fieldNames);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>核心代码：<code>findSerializerFactory().getObjectDeserializer(type, cl);</code></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Reads the object as a map.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> Deserializer <span class="title function_">getObjectDeserializer</span><span class="params">(String type, Class cl)</span></span><br><span class="line">        <span class="keyword">throws</span> HessianProtocolException &#123;</span><br><span class="line">    <span class="comment">// 获取反序列化具体实现</span></span><br><span class="line">    <span class="type">Deserializer</span> <span class="variable">reader</span> <span class="operator">=</span> getObjectDeserializer(type);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cl == <span class="literal">null</span></span><br><span class="line">            || cl.equals(reader.getType())</span><br><span class="line">            || cl.isAssignableFrom(reader.getType())</span><br><span class="line">            || reader.isCustom()</span><br><span class="line">            || HessianHandle.class.isAssignableFrom(reader.getType())) &#123;</span><br><span class="line">        <span class="keyword">return</span> reader;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (log.isLoggable(Level.FINE)) &#123;</span><br><span class="line">        log.fine(<span class="string">&quot;hessian: expected &#x27;&quot;</span> + cl.getName() + <span class="string">&quot;&#x27; at &#x27;&quot;</span> + type + <span class="string">&quot;&#x27; (&quot;</span></span><br><span class="line">                + reader.getType().getName() + <span class="string">&quot;)&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> getDeserializer(cl);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Reads the object as a map.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> Deserializer <span class="title function_">getObjectDeserializer</span><span class="params">(String type)</span></span><br><span class="line">        <span class="keyword">throws</span> HessianProtocolException &#123;</span><br><span class="line">    <span class="type">Deserializer</span> <span class="variable">deserializer</span> <span class="operator">=</span> getDeserializer(type);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 因为不存在类型，所以这里 deserializer 为null</span></span><br><span class="line">    <span class="keyword">if</span> (deserializer != <span class="literal">null</span>)</span><br><span class="line">        <span class="keyword">return</span> deserializer;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (_hashMapDeserializer != <span class="literal">null</span>)</span><br><span class="line">        <span class="comment">// 如果缓存中有 _hashMapDeserializer，直接返回</span></span><br><span class="line">        <span class="keyword">return</span> _hashMapDeserializer;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 否则创建一个MapDeserializer，保存在缓存中，然后返回</span></span><br><span class="line">        _hashMapDeserializer = <span class="keyword">new</span> <span class="title class_">MapDeserializer</span>(HashMap.class);</span><br><span class="line">        <span class="keyword">return</span> _hashMapDeserializer;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="4"><li>获取反序列化器</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Returns a deserializer based on a string type.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> Deserializer <span class="title function_">getDeserializer</span><span class="params">(String type)</span></span><br><span class="line">        <span class="keyword">throws</span> HessianProtocolException &#123;</span><br><span class="line">    <span class="keyword">if</span> (type == <span class="literal">null</span> || type.equals(<span class="string">&quot;&quot;</span>) || _typeNotFoundDeserializerMap.containsKey(type))</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">    Deserializer deserializer;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果之前已经获取过了，直接从缓存里面取出来返回</span></span><br><span class="line">    <span class="keyword">if</span> (_cachedTypeDeserializerMap != <span class="literal">null</span>) &#123;</span><br><span class="line">        deserializer = (Deserializer) _cachedTypeDeserializerMap.get(type);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (deserializer != <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span> deserializer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 静态类型的反序列化器</span></span><br><span class="line">    deserializer = (Deserializer) _staticTypeMap.get(type);</span><br><span class="line">    <span class="keyword">if</span> (deserializer != <span class="literal">null</span>)</span><br><span class="line">        <span class="keyword">return</span> deserializer;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 集合类型</span></span><br><span class="line">    <span class="keyword">if</span> (type.startsWith(<span class="string">&quot;[&quot;</span>)) &#123;</span><br><span class="line">        <span class="type">Deserializer</span> <span class="variable">subDeserializer</span> <span class="operator">=</span> getDeserializer(type.substring(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (subDeserializer != <span class="literal">null</span>)</span><br><span class="line">            deserializer = <span class="keyword">new</span> <span class="title class_">ArrayDeserializer</span>(subDeserializer.getType());</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            deserializer = <span class="keyword">new</span> <span class="title class_">ArrayDeserializer</span>(Object.class);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (_unrecognizedTypeCache.get(type) == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 未识别出来的类型</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 因为class不存在，这里会抛异常</span></span><br><span class="line">            <span class="type">Class</span> <span class="variable">cl</span> <span class="operator">=</span> loadSerializedClass(type);</span><br><span class="line">            deserializer = getDeserializer(cl);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// 缓存到 _unrecognizedTypeCache 中，以免一直抛异常，影响性能</span></span><br><span class="line">            log.warning(<span class="string">&quot;Hessian/Burlap: &#x27;&quot;</span> + type + <span class="string">&quot;&#x27; is an unknown class in &quot;</span> + _loader + <span class="string">&quot;:\n&quot;</span> + e);</span><br><span class="line">            _typeNotFoundDeserializerMap.put(type, PRESENT);</span><br><span class="line">            log.log(Level.FINER, e.toString(), e);</span><br><span class="line">            _unrecognizedTypeCache.put(type, <span class="keyword">new</span> <span class="title class_">AtomicLong</span>(<span class="number">1L</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 记录次数，到了2000次后重置为1</span></span><br><span class="line">        <span class="comment">// 为什么要重置为1？到最大值后就不再累加不是更好？</span></span><br><span class="line">        ((AtomicLong) _unrecognizedTypeCache.get(type)).incrementAndGet();</span><br><span class="line">        <span class="keyword">if</span> (((AtomicLong) _unrecognizedTypeCache.get(type)).get() % <span class="number">2000L</span> == <span class="number">0L</span>)</span><br><span class="line">            ((AtomicLong) _unrecognizedTypeCache.get(type)).getAndSet(<span class="number">1L</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (deserializer != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (_cachedTypeDeserializerMap == <span class="literal">null</span>)</span><br><span class="line">            _cachedTypeDeserializerMap = <span class="keyword">new</span> <span class="title class_">ConcurrentHashMap</span>(<span class="number">8</span>);</span><br><span class="line"></span><br><span class="line">        _cachedTypeDeserializerMap.put(type, deserializer);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 因为前面抛异常了，所以这里 deserializer 仍然为null</span></span><br><span class="line">    <span class="keyword">return</span> deserializer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="5"><li>经过前面的一通操作，最后获取到了MapDeserializer序列化器，就是反序列化成HashMap。<code>MapDeserializer#readObject</code>：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">readObject</span><span class="params">(AbstractHessianInput in,</span></span><br><span class="line"><span class="params">                         String[] fieldNames)</span></span><br><span class="line">        <span class="keyword">throws</span> IOException &#123;bhjl0</span><br><span class="line">    <span class="type">Map</span> <span class="variable">map</span> <span class="operator">=</span> createMap();</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> <span class="variable">ref</span> <span class="operator">=</span> in.addRef(map);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; fieldNames.length; i++) &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> fieldNames[i];</span><br><span class="line"></span><br><span class="line">        map.put(name, in.readObject());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> map;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;Dubbo远程调用返回结果后，反序列化的时候将对象反序列化成了Map，对象的属性作为key。&lt;/p&gt;</summary>
    
    
    
    
    <category term="踩坑" scheme="https://eoccc.gitee.io/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>Http、TCP和UDP</title>
    <link href="https://eoccc.gitee.io/2023/03/14/Http%E3%80%81TCP%E5%92%8CUDP/"/>
    <id>https://eoccc.gitee.io/2023/03/14/Http%E3%80%81TCP%E5%92%8CUDP/</id>
    <published>2023-03-14T07:25:43.000Z</published>
    <updated>2023-03-26T09:09:44.530Z</updated>
    
    <content type="html"><![CDATA[<p>从 Http1.1 到 Http2，Http 协议一直都是使用 TCP 作为传输协议。然而在最新的 Http3把 TCP 抛弃了，而是基于 UDP 协议的基础上，在应用层实现了一个可靠的传输协议 —— QUIC。</p><span id="more"></span><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319173208876.png" alt="640-20230319173208876.png" style="zoom:80%;"><h1 id="tcp的特点"><a class="markdownIt-Anchor" href="#tcp的特点"></a> TCP的特点</h1><h2 id="超时重传"><a class="markdownIt-Anchor" href="#超时重传"></a> 超时重传</h2><p>TCP协议是一种面向连接的可靠的传输层协议，它保证数据可靠传输的基本原理是在发送一个数据之后，就开启一个定时器，若是在这个时间内没有收到刚才发送数据的ACK确认报文（是通过确认序号的方式进行确认，即刚才发送数据的序列号+1），则对该报文进行重传。如果一直失败，满一定次数后就会放弃并发送一个复位信号。</p><h2 id="按序接收"><a class="markdownIt-Anchor" href="#按序接收"></a> 按序接收</h2><p>TCP协议是一种面向连接的可靠的传输层协议，它保证数据可靠传输的基本原理是在发送一个数据之后，就开启一个定时器，若是在这个时间内没有收到刚才发送数据的ACK确认报文（是通过确认序号的方式进行确认，即刚才发送数据的序列号+1），则对该报文进行重传。如果一直失败，满一定次数后就会放弃并发送一个复位信号。</p><ol><li>为了保证数据包的可靠传递，发送方必须把已发送的数据包保留在缓冲区；</li><li>并为每个已发送的数据包启动一个超时定时器；</li><li>如在定时器超时之前收到了对方发来的应答信息（可能是对本包的应答，也可以是对本包后续包的应答），则释放该数据包占用的缓冲区;</li><li>否则，重传该数据包，直到收到应答或重传次数超过规定的最大次数为止。</li><li>接收方收到数据包后，先进行CRC校验，如果正确则把数据交给上层协议，然后给发送方发送一个累计应答包，表明该数据已收到，如果接收方正好也有数据要发给发送方，应答包也可方在数据包中捎带过去。</li></ol><h2 id="流量控制"><a class="markdownIt-Anchor" href="#流量控制"></a> 流量控制</h2><p>如果发送者发送数据过快，接收者来不及接收，那么就会有分组丢失。为了避免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。</p><p>流量控制由滑动窗口协议（连续ARQ协议）实现。滑动窗口协议既保证了分组无差错、有序接收，也实现了流量控制。主要的方式就是接收方返回的 ACK 中会包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。</p><h3 id="流量控制引发死锁"><a class="markdownIt-Anchor" href="#流量控制引发死锁"></a> 流量控制引发死锁</h3><p>当发送者收到了一个窗口为0的应答，发送者便停止发送，等待接收者的下一个应答。但是如果这个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁。<br>为了避免流量控制引发死锁，TCP使用了持续计时器。每当发送者收到一个0窗口的ack后就启动该计时器。时间一到便主动发送报文询问接收者的窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生。</p><h2 id="拥塞控制"><a class="markdownIt-Anchor" href="#拥塞控制"></a> 拥塞控制</h2><p>拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况；常用的方法就是：慢开始，拥塞避免，快重传，快恢复。</p><h3 id="慢开始算法"><a class="markdownIt-Anchor" href="#慢开始算法"></a> 慢开始算法</h3><p>慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口cwnd（congestion window）的大小。</p><p>一个传输轮次所经历的时间其实就是往返时间RTT，而且每经过一个传输轮次（transmission round），拥塞窗口cwnd就加倍。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230320010432039.png" alt="image-20230320010432039" style="zoom:46%;"><p>为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量。ssthresh的用法如下：</p><ol><li>当cwnd &lt; ssthresh时，使用慢开始算法</li><li>当cwnd = ssthresh时，慢开始与拥塞避免算法任意</li><li>当cwnd &gt; ssthresh时，改用拥塞避免算法</li></ol><h3 id="拥塞避免算法"><a class="markdownIt-Anchor" href="#拥塞避免算法"></a> 拥塞避免算法</h3><p>拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。</p><p>无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理）：</p><ol><li>把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半（但不能小于2）</li><li>把拥塞窗口cwnd重新设置为1，执行慢开始算法</li></ol><p>这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230320011037345.png" alt="image-20230320011037345" style="zoom:50%;"><blockquote><ol><li>拥塞窗口cwnd初始化为1个报文段，慢开始门限初始值为16</li><li>执行慢开始算法，指数规律增长到第4轮，即cwnd=16=ssthresh，改为执行拥塞避免算法，拥塞窗口按线性规律增长</li><li>假定cwnd=24时，网络出现超时（拥塞），则更新后的ssthresh=12，cwnd重新设置为1，并执行慢开始算法</li><li>当cwnd=12=ssthresh时，改为执行拥塞避免算法</li></ol></blockquote><h3 id="快重传算法"><a class="markdownIt-Anchor" href="#快重传算法"></a> 快重传算法</h3><p>快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方，可提高网络吞吐量约20%）。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230320011420526.png" alt="image-20230320011420526" style="zoom: 50%;"><h3 id="快恢复算法"><a class="markdownIt-Anchor" href="#快恢复算法"></a> 快恢复算法</h3><p>当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞）。但是接下去并不执行慢开始算法（如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞）。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230320011607939.png" alt="image-20230320011607939" style="zoom:50%;"><h1 id="tcp-存在队头阻塞问题"><a class="markdownIt-Anchor" href="#tcp-存在队头阻塞问题"></a> TCP 存在队头阻塞问题</h1><p>TCP 队头阻塞的问题要从两个角度看，一个是<strong>发送窗口的队头阻塞</strong>，另外一个是<strong>接收窗口的队头阻塞</strong>。</p><h2 id="发送窗口的队头阻塞"><a class="markdownIt-Anchor" href="#发送窗口的队头阻塞"></a> 发送窗口的队头阻塞</h2><p>TCP 发送出去的数据，都是需要按序确认的，只有在数据都被按顺序确认完后，发送窗口才会往前滑动。举个例子，比如下图的发送方把发送窗口内的数据全部都发出去了，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据的。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640.png" alt="640.png"></p><p>接着，当发送方收到对第 32~36 字节的 ACK 确认应答后，则<strong>滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认</strong>，接下来第 52~56 字节又变成了可用窗口，那么后续也就可以发送 52~56 这 5 个字节的数据了。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319173701699.png" alt="640-20230319173701699.png"></p><p><strong>但是如果某个数据报文丢失或者其对应的 ACK 报文在网络中丢失，会导致发送方无法移动发送窗口，这时就无法再发送新的数据</strong>，只能超时重传这个数据报文，直到收到这个重传报文的 ACK，发送窗口才会移动，继续后面的发送行为。</p><p>举个例子，比如下图，客户端是发送方，服务器是接收方。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319173855342.png" alt="640-20230319173855342.png"></p><p>客户端发送了第 5～9 字节的数据，但是第 5 字节的 ACK 确认报文在网络中丢失了，那么即使客户端收到第 6～9 字节的 ACK 确认报文，发送窗口也不会往前移动。</p><p><strong>此时的第 5 字节相当于“队头”，因为没有收到“队头”的 ACK 确认报文，导致发送窗口无法往前移动，此时发送方就无法继续发送后面的数据，相当于按下了发送行为的暂停键，这就是发送窗口的队头阻塞问题</strong>。</p><h2 id="接收窗口的队头阻塞"><a class="markdownIt-Anchor" href="#接收窗口的队头阻塞"></a> 接收窗口的队头阻塞</h2><p>接收方收到的数据范围必须在接收窗口范围内，如果收到超过接收窗口范围的数据，就会丢弃该数据，比如下图接收窗口的范围是 32 ～ 51 字节，如果收到第 52 字节以上数据都会被丢弃。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319174054907.png" alt="640-20230319174054907.png"></p><p>当接收窗口收到有序数据时，接收窗口才能往前滑动，然后那些已经接收并且被确认的「有序」数据就可以被应用层读取。</p><p>但是，<strong>当接收窗口收到的数据不是有序的，比如收到第 33～40 字节的数据，由于第 32 字节数据没有收到， 接收窗口无法向前滑动，那么即使先收到第 33～40 字节的数据，这些数据也无法被应用层读取的</strong>。只有当发送方重传了第 32 字节数据并且被接收方收到后，接收窗口才会往前滑动，然后应用层才能从内核读取第 32～40 字节的数据。</p><h2 id="http2的队头阻塞"><a class="markdownIt-Anchor" href="#http2的队头阻塞"></a> Http2的队头阻塞</h2><p>Http2 通过抽象出 Stream 的概念，实现了 Http 并发传输，一个 Stream 就代表 Http1.1 里的请求和响应。不同 Stream 的帧可以乱序发送（因此可以并发不同的 Stream ），因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 Http 消息，而同一 Stream 内部的帧必须是严格有序的。</p><p><strong>但是 Http2 多个 Stream 请求都是在一条 TCP 连接上传输，这意味着多个 Stream 共用同一个 TCP 滑动窗口，那么当发生数据丢失，滑动窗口是无法往前移动的，此时就会阻塞住所有的 Http 请求，这属于 TCP 层队头阻塞</strong>。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319223934662.png" alt="640-20230319223934662.png"></p><h1 id="http3-quic"><a class="markdownIt-Anchor" href="#http3-quic"></a> Http3 QUIC</h1><h2 id="没有队头阻塞的-quic"><a class="markdownIt-Anchor" href="#没有队头阻塞的-quic"></a> 没有队头阻塞的 QUIC</h2><p>QUIC 也借鉴 HTTP/2 里的 Stream 的概念，在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (Stream)。但是<strong>QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口</strong>。</p><p>假如 Stream2 丢了一个 UDP 包，也只会影响 Stream2 的处理，不会影响其他 Stream。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319224200820.png" alt="640-20230319224200820.png"></p><h2 id="减少建立连接延迟"><a class="markdownIt-Anchor" href="#减少建立连接延迟"></a> 减少建立连接延迟</h2><p>对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，<strong>先 TCP 握手（1RTT），再 TLS 握手（2RTT）</strong>，所以需要 3RTT 的延迟才能传输数据，就算 Session 会话复用，也需要至少 2 个 RTT，这在一定程序上增加了数据传输的延迟。</p><p><em>RTT(Round-Trip Time)：表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认，不包含数据传输时间）总共经历的时间。</em></p><p><strong>HTTP/3首次建立连接的步骤：</strong></p><blockquote><ol><li><p>第一次握手：客户端向服务器发送一个Initial Packet，该数据包包含以下信息：</p><ul><li>目标服务器的IP地址和端口号</li><li>客户端的Connection ID</li><li>客户端的TLS证书</li></ul><p>服务器收到Initial Packet后，发送一个Response Packet，该数据包包含以下信息：</p><ul><li>服务器的Connection ID</li><li>服务器的TLS证书</li></ul></li><li><p>第二次握手：客户端向服务器发送一个0-RTT Packet，该数据包包含客户端的请求信息。由于客户端发送了0-RTT数据包，因此在第二次握手中，服务器不需要等待客户端发送请求数据。</p><p>服务器收到0-RTT Packet后，发送一个Handshake Packet，该数据包包含以下信息：</p><ul><li>服务器的Connection ID</li><li>ACK确认客户端的Connection ID</li><li>传输参数，例如初始拥塞窗口大小和最大数据包大小等</li></ul></li><li><p>连接建立完成：客户端收到服务器发送的Handshake Packet后，连接建立完成，客户端可以开始发送请求数据。</p></li></ol></blockquote><p>在重新连接的时候，HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</p><p>HTTP/3 的 QUIC 协议并不是与 TLS 分层（因为 QUIC 也是应用层实现的协议），所以可以<strong>将 QUIC 和 TLS 协议握手的过程合并在一起</strong>，QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319231040877.png" alt="640-20230319231040877.png"></p><h3 id="0-rtt-重放攻击"><a class="markdownIt-Anchor" href="#0-rtt-重放攻击"></a> 0-RTT 重放攻击</h3><p><strong>什么是重放攻击</strong></p><p>重放攻击（Replay Attack）是指攻击者在通信过程中截获了合法的通信报文，将其保存下来，并在稍后的某个时间重放这些报文，以达到欺骗或攻击的目的。重放攻击通常用于绕过身份验证或者欺骗服务器接受恶意请求，从而造成安全问题。</p><p>为了防止重放攻击，常用的方法是在通信过程中添加<strong>时间戳</strong>或者<strong>随机数</strong>等非重复性的因素，并对每个通信报文进行唯一性标识，以确保每个报文只能被使用一次。同时，还可以使用<strong>数字签名</strong>等技术对通信报文进行验证和加密，从而确保数据的完整性和安全性。</p><p><strong>HTTP/3解决0-RTT导致的重放攻击方式：</strong></p><p>为了解决这个问题，HTTP/3采用了“0-RTT数据包使用0-RTT密钥”的机制，即客户端和服务器在0-RTT数据传输期间使用不同的密钥进行加密和解密。客户端在发送0-RTT数据包时使用之前的会话密钥，而服务器只有在验证了该密钥的有效性后才会使用新生成的密钥。这样可以确保0-RTT数据包的安全性，但也会增加一些复杂性和延迟。因此，在使用0-RTT技术时，需要权衡安全性和性能之间的关系，谨慎决策。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;从 Http1.1 到 Http2，Http 协议一直都是使用 TCP 作为传输协议。然而在最新的 Http3把 TCP 抛弃了，而是基于 UDP 协议的基础上，在应用层实现了一个可靠的传输协议 —— QUIC。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>JVM虚拟机-ZGC</title>
    <link href="https://eoccc.gitee.io/2022/12/08/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA-ZGC/"/>
    <id>https://eoccc.gitee.io/2022/12/08/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA-ZGC/</id>
    <published>2022-12-08T07:25:43.000Z</published>
    <updated>2023-02-07T03:49:44.798Z</updated>
    
    <content type="html"><![CDATA[<p>ZGC(Z Garbage Collector)是一款在JDK 11中新加入的具有实验性质的低延迟垃圾收集器。</p><span id="more"></span><p>ZGC希望在尽可能对吞吐量影响不太大的前提下，实现在任意堆内存大小下都可以把垃圾收集的停顿时间限制在10ms以内的低延迟。</p><p>ZGC基于Region内存布局，(暂时) 不设分代，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-整理算法。</p><h1 id="内存布局"><a class="markdownIt-Anchor" href="#内存布局"></a> 内存布局</h1><p>ZGC采用基于Region的堆内存布局，ZGC的Region具有动态性——动态创建和销毁，以及动态的区域容量大小。在x64硬件平台下，ZGC的Region可以具有如图3-19所示的大、中、小三类容量：</p><ul><li>小型Region：容量为2MB，用于放置小于256KB的小对象</li><li>中型Region：容量为32MB，用于放置大于等于256KB，小于4MB的对象</li><li>大型Region：容量不固定，可以动态变化，但必须为2MB的整数倍。用于放置大于4MB的大对象。大型Region不会被重分配。</li></ul><h1 id="染色指针"><a class="markdownIt-Anchor" href="#染色指针"></a> 染色指针</h1><p>ZGC收集器有一个标志性的设计是它采用的染色指针技术(Colored Pointer)，直接将少量额外的信息存储在指针上。</p><p>Linux下64位指针的高18位不能用来寻址，但剩余的46位指针所能支持的64T B内存在今天仍然能够充分满足大型服务器的需要。鉴于此，ZGC的染色指针技术继续盯上了这剩下的46位指针宽度，将其高4位提取出来存储四个标志信息。通过这些标志位，虚拟机可以直接从指针中看到其引用对 象的三色标记状态、是否进入了重分配集(即被移动过)、是否只能通过finaliz e()方法才能被访问 到，如图3-20所示。当然，由于这些标志位进一步压缩了原本就只有46位的地址空间，也直接导致ZGC能够管理的内存不可以超过4TB(2的42次幂)。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20221211183456746.png" alt="image-20221211183456746"></p><p>虽然染色指针有4TB的内存限制，不能支持32位平台，不能支持压缩指针(-XX:+UseCompressedOops)等诸多约束，但它带来的收益也是非常可观的：</p><ol><li>一旦某个Region的存活对象被移走以后，这个region可以立即被释放掉，而不必等整个堆中所有指向该Region的引用都被修正后才能清理。（好处：ZGC只要有一个空闲的Region，就能够完成收集。）</li><li>可以减少在垃圾收集过程中内存屏障的使用，提高性能。设置内存屏障，尤其是写屏障的目的通常是为了记录对象引用的变动情况，如果将这些信息直接维护在指针中，显然就可以省去一些 专门的记录操作。（实际上，到目前为止ZGC都并未使用任何写屏障，只使用了读屏障。）</li><li>染色指针可以作为一种可扩展的存储结构用来记录更多与对象标记、重定位过程相关的数据，以便日后进一步提高性能。比如可以开发Linux下的64位指针中剩余的18位，用来记录一些其他信息。</li></ol><h1 id="垃圾回收"><a class="markdownIt-Anchor" href="#垃圾回收"></a> 垃圾回收</h1><p>ZGC的垃圾回收过程大致可划分为四个大的阶段。全部四个阶段都是可以并发执行的，仅是两个阶段中间会存在短暂的停顿小阶段。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20221211202804016.png" alt="image-20221211202804016"></p><ol><li><p>并发标记</p><p>遍历对象图做可达性分析，类似于G1，也会经过初始标记、最终标记的短暂STW，但是ZGC的标记是在指针上完成的，而不是在对象上。</p></li><li><p>并发预备重分配</p><p>根据特定的查询条件统计出本次收集过程要清理哪些region，这些region组成重分配集（Relocation Set），注意，ZGC每次回收都会扫描所有的region，用更大范围的扫描成本替换G1中的记忆集的维护成本。重分配集里面的对象会被复制到其他region中，里面的region会被释放。</p></li><li><p>并发重分配</p><p>把重分配集中的存活对象复制到新的region上，并为重分配集中的每个region维护一个转发表，记录从旧对象到新对象的转向关系。</p><p>ZGC根据染色指针就能知道一个对象是否处于重分配集中，当访问这个对象的时候，会被读内存屏障捕获，然后根据转发表将访问转发到新的对象上，同时更新引用的值（ZGC将这一过程称为“自愈”，类似于redis的rehash过程）。</p></li><li><p>并发重映射</p><p>修正重分配集中存活对象的引用，但是这个阶段ZGC并没有主动去完成，而是放在了下一次GC的并发标记阶段，反正并发标记的时候要遍历堆的所有对象。</p></li></ol><h1 id="zgc的缺点"><a class="markdownIt-Anchor" href="#zgc的缺点"></a> ZGC的缺点</h1><ol><li><p>没有分代</p><p>ZGC没有引入分代，每次回收都需要扫描整个堆的所有对象。</p></li><li><p>浮动垃圾</p><p>ZGC每次都会对整个堆进行回收，回收垃圾的整个过程耗时较长，并发标记的时候会产生浮动垃圾，如果系统持续高速的产生浮动垃圾的话，回收到的内存空间持续小于回收期间产生的浮动垃圾占用的空间，就会导致堆可用的空间越来越小，最终OOM。目前唯一的办法就是增加堆的容量，让ZGC获得更多的喘息空间。</p><p>要根本解决这个问题，还是得引入分代，让新对象在一个专门的区域中创建，然后对这块区域进行频率更高、更快的收集。</p></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;ZGC(Z Garbage Collector)是一款在JDK 11中新加入的具有实验性质的低延迟垃圾收集器。&lt;/p&gt;</summary>
    
    
    
    
    <category term="JVM" scheme="https://eoccc.gitee.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>JVM虚拟机-jdk工具</title>
    <link href="https://eoccc.gitee.io/2022/12/04/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA-jdk%E5%B7%A5%E5%85%B7/"/>
    <id>https://eoccc.gitee.io/2022/12/04/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA-jdk%E5%B7%A5%E5%85%B7/</id>
    <published>2022-12-04T07:25:43.000Z</published>
    <updated>2023-03-10T09:49:12.146Z</updated>
    
    <content type="html"><![CDATA[<p>JDK自带了很多小工具，打包、部署、签名、调试、监控、运维等 各种场景都可能会用到它们。</p><span id="more"></span><h1 id="jps虚拟机进程状态"><a class="markdownIt-Anchor" href="#jps虚拟机进程状态"></a> jps：虚拟机进程状态</h1><p>jps类似于linux的ps命令，可以列出正在运行的虚拟机进程，显示主类的名称及该进程的id。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps [options] [hostid]</span><br></pre></td></tr></table></figure><p>列出java进程：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">jps -l</span></span><br><span class="line">22407 org.jetbrains.jps.cmdline.Launcher</span><br><span class="line">22408 com.intellij.rt.junit.JUnitStarter</span><br><span class="line">22415 jdk.jcmd/sun.tools.jps.Jps</span><br></pre></td></tr></table></figure><p>jps还可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态，hostid的定义：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;hostid&gt;:      &lt;hostname&gt;[:&lt;port&gt;]</span><br></pre></td></tr></table></figure><p>jps可选参数：</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>-q</td><td>只列出进程id</td></tr><tr><td>-m</td><td>输出虚拟机进程启动时传给主类main函数的参数</td></tr><tr><td>-l</td><td>输出主类的全名，如果进程执行的是jar包，则数据jar的路径</td></tr><tr><td>-v</td><td>输出jvm虚拟机的执行参数</td></tr></tbody></table><h1 id="jstat虚拟机统计信息监视工具"><a class="markdownIt-Anchor" href="#jstat虚拟机统计信息监视工具"></a> jstat：虚拟机统计信息监视工具</h1><p>Jstat可以显示本地或者远程虚拟机进程中的类加载、内存、垃圾收集、即时编译等运行时数据。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstat [ option vmid [interval[s|ms] [count]] ]</span><br></pre></td></tr></table></figure><p>vmid：对于本地虚拟机进程，填LVMID就可以；对于远程虚拟机，格式为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[protocol:][//]lvmid[@hostname[:port]/servername]</span><br></pre></td></tr></table></figure><p>参数int erval和count 代表查询间隔和次数，如果省略这2个参数，说明只查询一次。假设需要每250 毫秒查询一次进程2764垃圾收集状况，一共查询20次，那命令应当是:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstat -gc 2764 250 20</span><br></pre></td></tr></table></figure><p>选项option代表用户希望查询的虚拟机信息，主要分为三类：类加载、垃圾收集、运行期编译状况。</p><p><img src="/.io//image-20221213102254091.png" alt="image-20221213102254091"></p><h1 id="jinfo-java配置信息工具"><a class="markdownIt-Anchor" href="#jinfo-java配置信息工具"></a> jinfo: Java配置信息工具</h1><p>实时查看和调整虚拟机各项参数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jinfo [ option ] pid</span><br></pre></td></tr></table></figure><p>jinfo还可以使用-sysprops选项把虚拟机 进程的System.getProperties()的内容打印出来。</p><p>jinfo还可以在运行期 修改部分参数值。</p><h1 id="jmap-java内存映像工具"><a class="markdownIt-Anchor" href="#jmap-java内存映像工具"></a> jmap: Java内存映像工具</h1><p>生成堆转储快照(一般称为heapdump或dump文件)。可以查询finaliz e执行队列、Java堆和方法区的 详细信息，如空间使用率、当前用的是哪种收集器等。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap [ option ] vmid</span><br></pre></td></tr></table></figure><p>如果不使用jmap 命令，要想获取Java堆转储快照可以使用-XX:+HeapDumpOnOutOfMemoryError参数，让虚拟机在内存溢出异常出现之后自动生成堆转储快照文件，或者使用-XX:+HeapDumpOnCtrlBreak参数，然后使用kill -3让虚拟机生成堆转储快照。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20221213192925832.png" alt="image-20221213192925832"></p><h1 id="jhat-虚拟机堆转储快照分析工具"><a class="markdownIt-Anchor" href="#jhat-虚拟机堆转储快照分析工具"></a> jhat: 虚拟机堆转储快照分析工具</h1><p>与jmap搭配使用，来分析jmap生成的堆转储快照。内置了一个微型的HTTP/Web服务器，可以通过<a href="http://localhost:7000/%E6%9F%A5%E7%9C%8B%E5%88%86%E6%9E%90%E7%BB%93%E6%9E%9C%E3%80%82">http://localhost:7000/查看分析结果。</a></p><p>jhat的分析功能相对来说比较简陋，可以使用其他的分析工具如VisualVM，以及专业用于分析堆转储快照文件的EclipseMemoryAnalyzer、IBMHeapAnalyzer等工具。</p><h1 id="jstack-java堆栈跟踪工具"><a class="markdownIt-Anchor" href="#jstack-java堆栈跟踪工具"></a> jstack: Java堆栈跟踪工具</h1><p>用于生成虚拟机当前时刻的线程快照(一般称为threaddump或者 javacore文件)。通常可以用于定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间挂起等，都是导致线程长时间停顿的常见原因。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstack [ option ] vmid</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20221213193724742.png" alt="image-20221213193724742"></p><h1 id="jdk日志参数"><a class="markdownIt-Anchor" href="#jdk日志参数"></a> JDK日志参数</h1><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20221213100624431.png" alt="image-20221213100624431"></p><p><img src="/.io//image-20221213100659078.png" alt="image-20221213100659078"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;JDK自带了很多小工具，打包、部署、签名、调试、监控、运维等 各种场景都可能会用到它们。&lt;/p&gt;</summary>
    
    
    
    
    <category term="JVM" scheme="https://eoccc.gitee.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>Mysql知识整理</title>
    <link href="https://eoccc.gitee.io/2022/11/02/Mysql%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"/>
    <id>https://eoccc.gitee.io/2022/11/02/Mysql%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</id>
    <published>2022-11-02T07:25:19.000Z</published>
    <updated>2023-03-28T02:26:09.868Z</updated>
    
    <content type="html"><![CDATA[<p>整理一些mysql的知识。</p><span id="more"></span><h1 id="mysql"><a class="markdownIt-Anchor" href="#mysql"></a> Mysql</h1><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/g7_US3L4q.jpeg" alt="g7_US3L4q.jpeg"></p><h2 id="不常用sql语法"><a class="markdownIt-Anchor" href="#不常用sql语法"></a> 不常用sql语法</h2><h3 id="创建数据库"><a class="markdownIt-Anchor" href="#创建数据库"></a> 创建数据库</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database name;</span><br></pre></td></tr></table></figure><h3 id="创建table"><a class="markdownIt-Anchor" href="#创建table"></a> 创建table</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> name (</span><br><span class="line"># 字段</span><br><span class="line">)engine<span class="operator">=</span>Innodb <span class="keyword">default</span> charset<span class="operator">=</span>utf8;</span><br></pre></td></tr></table></figure><h3 id="更改table名"><a class="markdownIt-Anchor" href="#更改table名"></a> 更改table名</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> name rename <span class="keyword">to</span> newName;</span><br></pre></td></tr></table></figure><h3 id="更改字段类型"><a class="markdownIt-Anchor" href="#更改字段类型"></a> 更改字段类型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> tableName modify columName newType <span class="keyword">not</span> <span class="keyword">null</span>;</span><br></pre></td></tr></table></figure><h3 id="更改字段名称及类型"><a class="markdownIt-Anchor" href="#更改字段名称及类型"></a> 更改字段名称及类型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> tableName change columName newName newType <span class="keyword">not</span> <span class="keyword">null</span>;</span><br></pre></td></tr></table></figure><h3 id="创建用户"><a class="markdownIt-Anchor" href="#创建用户"></a> 创建用户</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">user</span> <span class="string">&#x27;demo&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> identified <span class="keyword">by</span> <span class="string">&#x27;demo&#x27;</span>;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> users.<span class="operator">*</span> <span class="keyword">to</span> <span class="string">&#x27;demo&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span>;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><h3 id="drop-delete与truncate"><a class="markdownIt-Anchor" href="#drop-delete与truncate"></a> drop、delete与truncate</h3><table><thead><tr><th></th><th>delete</th><th>truncate</th><th>drop</th></tr></thead><tbody><tr><td>回滚</td><td>可回滚</td><td>不可回滚</td><td>不可回滚</td></tr><tr><td>删除内容</td><td>保留表结构，删除一条或多条记录</td><td>保留表结构，删除所有记录</td><td>从数据库中删除表，删除所有的记录、索引、权限</td></tr><tr><td>删除速度</td><td>删除速度慢，需要逐行删除</td><td>删除速度快</td><td>删除速度最快</td></tr></tbody></table><h2 id="索引"><a class="markdownIt-Anchor" href="#索引"></a> 索引</h2><h3 id="什么是索引"><a class="markdownIt-Anchor" href="#什么是索引"></a> 什么是索引</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">索引是一种特殊的文件，包含对数据表里所有记录的引用指针；</span><br><span class="line">索引是一种数据结构，通常使用B树或B+树实现，用来协助快速地查询、更新数据库；</span><br><span class="line">通俗的说，索引就是为了快速的查询和更新数据库而建立的一种目录，存储于文件中，需要占用物理空间。</span><br></pre></td></tr></table></figure><h3 id="索引的优缺点"><a class="markdownIt-Anchor" href="#索引的优缺点"></a> 索引的优缺点</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">优点：</span><br><span class="line"><span class="bullet">  1.</span> 可以加快检索数据的速度</span><br><span class="line"><span class="bullet">  2.</span> 可以加速表与表之间的连接</span><br><span class="line"><span class="bullet">  3.</span> 提升排序和分组的性能</span><br><span class="line"><span class="bullet">  4.</span> 查询过程中，通过索引使用优化隐藏器，提升系统性能</span><br><span class="line"><span class="bullet">  6.</span> 通过创建唯一索引，保证数据的唯一性</span><br><span class="line">缺点：</span><br><span class="line"><span class="bullet">  1.</span> 创建和维护索引都需要时间，耗费的时间随数据量增加而增加</span><br><span class="line"><span class="bullet">  2.</span> 插入、修改和删除数据都需要维护索引，会降低数据库的更新速度</span><br><span class="line"><span class="bullet">  3.</span> 索引需要占用物理空间，随数据量的增加而增加</span><br></pre></td></tr></table></figure><h3 id="有哪些索引"><a class="markdownIt-Anchor" href="#有哪些索引"></a> 有哪些索引</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="strong">**主键索引**</span>不允许重复，不允许null值，一个表只能有一个主键索引</span><br><span class="line"><span class="strong">**唯一索引**</span> 与单列索引类似，但是<span class="strong">**索引列的值必须唯一，允许出现一个null值**</span></span><br><span class="line"><span class="strong">**普通索引（单列索引）**</span> 是最基本的索引，没有任何限制。</span><br><span class="line"><span class="strong">**组合索引**</span> 在多个字段上创建的索引。遵守最左前缀原则，即<span class="strong">**在查询语句中用到复合索引的第一个字段，索引才会被使用**</span></span><br><span class="line"><span class="strong">**全文索引**</span> 与其他索引不一样，更像是一个搜索引擎，主要用来查找文本中的关键字，而不是直接与索引中的值进行比较</span><br></pre></td></tr></table></figure><h3 id="非聚簇索引一定会回表查询吗"><a class="markdownIt-Anchor" href="#非聚簇索引一定会回表查询吗"></a> 非聚簇索引一定会回表查询吗</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">不一定，当查询语句需要查询的字段全部命中索引，就不需要回表查询。</span><br></pre></td></tr></table></figure><h3 id="索引失效的情况"><a class="markdownIt-Anchor" href="#索引失效的情况"></a> 索引失效的情况？</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">1.</span> 在where后使用or，导致索引失效（尽量少用or）</span><br><span class="line"><span class="bullet">2.</span> 使用like，like查询是以%开头</span><br><span class="line"><span class="bullet">3.</span> 复合索引遵守“最左前缀”原则，即在查询条件中使用了复合索引的第一个字段，索引才会被使用</span><br><span class="line"><span class="bullet">4.</span> 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引</span><br><span class="line"><span class="bullet">5.</span> 使用in导致索引失效</span><br><span class="line"><span class="bullet">6.</span> DATE<span class="emphasis">_FORMAT()格式化时间，格式化后的时间再去比较，可能会导致索引失效。</span></span><br></pre></td></tr></table></figure><h3 id="设计索引的原则"><a class="markdownIt-Anchor" href="#设计索引的原则"></a> 设计索引的原则</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.最左匹配原则</span><br><span class="line">2.对频繁的查询条件字段加索引</span><br><span class="line">3.更新频繁的字段不要加索引</span><br><span class="line">4.对区分度高的字段加索引</span><br><span class="line">5.尽量拓展索引，而不是新增索引。如已经有a索引，要加(a,b)索引，应该修改a索引</span><br><span class="line">6.定义有外键的数据一定要加索引</span><br><span class="line">7.使用短索引，如果要对长字符串加索引，尽量限制前缀长度</span><br><span class="line">8.不要过度加索引</span><br><span class="line">9.不要对text、image和bit加索引</span><br></pre></td></tr></table></figure><h3 id="最左前缀原则"><a class="markdownIt-Anchor" href="#最左前缀原则"></a> 最左前缀原则</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.顾名思义，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。</span><br><span class="line">2.mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</span><br><span class="line">3.=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式</span><br></pre></td></tr></table></figure><h3 id="innodb-索引如何实现"><a class="markdownIt-Anchor" href="#innodb-索引如何实现"></a> InnoDB 索引如何实现</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">（1）B+树，减少IO次数。一个节点就是一页的大小，而索引中B+树，它的层级一般是3层，也就意味着我们需要3次IO</span><br><span class="line">（2）叶子节点有链表，节点包含数据行的所有信息，加快区间访问速度</span><br><span class="line">（3）主键索引、辅助索引的区别？（叶子节点存什么）</span><br><span class="line"><span class="code">聚集索引：表中行的物理顺序与键值的逻辑（索引）顺序相同。叶子节点包含数据行的所有信息。一个表只能包含一个聚集索引，提供更快的数据访问速度，适用于很少对基表进行增删改操作的情况。</span></span><br><span class="line"><span class="code">    二级索引：又叫辅助索引、非聚集索引。B+tree结构，但是叶子节点保存的是&lt;键值，主键值&gt;</span></span><br><span class="line"><span class="code">InnoDB的主键索引是聚集索引，即包含了数据行的所有信息。</span></span><br><span class="line"><span class="code">InnoDB的二级索引（辅助索引）叶子包含的数据就是该行的主键。</span></span><br><span class="line"><span class="code">（4）InnoDB这么设计是利用了缓存机制，减少IO访问次数</span></span><br></pre></td></tr></table></figure><h3 id="执行计划"><a class="markdownIt-Anchor" href="#执行计划"></a> 执行计划</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">explain  查询语句会得到如下信息：</span><br><span class="line"><span class="code">table | type | possible_keys | key | key_len | ref | rows | Extra</span></span><br><span class="line"><span class="code">table：显示这一行的数据是关于哪张表的</span></span><br><span class="line"><span class="code">type：这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、index和ALL</span></span><br><span class="line"><span class="code">possible_keys：显示可能应用在这张表中的索引。</span></span><br><span class="line"><span class="code">**key：**实际使用的索引，查看是否使用我们想要的key</span></span><br><span class="line"><span class="code">key_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好</span></span><br><span class="line"><span class="code">ref：显示索引的哪一列被使用了，如果可能的话，是一个常数</span></span><br><span class="line"><span class="code">rows：MYSQL认为必须检查的用来返回请求数据的行数</span></span><br><span class="line"><span class="code">**extra：**是否有耗性能的操作，比如：</span></span><br><span class="line"><span class="code">Using filesort: mysql需要进行额外的步骤来发现如何对返回的行排序</span></span><br><span class="line"><span class="code">Using temporary: mysql需要创建一个临时表来存储结果</span></span><br></pre></td></tr></table></figure><h3 id="sql如何调优"><a class="markdownIt-Anchor" href="#sql如何调优"></a> SQL如何调优</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">（1）查看执行计划（如上）</span><br><span class="line">（2）优化索引</span><br><span class="line">最左前缀原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配</span><br><span class="line">覆盖索引，索引中包含了满足查询语句中字段与条件的数据，避免回表查询</span><br><span class="line">使用索引排序，而不是file sort</span><br><span class="line">主键使用合适的数据类型</span><br><span class="line">选用区分度较高的索引</span><br><span class="line">（3）反范式设计</span><br><span class="line">在表里增加一些与主键不直接相关的列</span><br><span class="line">（4）Join内连接的优化</span><br><span class="line">小表驱动大表（Mysql优化器可优化、减少循环次数），在被驱动表中连接的字段要走索引。EXPLAIN结果中，第一行出现的表就是驱动表</span><br><span class="line">（4）万变不离其宗，主要就是为了减少IO次数</span><br><span class="line"></span><br><span class="line">具体的：</span><br><span class="line"><span class="bullet">1.</span> 指定查询的列，只查询需要的结果，避免查询所有列</span><br><span class="line"><span class="bullet">2.</span> 使用覆盖索引，避免回表查询</span><br><span class="line"><span class="bullet">3.</span> 空值判断使用<span class="code">`is not null`</span>， 使用<span class="code">`is null`</span>会导致全表扫描</span><br><span class="line"><span class="bullet">4.</span> 使用组合索引要注意最左前缀原则</span><br><span class="line"><span class="bullet">5.</span> where、order by、group、多表连接条件中的字段应该创建索引</span><br><span class="line"><span class="bullet">6.</span> 使用like匹配时，通配符%不能放在最前</span><br><span class="line"><span class="bullet">7.</span> 分页查询不要使用offset，而是使用范围查询+limit</span><br><span class="line"><span class="bullet">8.</span> 避免对查询条件使用函数，会导致索引失效</span><br><span class="line"><span class="bullet">9.</span> 隐式转换会导致索引失效</span><br><span class="line"><span class="bullet">10.</span> 避免使用or，会导致索引失效，而应该用union连接</span><br></pre></td></tr></table></figure><h3 id="b树和b树的区别"><a class="markdownIt-Anchor" href="#b树和b树的区别"></a> B树和B+树的区别</h3><table><thead><tr><th>B树</th><th>B+树</th></tr></thead><tbody><tr><td>有k个元素的中间节点包含k+1个子树</td><td>有k个元素的中间节点包含k个子树</td></tr><tr><td>子树中不包含中间节点的元素</td><td>子树中包含中间节点的元素</td></tr><tr><td>叶子节点之间没有链接，范围查询要不断进行中序遍历</td><td>叶子节点为有序链表，方便范围查询</td></tr><tr><td>每个节点都包含数据</td><td>只有叶子节点包含数据</td></tr><tr><td>查询性能最好为1，最差为树高的次数（每次都要IO）</td><td>查询次数为树高，只需要一次IO</td></tr></tbody></table><h3 id="hash索引和b树索引"><a class="markdownIt-Anchor" href="#hash索引和b树索引"></a> Hash索引和B树索引</h3><table><thead><tr><th></th><th>Hash索引</th><th>B树索引</th></tr></thead><tbody><tr><td>等值查询</td><td>更快，但是存在大量hash冲突时会大大降低查询效率</td><td>查询效率比较稳定</td></tr><tr><td>范围查询</td><td>不支持</td><td>支持</td></tr><tr><td>排序</td><td>不支持</td><td>支持</td></tr><tr><td>模糊查询</td><td>不支持</td><td>支持</td></tr><tr><td>前缀查询</td><td>不支持</td><td>支持</td></tr><tr><td>回表查询</td><td>每次查询都要回表</td><td>聚集索引不需要回表</td></tr></tbody></table><h2 id="存储引擎"><a class="markdownIt-Anchor" href="#存储引擎"></a> 存储引擎</h2><h3 id="innodb和myisam"><a class="markdownIt-Anchor" href="#innodb和myisam"></a> InnoDB和MyIsam</h3><table><thead><tr><th></th><th>MyIsam</th><th>Memory</th><th>InnoDB</th></tr></thead><tbody><tr><td>全文索引</td><td>yes</td><td>no</td><td>no</td></tr><tr><td>哈希索引</td><td>no</td><td>yes</td><td>no</td></tr><tr><td>B树索引</td><td>yes</td><td>yes</td><td>yes</td></tr><tr><td>集群索引</td><td>no</td><td>no</td><td>yes</td></tr><tr><td>数据索引</td><td>no</td><td>yes</td><td>yes</td></tr><tr><td>外键</td><td>no</td><td>no</td><td>yes</td></tr><tr><td>锁支持</td><td>表级锁</td><td></td><td>行级锁、表级锁，锁粒度小并发能力更高</td></tr><tr><td>事务</td><td>不支持</td><td></td><td>支持</td></tr><tr><td>外键</td><td>不支持</td><td></td><td>支持</td></tr><tr><td>记录存储顺序</td><td>按记录插入顺序保存</td><td></td><td>按主键大小顺序保存</td></tr><tr><td>存储空间</td><td>MyISAM可被压缩，存储空间较小</td><td></td><td>InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引</td></tr><tr><td>select count(*)</td><td>更快，因为维护了一个计数器</td><td></td><td>通过索引计算</td></tr></tbody></table><h3 id="b树和b树"><a class="markdownIt-Anchor" href="#b树和b树"></a> B树和B+树</h3><table><thead><tr><th>B树</th><th>B+树</th></tr></thead><tbody><tr><td>子树中不包含中间节点的元素</td><td>子树中包含中间节点的元素</td></tr><tr><td></td><td>叶子节点为有序链表，方便范围查询</td></tr><tr><td>每个节点都包含数据</td><td>只有叶子节点包含数据</td></tr><tr><td>查询性能最好为1，最差为树高的次数（每次都要IO）</td><td>查询次数为树高，只需要一次IO</td></tr></tbody></table><h2 id="事务"><a class="markdownIt-Anchor" href="#事务"></a> 事务</h2><h3 id="事务的特性-acid"><a class="markdownIt-Anchor" href="#事务的特性-acid"></a> 事务的特性-ACID</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Atomic（原子性）：事务中的操作，要么都成功，都失败</span><br><span class="line">Consistency（一致性）：数据从一个正确的状态到另一个正确的状态</span><br><span class="line">Isolation（隔离性）：事务之间互相影响，保证同时执行的事务互相之间没有干扰</span><br><span class="line">Durability（持久性）：存到磁盘中，即使机器断电，数据还是有的</span><br></pre></td></tr></table></figure><h3 id="并发事务带来的问题"><a class="markdownIt-Anchor" href="#并发事务带来的问题"></a> 并发事务带来的问题</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="strong">**更新丢失:**</span> 两个事务同时更新一行数据，最后一个事务的更新会覆盖掉第一个事务的更新，从而导致第一个事务更新的数据丢失，这是由于没有加锁造成的；</span><br><span class="line"><span class="strong">**脏读:**</span> 事务读取尚未提交的数据;</span><br><span class="line"><span class="strong">**不可重复读:**</span> 更新行导致，在同一事务中，两次读取同一数据，得到内容不同，也就是有其他事务更改了这些数据</span><br><span class="line"><span class="strong">**幻读:**</span> 插入行导致，一个事务在执行过程中读取到了另一个事务已提交的插入数据。</span><br></pre></td></tr></table></figure><h3 id="事务的隔离级别"><a class="markdownIt-Anchor" href="#事务的隔离级别"></a> 事务的隔离级别</h3><table><thead><tr><th style="text-align:center">隔离级别</th><th style="text-align:center">脏读</th><th style="text-align:center">不可重复读</th><th style="text-align:center">幻读</th></tr></thead><tbody><tr><td style="text-align:center">Read Uncommitted(一个事务可以读取另一个未提交事务的数据)</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">Read Committed(一个事务要等另一个事务提交后才能读取数据)</td><td style="text-align:center"></td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">Repeatable Read（默认，在开始读取数据时，不再允许修改操作<br>实现：间隙锁锁住叶子节点的next指针）</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">Serializable(事务串行化顺序执行，效率低下)</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MySql默认的隔离级别：RR</span><br><span class="line">Oracle默认的隔离级别：RC</span><br></pre></td></tr></table></figure><h3 id="mvcc"><a class="markdownIt-Anchor" href="#mvcc"></a> MVCC</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">多版本并发控制（MVCC），解决不可重复读。</span><br><span class="line">为每个数据增加一个版本号，每次修改会对该记录版本号递增，可重复读（RR），读取事务开始前最新的版本号；读已提交（RC，通过间隙锁实现），每次读取最新的数据。</span><br></pre></td></tr></table></figure><h3 id="分布式事务"><a class="markdownIt-Anchor" href="#分布式事务"></a> 分布式事务</h3><p>写的很好的博客：<a href="https://www.cnblogs.com/yaochunhui/p/15594250.html">https://www.cnblogs.com/yaochunhui/p/15594250.html</a></p><h4 id="xa协议"><a class="markdownIt-Anchor" href="#xa协议"></a> XA协议</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">XA分布式事务协议，包含二阶段提交（2PC），三阶段提交（3PC）两种实现。</span><br><span class="line"><span class="strong">**二阶段提交**</span></span><br><span class="line"><span class="code">1.准备阶段</span></span><br><span class="line"><span class="code">  事务协调者，向所有事务参与者发送事务内容，询问是否可以提交事务，并等待参与者回复；</span></span><br><span class="line"><span class="code">  事务参与者收到事务内容，开始执行事务操作，将 undo 和 redo 信息记入事务日志中（但此时并不提交事务）；</span></span><br><span class="line"><span class="code">  如果参与者执行成功，给协调者回复yes,表示可以进行事务提交。如果执行失败，给协调者回复no,表示不可提交。</span></span><br><span class="line"><span class="code">2.提交阶段</span></span><br><span class="line"><span class="code">  如果协调者收到了参与者的失败信息或超时，直接给所有参与者发送回滚（rollback）信息进行事务回滚，否则，发送提交（commit）信息。</span></span><br><span class="line"><span class="code">存在的问题：</span></span><br><span class="line"><span class="code">  性能问题：所有参与者在事务提交阶段处于同步阻塞状态，占用系统资源，容易导致性能瓶颈。</span></span><br><span class="line"><span class="code">可靠性问题：如果协调者存在单点故障问题，如果协调者出现故障，参与者将一直处于锁定状态。</span></span><br><span class="line"><span class="code">数据一致性问题：在阶段2中，如果发生网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。</span></span><br><span class="line"><span class="code">**三阶段提交**</span></span><br><span class="line"><span class="code">  三阶段提交是在二阶段提交上的改进版本，主要是加入了超时机制。同时在协调者和参与者中都引入超时机制，在等待超时后协调者或参与者会中断事务，避免了协调者单点问题。</span></span><br><span class="line"><span class="code">  1. preCommit</span></span><br><span class="line"><span class="code">     协调者向所有参与者发出包含事务内容的 canCommit 请求，询问是否可以提交事务，并等待所有参与者答复。</span></span><br><span class="line"><span class="code">     参与者收到 canCommit 请求后，如果认为可以执行事务操作，则反馈 yes 并进入预备状态，否则反馈 no。</span></span><br><span class="line"><span class="code">  2. preCommit</span></span><br><span class="line"><span class="code">     阶段1所有参与者均反馈 yes</span></span><br><span class="line"><span class="code">        协调者向所有参与者发出 preCommit 请求，进入准备阶段</span></span><br><span class="line"><span class="code">        参与者收到 preCommit 请求后，执行事务操作，将 undo 和 redo 信息记入事务日志中（但不提交事务）</span></span><br><span class="line"><span class="code">        各参与者向协调者反馈 ack 响应或 no 响应，并等待最终指令</span></span><br><span class="line"><span class="code">     阶段1任何一个参与者反馈 no</span></span><br><span class="line"><span class="code">        协调者向所有参与者发出 abort 请求</span></span><br><span class="line"><span class="code">        无论收到协调者发出的 abort 请求，或者在等待协调者请求过程中出现超时，参与者均会中断事务。</span></span><br><span class="line"><span class="code">  3. do Commit</span></span><br><span class="line"><span class="code">     阶段2所有参与者均反馈 yes</span></span><br><span class="line"><span class="code">        如果协调者处于工作状态，则向所有参与者发出 do Commit 请求</span></span><br><span class="line"><span class="code">        参与者收到 do Commit 请求后，会正式执行事务提交，并释放整个事务期间占用的资源</span></span><br><span class="line"><span class="code">        各参与者向协调者反馈 ack 完成的消息</span></span><br><span class="line"><span class="code">        协调者收到所有参与者反馈的 ack 消息后，即完成事务提交</span></span><br><span class="line"><span class="code">     阶段2任何一个参与者反馈 no</span></span><br><span class="line"><span class="code">        如果协调者处于工作状态，向所有参与者发出 abort 请求</span></span><br><span class="line"><span class="code">        参与者使用阶段1中的 undo 信息执行回滚操作，并释放整个事务期间占用的资源</span></span><br><span class="line"><span class="code">        各参与者向协调者反馈 ack 完成的消息</span></span><br><span class="line"><span class="code">        协调者收到所有参与者反馈的 ack 消息后，即完成事务中断</span></span><br><span class="line"><span class="code">     注意：进入阶段3后，如果参与者超时了还没有收到协调者的信息，会提交事务。</span></span><br><span class="line"><span class="code">  存在的问题：数据不一致问题依然存在，当在参与者收到 preCommit 请求后等待 do commite 指令时，此时如果协调者请求中断事务，而协调者无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。</span></span><br></pre></td></tr></table></figure><h4 id="tcc事务"><a class="markdownIt-Anchor" href="#tcc事务"></a> TCC事务</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">TCC（Try-Confirm-Cancel）：实现最终一致性。</span><br><span class="line">TCC 是服务化的二阶段编程模型，其Try、Confirm、Cancel个方法均由业务编码实现（可以理解为SQL事务中的Lock、Commit、Rollback）：</span><br><span class="line"><span class="code">Try 操作作为一阶段，负责资源的检查和预留。</span></span><br><span class="line"><span class="code">Confirm 操作作为二阶段提交操作，执行真正的业务。</span></span><br><span class="line"><span class="code">Cancel 是预留资源的取消。</span></span><br><span class="line"><span class="code">Try 阶段是一个初步的操作：</span></span><br><span class="line"><span class="code">完成所有业务检查( 一致性 ) 。</span></span><br><span class="line"><span class="code">预留必须业务资源( 准隔离性 ) 。</span></span><br><span class="line"><span class="code">Try 尝试执行业务。</span></span><br><span class="line"><span class="code">Confirm 阶段：如果事务正常执行，进入Confirm阶段，执行事务提交。</span></span><br><span class="line"><span class="code">Cancel 阶段：如果事务执行异常，进入Cancel阶段，回滚事务，释放资源。</span></span><br></pre></td></tr></table></figure><h4 id="saga事务"><a class="markdownIt-Anchor" href="#saga事务"></a> Saga事务</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Saga 事务也是保证最终一致性。</span><br><span class="line">Saga 事务核心思想是将长事务拆分为多个本地短事务，由 Saga 事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。</span><br><span class="line">Saga 事务基本协议如下：</span><br><span class="line"><span class="code">每个 Saga 事务由一系列幂等的有序子事务(sub-transaction) Ti 组成。</span></span><br><span class="line"><span class="code">每个 Ti 都有对应的幂等补偿动作 Ci，补偿动作用于撤销 Ti 造成的结果。</span></span><br></pre></td></tr></table></figure><h2 id="innodb中的锁"><a class="markdownIt-Anchor" href="#innodb中的锁"></a> InnoDB中的锁</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">行锁（Record lock）：锁住单个行记录</span><br><span class="line">间隙锁（Gap lock）：锁定一个范围，不包括记录本身</span><br><span class="line">范围锁（Next-key lock）：record+gap 锁定一个范围，包含记录本身</span><br><span class="line">注意：innoDB的锁是通过索引来实现的，如果查询条件不是索引，将锁住整张表</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="乐观锁-悲观锁的实现区别使用场景"><a class="markdownIt-Anchor" href="#乐观锁-悲观锁的实现区别使用场景"></a> 乐观锁、悲观锁的实现？区别？使用场景？</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">乐观锁：</span><br><span class="line">  通过 where 条件中的版本号来确定是否更新，版本号递增，当版本号相同时才做修改操作。</span><br><span class="line">悲观锁：</span><br><span class="line">  排他锁：for update</span><br><span class="line">共享锁：in share mode（只能读）</span><br><span class="line">行锁、表锁</span><br><span class="line">  innodb，走索引，能走到行锁</span><br></pre></td></tr></table></figure><h2 id="log"><a class="markdownIt-Anchor" href="#log"></a> log</h2><h3 id="redo-log的作用"><a class="markdownIt-Anchor" href="#redo-log的作用"></a> redo log的作用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">是重做日志，提供前滚操作。WAL，write ahead log，随机写变顺序写，提高性能，保证数据的持久性（D）</span><br></pre></td></tr></table></figure><h3 id="undo-log的作用"><a class="markdownIt-Anchor" href="#undo-log的作用"></a> undo log的作用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">回退日志，提供回滚操作。保证原子性（A）（隔离性(I)由锁保证）</span><br></pre></td></tr></table></figure><h3 id="binlog的作用"><a class="markdownIt-Anchor" href="#binlog的作用"></a> binlog的作用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">备份、主备同步。binlog是一个二进制格式的文件，用于记录用户对数据库更新的SQL语句信息。</span><br></pre></td></tr></table></figure><h3 id="innodb和myisam的区别"><a class="markdownIt-Anchor" href="#innodb和myisam的区别"></a> InnoDB和MyIsam的区别？</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">InnoDB（默认，公司用的都是这个）</span><br><span class="line">  1、支持事务处理、ACID事务特性；</span><br><span class="line">  2、实现了SQL标准的四种隔离级别；</span><br><span class="line">  3、支持行级锁和外键约束；</span><br><span class="line">  4、锁级别为行锁，行锁优点是适用于高并发的频繁表修改，高并发是性能优于 MyISAM。缺点是系统消耗较大。</span><br><span class="line">  5、索引存储数据（聚集索引），相比 MyISAM 需要更大的内存。</span><br><span class="line">MyIsam</span><br><span class="line">  1.高性能读取；</span><br><span class="line">  2.因为它保存了表的行数，当使用COUNT统计时不会扫描全表</span><br><span class="line">  3.支持全文本索引（更好的选择是EleasticSearch）</span><br></pre></td></tr></table></figure><h2 id="数据库设计的三大范式"><a class="markdownIt-Anchor" href="#数据库设计的三大范式"></a> 数据库设计的三大范式</h2><pre class="highlight"><code class="markdown">（1）每个属性都是原子的（必须遵循的，方便查）（2）表中每个列都和主键相关(也是要遵循的)，不能部分相关（3）表中的每列和主键直接相关，不能间接相关</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;整理一些mysql的知识。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>红黑树</title>
    <link href="https://eoccc.gitee.io/2022/10/02/%E7%BA%A2%E9%BB%91%E6%A0%91/"/>
    <id>https://eoccc.gitee.io/2022/10/02/%E7%BA%A2%E9%BB%91%E6%A0%91/</id>
    <published>2022-10-02T07:25:19.000Z</published>
    <updated>2022-10-06T14:24:35.421Z</updated>
    
    <content type="html"><![CDATA[<p>红黑树是特殊的AVL树(二叉平衡树)，设计红黑树的目的，就是解决平衡树的维护起来比较麻烦的问题，红黑树读取略逊于AVL，维护强于AVL，每次插入和删除的平均旋转次数应该是远小于平衡树。</p><span id="more"></span><h1 id="红黑树的应用"><a class="markdownIt-Anchor" href="#红黑树的应用"></a> 红黑树的应用</h1><ol><li>IO多路复用的实现采用红黑树组织管理，以支持快速的增删改查</li><li>ngnix中用红黑树管理timer，因为红黑树是有序的，可以很快的得到距离当前最小的定时器</li><li>java中TreeMap，jdk1.8的hashMap实现</li></ol><h1 id="红黑树的特征"><a class="markdownIt-Anchor" href="#红黑树的特征"></a> 红黑树的特征</h1><p><strong>红定理：</strong> 不会有连续的红色节点，红色节点的子节点必定为黑色。</p><p><strong>黑定理：</strong> 根节点必须是黑节点，所有叶子节点都是黑色。</p><blockquote><ol><li>每个节点要么是黑色，要么是红色</li><li>根节点是黑色</li><li>每个叶子节点（NIL）是黑色</li><li>每个红色结点的两个子结点一定都是黑色</li><li>任意一节点到每个叶子结点的路径都包含数量相同的黑结点</li></ol></blockquote><h1 id="红黑树的插入"><a class="markdownIt-Anchor" href="#红黑树的插入"></a> 红黑树的插入</h1><p>基本操作是添加、删除和旋转。在对红黑树进行添加或删除后，会用到旋转方法。旋转的目的是让树保持红黑树的特性。旋转包括两种：左旋 和 右旋</p><h2 id="左旋"><a class="markdownIt-Anchor" href="#左旋"></a> 左旋</h2><p>父节点（P）左沉，右节点的的左节点（R）变成父节点的右子节点，右节点（V）变成新的父节点。</p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhnbkg17j30ta094jrp.jpg" alt="image-20221006123731381" style="zoom:50%;"><h2 id="右旋"><a class="markdownIt-Anchor" href="#右旋"></a> 右旋</h2><p>父节点（P）右沉，左节点的的右节点（K）变成父节点的左子节点，左节点（F）变成新的父节点。</p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhniugauj30xg094q3a.jpg" alt="image-20221006124133170" style="zoom:50%;"><h2 id="插入节点"><a class="markdownIt-Anchor" href="#插入节点"></a> 插入节点</h2><p>插入红色节点，不需要做自平衡</p><p>插入黑色节点，需要做自平衡</p><h3 id="插入红色节点"><a class="markdownIt-Anchor" href="#插入红色节点"></a> 插入红色节点</h3><p><strong>叔叔节点存在且为红色</strong></p><p>将父节点和叔叔节点变成黑色，将主父节点变成红色（主父节点违反了红黑树的规则，要继续做变色处理，最后如果根节点变成了红色，要做自旋）。</p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhnm2i70j30k60963zb.jpg" alt="image-20221006125541140" style="zoom:50%;">   <img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhnplw2cj30kc090t9i.jpg" alt="image-20221006130117125" style="zoom:50%;"></p><p><strong>叔叔节点不存在或为黑色</strong></p><ol><li><p>插入节点的父节点为左节点</p><ul><li><p>插入节点为左节点</p><p>右旋</p></li></ul><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhntajkcj30ki09474y.jpg" alt="image-20221006130459279" style="zoom:50%;"><ul><li><p>插入节点为右节点</p><p>先左旋，再右旋</p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhnuqyepj30xc0a8dh4.jpg" alt="image-20221006130658504" style="zoom:45%;"></li></ul></li><li><p>插入节点的父节点为右节点</p><ul><li><p>插入节点为左节点</p><p>先右旋，再左旋</p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhnwxpx4j30xc0as75p.jpg" alt="image-20221006130906594" style="zoom:45%;"></li><li><p>插入节点为右节点</p><p>左旋</p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vho0a6tnj30t60e2ta4.jpg" alt="image-20221006130925077" style="zoom:40%;"></li></ul></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;红黑树是特殊的AVL树(二叉平衡树)，设计红黑树的目的，就是解决平衡树的维护起来比较麻烦的问题，红黑树读取略逊于AVL，维护强于AVL，每次插入和删除的平均旋转次数应该是远小于平衡树。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据结构" scheme="https://eoccc.gitee.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Mysql-ShardingSphere分库分表</title>
    <link href="https://eoccc.gitee.io/2022/09/27/Mysql-ShardingSphere%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    <id>https://eoccc.gitee.io/2022/09/27/Mysql-ShardingSphere%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</id>
    <published>2022-09-27T08:25:19.000Z</published>
    <updated>2022-10-08T05:57:28.052Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://shardingsphere.apache.org/document/current/cn/overview/#shardingsphere-jdbc">Apache ShardingSphere</a>是一款开源的分布式数据库中间件组成的生态圈。它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（规划中）组成。提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。</p><span id="more"></span><p>Inline 不支持范围查找</p><p>Standard 支持范围查找</p><p>Complex  支持范围查找、支持多分片键</p><p>Hint 通过Hint指定分片值而非从SQL中提取分片值的方式进行分片</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://shardingsphere.apache.org/document/current/cn/overview/#shardingsphere-jdbc&quot;&gt;Apache ShardingSphere&lt;/a&gt;是一款开源的分布式数据库中间件组成的生态圈。它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（规划中）组成。提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Mysql-分库分表</title>
    <link href="https://eoccc.gitee.io/2022/09/26/Mysql-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    <id>https://eoccc.gitee.io/2022/09/26/Mysql-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</id>
    <published>2022-09-26T08:25:19.000Z</published>
    <updated>2023-03-28T02:21:13.537Z</updated>
    
    <content type="html"><![CDATA[<p>不管是IO瓶颈，还是CPU瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承载活跃连接数的阈值。在业务Service来看就是，可用数据库连接少甚至无连接可用。</p><span id="more"></span><h1 id="数据库瓶颈"><a class="markdownIt-Anchor" href="#数据库瓶颈"></a> 数据库瓶颈</h1><p>数据量增长过快或者业务规模扩大导致单个数据库实例无法满足系统的性能和容量需求，需要通过分布式扩展来解决这些问题。</p><p>具体来说，以下情况可能需要进行分库分表：</p><ol><li>数据量过大：当单个数据库实例存储的数据量达到了数据库系统的承载极限，无法再继续扩展时，需要进行分库分表来分散存储数据的压力。</li><li>数据访问频繁度不同：某些数据表可能会被频繁访问，而其他表则很少被访问，此时可以通过分表将热点数据和冷数据分开存储，从而提高数据库的性能。</li><li>数据访问模式不同：当数据表中的数据被不同的业务模块访问时，可能需要将这些数据分散到不同的数据库中，以提高系统的性能。</li><li>业务扩展需要：当业务规模扩大时，可能需要通过分库分表来增加数据库的并发能力和容量，以满足业务需求。</li><li>分布式部署需要：当系统需要进行分布式部署时，可能需要将数据库进行分库分表来支持分布式部署架构。</li></ol><p>需要注意的是，在进行数据库分库时，需要考虑数据的一致性和分布式事务的处理。此外，需要根据具体的业务场景和数据特点选择最合适的分库方式。</p><h2 id="io瓶颈"><a class="markdownIt-Anchor" href="#io瓶颈"></a> IO瓶颈</h2><ol><li><p>磁盘IO瓶颈</p><p>热点数据太多，mysql的缓存放不下，产生大量的回表查询，导致查询数据降低。</p><p>解决：分库，垂直分表</p></li><li><p>网络IO瓶颈</p><p>请求的数据太多，带宽不够</p><p>解决：分库分集群</p></li></ol><h2 id="cpu瓶颈"><a class="markdownIt-Anchor" href="#cpu瓶颈"></a> CPU瓶颈</h2><ol><li><p>SQL问题</p><p>如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运算的操作</p><p>解决：SQL优化，建立合适的索引，在业务Service层进行业务计算</p></li><li><p>单表数据量太大</p><p>查询时扫描的行数太多，sql效率低</p><p>解决：水平分表</p></li></ol><h1 id="分库"><a class="markdownIt-Anchor" href="#分库"></a> 分库</h1><h2 id="水平分库horizontal-sharding"><a class="markdownIt-Anchor" href="#水平分库horizontal-sharding"></a> 水平分库（Horizontal Sharding）</h2><p>水平分库是指按照数据行的关系将数据拆分到不同的数据库中。例如，可以将用户表按照用户ID的范围进行拆分，将不同范围的用户存储在不同的数据库中。</p><p>根据分库键，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。</p><ul><li>每个库中的表结构都是一样的</li><li>每个库中的数据都不一样，没有交集</li><li>所有库中的数据的并集为全量数据</li></ul><p>适用场景：一个库的数据量太大，导致cpu、磁盘io、网络io的压力都很高。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/-wKcOJIPb.jpeg" alt="-wKcOJIPb.jpeg"></p><h2 id="垂直分库vertical-sharding"><a class="markdownIt-Anchor" href="#垂直分库vertical-sharding"></a> 垂直分库（Vertical Sharding）</h2><p>垂直分库是指按照数据表或列的关系将数据拆分到不同的数据库中。例如，可以将订单表和用户表分别存储在不同的数据库中，这样可以避免数据表之间的冗余和重复。</p><p>以表或列为依据，按照业务归属不同，将不同的表拆分到不同的库中。</p><ul><li>每个库中存放不同的表</li><li>每个库中的数据都不同</li><li>所有库中的数据的并集为全部数据</li></ul><p>适用场景：数据库中的表越来越多，导致数据库连接数不足。业务发展到这种情况，可以考虑拆分服务。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/99Watzd9D.jpeg" alt="99Watzd9D.jpeg"></p><h2 id="分片sharding"><a class="markdownIt-Anchor" href="#分片sharding"></a> 分片（Sharding）</h2><p>分片是指将数据按照某种规则进行分割，并将不同的分片存储在不同的数据库中。例如，可以按照用户的地理位置将用户数据分割成不同的分片，并将每个分片存储在不同的数据库中。</p><p>和水平分库相似。</p><h2 id="混合分库hybrid-sharding"><a class="markdownIt-Anchor" href="#混合分库hybrid-sharding"></a> 混合分库（Hybrid Sharding）</h2><p>混合分库是指将垂直分库和水平分库结合起来，以实现更精细的数据划分。例如，可以将用户表按照用户ID的范围进行水平分割，并将不同的用户表存储在不同的数据库中，同时将订单表和商品表等其他表垂直分割到不同的数据库中。</p><h1 id="分表"><a class="markdownIt-Anchor" href="#分表"></a> 分表</h1><h2 id="水平分表"><a class="markdownIt-Anchor" href="#水平分表"></a> 水平分表</h2><p>根据分表键，按照一定策略（hash、range等），将一个库中的数据拆分到多个表中。</p><ul><li>每个表中的表结构都是一样的</li><li>每个表中的数据都不一样，没有交集</li><li>所有表中的数据的并集为全量数据</li></ul><p>适用场景：单表的数据量太大，导致查询效率降低。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/VNwsPuzzM.jpeg" alt="VNwsPuzzM.jpeg"></p><p>一些水平分表的方式：</p><ol><li>按照数据量分表：按照数据量的大小将数据分散存储到不同的表中，每个表存储一定量的数据。这种方式比较简单，但需要预估数据增长量并及时进行迁移，否则可能会导致某些表数据过大而影响系统性能。</li><li>按照数据业务属性分表：将数据按照业务属性进行分表，例如将订单表按照用户ID分表，将商品表按照商品类别分表等。这种方式可以提高查询效率，但需要对业务进行分析，合理设计分表规则。</li><li>按照数据地理位置分表：将数据按照地理位置进行分表，例如将用户按照所在省份进行分表。这种方式适用于需要根据地理位置进行查询的业务，可以减少跨节点查询的开销。</li><li>按照时间分表：将数据按照时间进行分表，例如将日志表按照日期分表，每天一个表。这种方式可以提高查询效率，同时方便数据的归档和清理。</li></ol><h2 id="垂直分表"><a class="markdownIt-Anchor" href="#垂直分表"></a> 垂直分表</h2><p>以字段为依据，按照字段的活跃度，将表中字段拆到不同的表（主表和扩展表）中。</p><ul><li>每个表的结构不一样</li><li>每个表中只有一个关联键是一样的，其他数据都不一样</li><li>所有表的所有列的并集为全量数据</li></ul><p>适用场景：单表的字段过多，同时存在热数据和冷数据，单行数据占用的空间大，导致叶缓存能够保存的数据条数减少，查询时产生大量IO。另外，字段过多，查询条件也会很多，就需要建立更多的索引，导致插入、更新和删除效率降低，索引文件很大。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/a_YCOhAzj.jpeg" alt="a_YCOhAzj.jpeg"></p><p>需要注意：分表以后，进行联合查询的时候要<strong>尽量不要使用join</strong>，因为join不仅会增加CPU负担并且会将两个表耦合在一起（必须在一个数据库实例上）。关联数据应该在业务Service层做文章，分别获取主表和扩展表数据然后用关联字段关联得到全部数据。</p><h2 id="组合分库分表"><a class="markdownIt-Anchor" href="#组合分库分表"></a> 组合分库分表</h2><p>在一些场景下，只有分库或者分表是不能解决问题的。这时我们可以结合分库和分表，灵活进行配。</p><p>我们可以先根据第一个key进行分库，然后根据第二个key进行分表。</p><p>并且可以根据不同的业务情况，设定不同的分配策略，比如订单表，对于订单较多的月份，我们可以分配更多的表，使用hash策略将订单均匀的写到不同的表中。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;不管是IO瓶颈，还是CPU瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承载活跃连接数的阈值。在业务Service来看就是，可用数据库连接少甚至无连接可用。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Lombok @Builder注解导致默认值失效</title>
    <link href="https://eoccc.gitee.io/2022/09/11/Lombok%20@Builder%E6%B3%A8%E8%A7%A3%E5%AF%BC%E8%87%B4%E9%BB%98%E8%AE%A4%E5%80%BC%E5%A4%B1%E6%95%88/"/>
    <id>https://eoccc.gitee.io/2022/09/11/Lombok%20@Builder%E6%B3%A8%E8%A7%A3%E5%AF%BC%E8%87%B4%E9%BB%98%E8%AE%A4%E5%80%BC%E5%A4%B1%E6%95%88/</id>
    <published>2022-09-11T07:25:19.000Z</published>
    <updated>2022-09-22T12:03:10.125Z</updated>
    
    <content type="html"><![CDATA[<p>Lombok @Builder注解可以让我们很方便的使用builder模式构建对象，但是今天发现使用@Builder注解创建对象时，不会初始化默认值。</p><p>我们测试一下，先写个demo：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Builder</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> <span class="string">&quot;haha&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 测试一下</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> User.builder().build();</span><br><span class="line">  System.out.println(user.getName());</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：null</span></span><br></pre></td></tr></table></figure><p>编译以后，会生成两个class文件，一个是User自己的class，另一个是builder生成的class：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User$UserBuilder.class</span><br><span class="line">User.class</span><br></pre></td></tr></table></figure><p>随后我们反编译一下 看看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">javap -p User.class</span><br><span class="line">javap -p User\<span class="variable">$UserBuilder</span>.class</span><br></pre></td></tr></table></figure><p>反编译结果：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line"><span class="comment">//属性上设置了默认值</span></span><br><span class="line">  <span class="keyword">private</span> <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> <span class="string">&quot;haha&quot;</span>;</span><br><span class="line"></span><br><span class="line">  User(<span class="keyword">final</span> String name) &#123;</span><br><span class="line">    <span class="built_in">this</span>.name = name;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> UserBuilder <span class="title function_">builder</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">UserBuilder</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.name;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">UserBuilder</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    UserBuilder() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> User <span class="title function_">build</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="comment">//执行build的时候，没有将默认值设置进去</span></span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">User</span>(<span class="built_in">this</span>.name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;User.UserBuilder(name=&quot;</span> + <span class="built_in">this</span>.name + <span class="string">&quot;)&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>通过反编译的结果，我们可以看出编译后的代码是没有给User设置默认值的。</strong></p><p>在1.6.X版本中，Lombok加入了@Builder.Default注解，以实现默认值的初始化：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Builder</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="meta">@Builder</span>.Default</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> <span class="string">&quot;haha&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//测试</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> User.builder().build();</span><br><span class="line">  System.out.println(user.getName());</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：haha</span></span><br></pre></td></tr></table></figure><p>反编译看看：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//User.class</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//默认值放到了这个方法里面</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> String $<span class="keyword">default</span>$name() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;haha&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  User(<span class="keyword">final</span> String name) &#123;</span><br><span class="line">    <span class="built_in">this</span>.name = name;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> UserBuilder <span class="title function_">builder</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">UserBuilder</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.name;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">UserBuilder</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> name$set;</span><br><span class="line">    <span class="keyword">private</span> String name$value;</span><br><span class="line"></span><br><span class="line">    UserBuilder() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> UserBuilder <span class="title function_">name</span><span class="params">(<span class="keyword">final</span> String name)</span> &#123;</span><br><span class="line">      <span class="built_in">this</span>.name$value = name;</span><br><span class="line">      <span class="built_in">this</span>.name$set = <span class="literal">true</span>;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> User <span class="title function_">build</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="type">String</span> <span class="variable">name$value</span> <span class="operator">=</span> <span class="built_in">this</span>.name$value;</span><br><span class="line">      <span class="keyword">if</span> (!<span class="built_in">this</span>.name$set) &#123;</span><br><span class="line"><span class="comment">//执行build方法的时候，如果name没有设置，调用设置默认值</span></span><br><span class="line">        name$value = User.$<span class="keyword">default</span>$name();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">User</span>(name$value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;User.UserBuilder(name$value=&quot;</span> + <span class="built_in">this</span>.name$value + <span class="string">&quot;)&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>所以使用Lombok的<code>@Builder</code>注解默认是不会初始化默认值的，如果需要使用默认值，需要将版本升级到1.6.x，并使用<code>@Builder.Default</code>注解标记有默认值的属性。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Lombok @Builder注解可以让我们很方便的使用builder模式构建对象，但是今天发现使用@Builder注解创建对象时，不会初始化默认值。&lt;/p&gt;
&lt;p&gt;我们测试一下，先写个demo：&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;ta</summary>
      
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
    <category term="踩坑" scheme="https://eoccc.gitee.io/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>DDD大杂烩</title>
    <link href="https://eoccc.gitee.io/2022/08/21/DDD%E5%A4%A7%E6%9D%82%E7%83%A9/"/>
    <id>https://eoccc.gitee.io/2022/08/21/DDD%E5%A4%A7%E6%9D%82%E7%83%A9/</id>
    <published>2022-08-21T07:25:19.000Z</published>
    <updated>2022-10-06T04:25:27.255Z</updated>
    
    <content type="html"><![CDATA[<p>记录一些DDD的知识，比较碎。</p><span id="more"></span><h1 id="设计的两个阶段"><a class="markdownIt-Anchor" href="#设计的两个阶段"></a> 设计的两个阶段</h1><p>领域驱动设计一般分为两个阶段：</p><blockquote><ol><li>以一种领域专家、设计人员、开发人员都能理解的“通用语言”作为相互交流的工具，在不断交流的过程中发现和挖出一些主要的领域概念，然后将这些概念设计成一个领域模型；</li><li>由领域模型驱动软件设计，用代码来表现该领域模型。领域需求的最初细节，在功能层面通过领域专家的讨论得出。</li></ol></blockquote><h1 id="领域模型"><a class="markdownIt-Anchor" href="#领域模型"></a> 领域模型</h1><p>领域模型具有以下特点：</p><blockquote><ol><li>领域模型是对具有某个边界的领域的一个抽象，反映了领域内用户业务需求的本质；领域模型是有边界的，只反应了我们在领域内所关注的部分；</li><li>领域模型只反映业务，和任何技术实现无关；领域模型不仅能反映领域中的一些实体概念，如货物，书本，应聘记录，地址，等；还能反映领域中的一些过程概念，如资金转账，等；</li><li>领域模型确保了我们的软件的业务逻辑都在一个模型中，都在一个地方；这样对提高软件的可维护性，业务可理解性以及可重用性方面都有很好的帮助；</li><li>领域模型能够帮助开发人员相对平滑地将领域知识转化为软件构造；</li><li>领域模型贯穿软件分析、设计，以及开发的整个过程；领域专家、设计人员、开发人员通过领域模型进行交流，彼此共享知识与信息；因为大家面向的都是同一个模型，所以可以防止需求走样，可以让软件设计开发人员做出来的软件真正满足需求；</li><li>要建立正确的领域模型并不简单，需要领域专家、设计、开发人员积极沟通共同努力，然后才能使大家对领域的认识不断深入，从而不断细化和完善领域模型；</li><li>为了让领域模型看的见，我们需要用一些方法来表示它；图是表达领域模型最常用的方式，但不是唯一的表达方式，代码或文字描述也能表达领域模型；</li><li>领域模型是整个软件的核心，是软件中最有价值和最具竞争力的部分；设计足够精良且符合业务需求的领域模型能够更快速的响应需求变化；</li></ol></blockquote><h1 id="一些基本概念"><a class="markdownIt-Anchor" href="#一些基本概念"></a> 一些基本概念</h1><h2 id="实体"><a class="markdownIt-Anchor" href="#实体"></a> 实体</h2><p>实体（Entity）通常具备唯一id，能够被持久化，具有业务逻辑，对应现实世界业务对象。不要理解成简单的orm的对象。</p><h2 id="值对象"><a class="markdownIt-Anchor" href="#值对象"></a> 值对象</h2><p>值对象（value object）描述事物的对象，可以用来传递参数或对实体进行补充，可以认为是实体的属性，没有唯一id。</p><p>如果值对象是共享的，那么这个值对象的所有属性都应该只读。</p><p>值对象的属性应该尽可能简单，不要引用很多其他对象。</p><h2 id="聚合及聚合根"><a class="markdownIt-Anchor" href="#聚合及聚合根"></a> 聚合及聚合根</h2><p>聚合（aggregation）是用来定义领域边界的领域模式，通过定义清晰的对象所属关系和边界来实现领域的内聚，避免错综复杂的关系网。</p><p>一个聚合是一组对象组成的关系整体，每个聚合都有一个根对象，即聚合根（aggregation root），外部只能通过聚合根访问内部的聚合。</p><p>聚合的划分会直接映射到程序的结构上，DDD推荐按聚合设计子包，每个聚合对应一个子包，内部包括entity、value object、repository、domain等。</p><p>聚合的特点：</p><blockquote><ol><li>每个聚合有一个根和一个边界，边界定义了一个聚合内部有哪些实体或值对象，聚合根是聚合内的某个实体；</li><li>聚合内部的对象之间可以相互引用，但是聚合外部如果要访问聚合内部的对象时，必须通过聚合根访问聚合内的对象，也就是说聚合根是外部可以保持对它的引用的唯一元素；</li><li>聚合内除根以外的其他实体的唯一标识都是本地标识，也就是只要在聚合内部保持唯一即可；</li><li>聚合根负责与外部其他对象打交道并维护自己内部的业务规则；</li><li>聚合内部的对象可以持有其他聚合根的引用；</li><li>删除一个聚合根时必须同时删除该聚合内的所有相关对象。</li></ol></blockquote><h2 id="工厂"><a class="markdownIt-Anchor" href="#工厂"></a> 工厂</h2><p>工厂（Factory）用来封装创建一个复杂对象尤其是聚合时所需的逻辑，作用是将创建对象的细节隐藏起来。客户传递给工厂一些简单的参数，然后工厂可以在内部创建出一个复杂的领域对象然后返回给客户。当创建<strong>复杂的</strong>实体或值对象时建议使用工厂模式。</p><p>一个良好的工厂应该具有以下特点：</p><blockquote><ol><li>每个创建方法都是原子的；</li><li>一个工厂应该只能生产透明状态的对象；</li><li>创建整个实体时满足所有的变量；</li><li>一个工厂创建聚合根，聚合内部的实体通过聚合根调用其他工厂创建。</li></ol></blockquote><p>工厂会与其参数产生耦合，对于参数的选择，来自较低设计层的参数会更加安全。</p><p>工厂应该处理创建过程中的所有异常，可以定义一定的标准，比如发生异常的时候返回null，或者抛出指定的异常以通知使用者。</p><p>可以将固定规则的检查工作委托给工厂，而且这通常是最佳的。</p><h2 id="仓储"><a class="markdownIt-Anchor" href="#仓储"></a> 仓储</h2><p>仓储（Repositories）是用来存储实体的集合。仓储中存储的一定是聚合。</p><p>repository面向的是聚合根，dao面向的是数据访问，dao的方法是细粒度的。客户端应该始终调用领域对象，领域对象再调用dao实现数据库交互。</p><h2 id="服务"><a class="markdownIt-Anchor" href="#服务"></a> 服务</h2><p>服务（Service）只负责协调并委派业务逻辑给领域对象进行处理，其本身并不真正实现业务逻辑，绝大部分的业务逻辑都由领域对象承载和实现。</p><p>Service可与多种组件进行交互，包括：其他的service、领域对象和repository 或 dao。</p><p>服务接口的入参和出参都应该是dto。</p><h2 id="dto"><a class="markdownIt-Anchor" href="#dto"></a> DTO</h2><p>数据传输对象（Data Transfer Object）可以起到隐藏领域细节，帮助实现独立封闭的领域模型的作用。</p><p>DTO与领域对象之间的转换通常由Assembler承担。</p><h2 id="interface"><a class="markdownIt-Anchor" href="#interface"></a> Interface</h2><p>Interface层包含与其他系统/客户进行交互的接口与通信设施，在多数应用里，该层可能提供包括web service、rmi或rest等在内的一种或多种通信接口。该层主要由facade、dto和assembler三类组件构成，三类组件均是典型的j2ee模式。</p><h2 id="application"><a class="markdownIt-Anchor" href="#application"></a> Application</h2><p>Application层中主要组件是service。只负责协调并委派业务逻辑给领域对象进行处理。</p><h2 id="domain"><a class="markdownIt-Anchor" href="#domain"></a> Domain</h2><p>Domain层是整个系统的核心层，该层维护一个使用面向对象技术实现的领域模型，几乎全部的业务逻辑会在该层实现。Domain层包含entity（实体）、value object(值对象)、domain event（领域事件）和repository（仓储）等多种重要的领域组件。</p><h2 id="infrastructure"><a class="markdownIt-Anchor" href="#infrastructure"></a> Infrastructure</h2><p>Infrastructure（基础设施层）为interfaces、application和domain三层提供支撑。所有与具体平台、框架相关的实现会在infrastructure中提供，避免三层特别是domain层掺杂进这些实现，从而“污染”领域模型。Infrastructure中最常见的一类设施是对象持久化的具体实现。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;记录一些DDD的知识，比较碎。&lt;/p&gt;</summary>
    
    
    
    
    <category term="DDD" scheme="https://eoccc.gitee.io/tags/DDD/"/>
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>时间轮</title>
    <link href="https://eoccc.gitee.io/2022/08/10/%E6%97%B6%E9%97%B4%E8%BD%AE/"/>
    <id>https://eoccc.gitee.io/2022/08/10/%E6%97%B6%E9%97%B4%E8%BD%AE/</id>
    <published>2022-08-10T14:52:41.000Z</published>
    <updated>2022-08-21T13:19:47.693Z</updated>
    
    <content type="html"><![CDATA[<p>JDK中Timer和DelayQueue可以实现定时任务和延时操作的功能，但是O(nlogn)的时间复杂度在高并发的时候存在性能瓶颈，因此Kafka、Netty、ZooKeeper、Quartz等组件都使用了时间轮作为定时器。</p><span id="more"></span><h1 id="单层时间轮"><a class="markdownIt-Anchor" href="#单层时间轮"></a> 单层时间轮</h1><h2 id="时间轮的概念"><a class="markdownIt-Anchor" href="#时间轮的概念"></a> 时间轮的概念</h2><p>时间轮( TimingWheel) 是一个存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表( TimerTaskList)。 TimerTaskList 是一个环形的双向链表，链表中的元素即为定时任务( TimerTaskEntry)，其中封装了真正的定时任务 (TimerTask) 。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h5dde2pmc6j20mc0cwq3s.jpg" alt="image-20220820161912938" style="zoom:60%;"><p>时间轮的特征：</p><blockquote><ol><li>时间轮由多个时间格组成，时间格的个数固定为wheelSize</li><li>每个时间格的时间跨度为tickMs</li><li>总的时间跨度interval即为 tickMs * wheelSize</li><li>时间轮当前所处的时间为currentTime，currentTime是tickMs的整数倍</li></ol></blockquote><h2 id="插入任务"><a class="markdownIt-Anchor" href="#插入任务"></a> 插入任务</h2><p>当前时间为currentTime，要插入一个延时时间为delayTime的任务时，会将这个任务插入到当前时间格+(delayTime/tickMs)格中。</p><p>假设时间轮的tickMs为1ms，wheelSize为20。初始时currentTime指向时间格0，此时要插入一个定时为2ms，则会将这个任务插入到时间格2中。</p><p>当时间过了2ms后，currentTime指向了时间格2，需要将时间格2对应的TimTaskList中的任务执行。</p><p>此时又有一个定时为8的任务需要插入，则会插入到时间格10。</p><p>如果此时又要插入一个定时为19ms的任务，则会插入到时间格1。</p><p>但是需要注意，这个<strong>时间轮的interval时间为20ms，即插入的任务的定时不能超过20ms。</strong></p><h2 id="执行任务"><a class="markdownIt-Anchor" href="#执行任务"></a> 执行任务</h2><p>currentTime 可以将整个时间轮划分 为到期部分和未到期部分， currentTime 当前指向的时间格也属于到期部分，表示刚好到期，需 要处理此时间格所对应的 TimerTaskList 中的所有任务。</p><h1 id="多层时间轮"><a class="markdownIt-Anchor" href="#多层时间轮"></a> 多层时间轮</h1><p>当一层时间轮的interval时间不够用时，我们就需要升级到多层时间轮。多层时间轮之间的wheelSize是相同的，下一层时间轮的tickMs是上一层时间轮的interval：</p><blockquote><p>假设第一层的时间轮为：tickMs=1ms、wheelSize=20、inteval=20ms</p><p>则第二层的时间轮为：tickMs=20ms、wheelSize=20、inteval=400ms</p></blockquote><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h5dddyenmtj20nw0ni760.jpg" alt="image-20220820171558184" style="zoom:50%;"><h2 id="插入任务-2"><a class="markdownIt-Anchor" href="#插入任务-2"></a> 插入任务</h2><p>当一层时间轮的interval不足以容纳一个任务的定时时，就会升级到下一层时间轮。</p><p>在前面的时间轮中，如果我们要插入一个定时为350ms的任务时，第一层时间轮不足以容纳，就会升级到第二层时间轮，最终放到时间格17中（350/40=17）。</p><p>由于最低层的时间轮的tickMs=1，则这个时间轮的精度为1ms。</p><h2 id="执行任务-2"><a class="markdownIt-Anchor" href="#执行任务-2"></a> 执行任务</h2><p>随着时间的流逝，第二层的的currentTiume指向了第17格，即时间走了340ms，对于之前插入的定时为350ms的任务，还剩余10ms，这时还不能执行这个任务。</p><p>此时，会将这个任务从第二层时间轮中取出，然后重新插入一个定时为10ms的任务，最终插入到第一层的时间格10，当currentTime指向第一层的时间格时，才会真正执行这个任务，并将这个任务从时间轮中删除。</p><p>但是如果我们在currentTime=0时，插入了一个定时为200ms的任务，最终插入到了第二层的时间格5，currentTime指向这个时间格的时候，这个任务剩余的时间为0，所以会直接执行，不需要重新插入时间轮。</p><p>另外，在判断一个任务能不能执行的时候，还需要判断时间轮的精度，如果剩余的时间小于时间轮的精度，则会直接执行，否则需要重新插入到时间轮。</p>]]></content>
    
    
    <summary type="html">定时任务、延时操作的定时器实现。</summary>
    
    
    
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>protobuf序列化和反序列化</title>
    <link href="https://eoccc.gitee.io/2022/08/10/protobuf%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <id>https://eoccc.gitee.io/2022/08/10/protobuf%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/</id>
    <published>2022-08-10T10:25:19.000Z</published>
    <updated>2022-08-16T01:55:47.894Z</updated>
    
    <content type="html"><![CDATA[<p>Protobuf是一个很优秀的序列化和反序列化工具，具有较高的效率，并且使用紧凑的二进制码，能够减小内存占用，但是有一些坑，需要我们能够正确的使用。这篇博客就来记录一些Protobuf的使用和一些踩过的坑。</p><span id="more"></span><p>使用protobuf序列化和反序列化时，需要注意：</p><blockquote><ol><li>不支持Map类型，可以包装成其他类型再进行序列化</li><li>添加新字段的时候必须添加到尾部</li><li>不能修改名字</li><li>不能修改类型</li><li>不能删除字段</li></ol></blockquote><p>protobuf使用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">ProtoStuffSerializer</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Logger</span> <span class="variable">logger</span> <span class="operator">=</span> LoggerFactory.getLogger(ProtoStuffSerializer.class);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">byte</span>[] EMPTY_BYTES = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Field sizeField;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> &#123;</span><br><span class="line">      sizeField = WriteSession.class.getDeclaredField(<span class="string">&quot;size&quot;</span>);</span><br><span class="line">      sizeField.setAccessible(<span class="literal">true</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 序列化成字节数组</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="meta">@SuppressWarnings(&quot;all&quot;)</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">byte</span>[] serialize(Object obj) &#123;</span><br><span class="line">    <span class="keyword">if</span> (obj == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> EMPTY_BYTES;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="type">byte</span>[] bytes;</span><br><span class="line">      Schema&lt;Object&gt; schema = (Schema&lt;Object&gt;) getSchema(obj.getClass());</span><br><span class="line">      <span class="type">LinkedBuffer</span> <span class="variable">buffer</span> <span class="operator">=</span> LinkedBuffer.allocate(<span class="number">4096</span>);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        bytes = ProtobufIOUtil.toByteArray(obj, schema, buffer);</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        buffer.clear();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> bytes;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      logger.error(<span class="string">&quot;protostuff serialize error:&quot;</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> EMPTY_BYTES;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@SuppressWarnings(&quot;all&quot;)</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">byte</span>[] serialize(Object obj, <span class="type">byte</span>[] preFix) &#123;</span><br><span class="line">    <span class="keyword">if</span> (obj == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> EMPTY_BYTES;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="type">Schema</span> <span class="variable">schema</span> <span class="operator">=</span> getSchema(obj.getClass());</span><br><span class="line">      <span class="type">byte</span>[] init = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">8192</span>];</span><br><span class="line">      System.arraycopy(preFix, <span class="number">0</span>, init, <span class="number">0</span>, preFix.length);</span><br><span class="line">      <span class="type">LinkedBuffer</span> <span class="variable">buffer</span> <span class="operator">=</span> LinkedBuffer.wrap(init, <span class="number">0</span>, preFix.length);</span><br><span class="line">      <span class="keyword">final</span> <span class="type">ProtostuffOutput</span> <span class="variable">output</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ProtostuffOutput</span>(buffer);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        schema.writeTo(output, obj);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">NotSupportSerialException</span>(<span class="string">&quot;Serializing to a byte array threw an IOException &quot;</span> +</span><br><span class="line">                                            <span class="string">&quot;(should never happen).&quot;</span>, e);</span><br><span class="line">      &#125;</span><br><span class="line">      sizeField.set(output, output.getSize() + <span class="number">4</span>);</span><br><span class="line">      <span class="keyword">return</span> output.toByteArray();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      logger.error(<span class="string">&quot;protostuff serialize error: &quot;</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> EMPTY_BYTES;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 反序列化成对象</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; T <span class="title function_">deserialize</span><span class="params">(<span class="type">byte</span>[] bytes, Class&lt;T&gt; type)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (bytes == <span class="literal">null</span> || bytes.length &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      Schema&lt;T&gt; schema = getSchema(type);</span><br><span class="line">      <span class="type">T</span> <span class="variable">obj</span> <span class="operator">=</span> schema.newMessage();</span><br><span class="line">      ProtobufIOUtil.mergeFrom(bytes, obj, schema);</span><br><span class="line">      <span class="keyword">return</span> obj;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      logger.error(<span class="string">&quot;protostuff deserialize error: &quot;</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> &lt;T&gt; Schema&lt;T&gt; <span class="title function_">getSchema</span><span class="params">(Class&lt;T&gt; aClass)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (aClass == HashMap.class) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">NotSupportSerialException</span>(<span class="string">&quot;not support type:&quot;</span> + aClass);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> RuntimeSchema.getSchema(aClass);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;Protobuf是一个很优秀的序列化和反序列化工具，具有较高的效率，并且使用紧凑的二进制码，能够减小内存占用，但是有一些坑，需要我们能够正确的使用。这篇博客就来记录一些Protobuf的使用和一些踩过的坑。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
    <category term="踩坑" scheme="https://eoccc.gitee.io/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>开发经验教训总结</title>
    <link href="https://eoccc.gitee.io/2022/08/07/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C%E6%95%99%E8%AE%AD%E6%80%BB%E7%BB%93/"/>
    <id>https://eoccc.gitee.io/2022/08/07/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C%E6%95%99%E8%AE%AD%E6%80%BB%E7%BB%93/</id>
    <published>2022-08-07T14:52:41.000Z</published>
    <updated>2022-10-10T12:40:29.518Z</updated>
    
    <content type="html"><![CDATA[<p>从一个个故障的血泪教训，以及代码的坏味道中，总结一些开发经验。</p><span id="more"></span><h1 id="字段意义唯一性"><a class="markdownIt-Anchor" href="#字段意义唯一性"></a> 字段意义唯一性</h1><p>设计字段的时候，要尽可能保证字段所代表的逻辑的唯一性，不能一个字段控制了多个功能，否则会导致后期理解代码逻辑的成本急剧增加，并且出问题的概率也会增加，甚至是故障。</p><p>一个bad case：</p><blockquote><p>在我们的代码中存在了这样一个字段：productTypeCode，这个字段最开始是代表了商品类型，后来这个字段在后来的业务中被用作了其他的功能，比如上游系统中对商品进行分类，识别特殊的商品，因此，这个字段在业务代码中不断的被修改，有时候会换成另一个值，有时候加个后缀等等，以至于到了后来，我们都不知道这个字段到底是用来干嘛。</p></blockquote><h1 id="偶发性问题"><a class="markdownIt-Anchor" href="#偶发性问题"></a> 偶发性问题</h1><p>在beta环境偶发的问题，到了线上就一定会爆发，一定要查出根源，不要心存侥幸！不要心存侥幸！不要心存侥幸！</p><h1 id="map使用"><a class="markdownIt-Anchor" href="#map使用"></a> Map使用</h1><p>从map里面取出来的东西一定要进行判空处理，即使当前业务代码里面没有问题，随着代码的迭代，后面还是很有可能会发生NPE。不要成为水管工。</p><h1 id="删除字段"><a class="markdownIt-Anchor" href="#删除字段"></a> 删除字段</h1><p>随着业务的发展，线上的字段会越来越多，也会有一些字段被废弃掉。这时如果要删除（或者不赋值）没有用的字段，一定要慎重慎重再慎重，千万要理清楚字段的用途，以及影响范围，做好测试！否则可能会出现一些不可预知的bug，甚至是故障。</p><h1 id="业务降级"><a class="markdownIt-Anchor" href="#业务降级"></a> 业务降级</h1><p>我们都知道当业务出现问题的时候，可以选择降级，但是平时开发的时候往往就会忽略了降级，没有做相应的处理，一旦出现问题，可能就会引起全局的崩溃，导致故障。</p><p>开发的时候要尽量保证上线后业务可控，开发是做好开关控制，异常处理等，至少要能兜住一个模块内部的问题，不能影响其他业务。</p><h1 id="工具简单化"><a class="markdownIt-Anchor" href="#工具简单化"></a> 工具简单化</h1><p>开发工具的时候要尽可能将工具设计的简单易用，不要有太多的依赖，或者需要做太多的超过，要尽可能的做到上手即用，因为不是所有人都会去扒代码看工具的逻辑。如果需要配置，也要做到只需要配置一次，后面就可以直接使用。</p><p>一个case：</p><blockquote><p>我们写了一个加载配置的工具，在读配置的时候，会根据不同的配置格式将配置解析成系统可以直接使用的格式，但是新增配置的时候，需要将新配置的key添加到相应格式的key集合中，有人开发的时候就会忘记添加key，导致读取不到新配置。</p></blockquote><p>老代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; listFormatLabels = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Map&lt;String, List&lt;String&gt;&gt; listMap = Maps.newConcurrentMap();</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">initLabel</span><span class="params">()</span> &#123;</span><br><span class="line">  listFormatLabels.clear();</span><br><span class="line">  listFormatLabels.add(<span class="string">&quot;aaa&quot;</span>)</span><br><span class="line">  listFormatLabels.add(<span class="string">&quot;bbb&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">resolveListProperties</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (CollectionUtils.isEmpty(listFormatLabels)) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (String label : listFormatLabels) &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">config</span> <span class="operator">=</span> getConfig(label);</span><br><span class="line">    <span class="keyword">if</span> (StringUtils.isBlank(config)) &#123;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    String[] split = config.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">    listMap.put(label, Lists.newArrayList(split));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>优化后，我们采取了动态解析的方式，取配置的时候再解析，并将解析后的配置存储起来：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Map&lt;String, List&lt;String&gt;&gt; listMap = Maps.newConcurrentMap();</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;String&gt; <span class="title function_">getList</span><span class="params">(String label, List&lt;String&gt; defaultValue)</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (listMap.containsKey(label)) &#123;</span><br><span class="line">    <span class="keyword">return</span> listMap.get(label);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  List&lt;String&gt; result = defaultValue;</span><br><span class="line">  <span class="type">String</span> <span class="variable">value</span> <span class="operator">=</span> configMap.get(label);</span><br><span class="line">  <span class="keyword">if</span> (StringUtils.isNotBlank(value)) &#123;</span><br><span class="line">    result = SplitterUtil.split2List(value, <span class="string">&quot;,&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  listMap.put(label, result);</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="防腐层"><a class="markdownIt-Anchor" href="#防腐层"></a> 防腐层</h1><p>开发中往往会忽略防腐层的重要性，直接在业务中直接使用VO（View Object），导致后面修改对象时，需要修改一大片。所以要尽可能做好防腐，在业务中使用DTO（Data Transfer Object）。</p><h1 id="静态代码块"><a class="markdownIt-Anchor" href="#静态代码块"></a> 静态代码块</h1><p>类加载的顺序对于静态变量和静态代码块的执行顺序是按顺序执行的，因此我们最好把静态变量放在静态代码块之前，避免执行静态代码块的时候，静态变量还没有初始化，从而导致异常。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestStatic</span> &#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="type">Integer</span> <span class="variable">a</span> <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        print();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(a);</span><br><span class="line">        System.out.println(b);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">static</span> <span class="type">Integer</span> <span class="variable">b</span> <span class="operator">=</span> <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出：</span></span><br><span class="line"><span class="comment">//     1</span></span><br><span class="line"><span class="comment">//     null</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">从代码的坏味道中，总结一些开发经验。</summary>
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>软引用和弱的使用场景</title>
    <link href="https://eoccc.gitee.io/2022/07/10/%E8%BD%AF%E5%BC%95%E7%94%A8%E5%92%8C%E5%BC%B1%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
    <id>https://eoccc.gitee.io/2022/07/10/%E8%BD%AF%E5%BC%95%E7%94%A8%E5%92%8C%E5%BC%B1%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</id>
    <published>2022-07-09T16:00:00.000Z</published>
    <updated>2022-08-01T04:58:42.278Z</updated>
    
    <content type="html"><![CDATA[<p>我们日常开发中一般不会使用到软引用，因此对这块可能比较陌生，看过一些使用场景，但是过一段时间可能就忘记了，这篇博客就整理一下软引用的使用场景。</p><span id="more"></span><h1 id="软引用"><a class="markdownIt-Anchor" href="#软引用"></a> 软引用</h1><p>软引用的特点：当系统的内存不足时，进行回收，否则不会回收。</p><p>应用场景：</p><blockquote><ol><li>保存网页资源，如图片等</li><li>Spring 缓存配置属性缓存–SoftReferenceConfigurationPropertyCache</li></ol></blockquote><h1 id="弱引用"><a class="markdownIt-Anchor" href="#弱引用"></a> 弱引用</h1><p>软引用的特点：下一次GC的时候会回收</p><p>应用场景：</p><blockquote><ol><li>ThreaLocal中的map实现，此map继承了弱引用WeakReference，防止map中的key引用的对象无法被回收（线程一直处于活跃状态，导致ThreaLocal不会被回收）；</li><li>一些高速缓存场景，缓存仅在GC之间生效。</li></ol></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;我们日常开发中一般不会使用到软引用，因此对这块可能比较陌生，看过一些使用场景，但是过一段时间可能就忘记了，这篇博客就整理一下软引用的使用场景。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>缓存淘汰算法总结</title>
    <link href="https://eoccc.gitee.io/2022/06/20/%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    <id>https://eoccc.gitee.io/2022/06/20/%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</id>
    <published>2022-06-19T16:00:00.000Z</published>
    <updated>2022-09-22T13:25:47.574Z</updated>
    
    <content type="html"><![CDATA[<p>以前看到过一些缓存淘汰的算法，觉得很是精妙，比如大名鼎鼎的LRU、LFU、FIFO，以及mysql版的LRU，redis的缓存淘汰策略，GuavaCache的缓存淘汰算法，等等。写篇博客总结一下～～</p><span id="more"></span><h1 id="lru"><a class="markdownIt-Anchor" href="#lru"></a> LRU</h1><p>LRU(Least Recently Used)：最近最少使用算法。</p><p>核心思想：这种算法认为最近使用的数据是热点数据，很有可能被再次使用，而最近很少使用的数据是冷门数据，很有可能不再使用。当缓存容量满了的时候，优先淘汰最近最少使用的数据。</p><p>缓存满的状态下：</p><blockquote><ol><li>读取一条缓存，将更新这条缓存的使用时间</li><li>插入一条缓存，将移除时间最远的一条缓存</li></ol></blockquote><h2 id="lru实现"><a class="markdownIt-Anchor" href="#lru实现"></a> LRU实现</h2><p>LRU可以使用LinkedHashMap实现，从而达到O(1)的查询复杂度和更新复杂度。Hash实现O(1)的查询复杂度，链表维护缓存的新鲜度，靠近链表头部的数据是冷门数据，靠近链表尾部的数据是热点数据。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h4a9md6paaj20su0ay0tk.jpg" alt="image-20220713094354095" style="zoom:50%;"><p><em>LinkedHashMap提供了accessOrder选项，设置为true的时，访问node会将node移动到链表尾部。</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> V <span class="title function_">get</span><span class="params">(Object key)</span> &#123;</span><br><span class="line">  Node&lt;K,V&gt; e;</span><br><span class="line">  <span class="keyword">if</span> ((e = getNode(hash(key), key)) == <span class="literal">null</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (accessOrder)</span><br><span class="line">    afterNodeAccess(e);</span><br><span class="line">  <span class="keyword">return</span> e.value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//访问后的处理</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">afterNodeAccess</span><span class="params">(Node&lt;K,V&gt; e)</span> &#123;</span><br><span class="line">  LinkedHashMap.Entry&lt;K,V&gt; last;</span><br><span class="line">  <span class="comment">//如果accessOrder为true，会将node移动到尾部</span></span><br><span class="line">  <span class="keyword">if</span> (accessOrder &amp;&amp; (last = tail) != e) &#123;</span><br><span class="line">    LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after;</span><br><span class="line">    p.after = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (b == <span class="literal">null</span>)</span><br><span class="line">      head = a;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      b.after = a;</span><br><span class="line">    <span class="keyword">if</span> (a != <span class="literal">null</span>)</span><br><span class="line">      a.before = b;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      last = b;</span><br><span class="line">    <span class="keyword">if</span> (last == <span class="literal">null</span>)</span><br><span class="line">      head = p;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      p.before = last;</span><br><span class="line">      last.after = p;</span><br><span class="line">    &#125;</span><br><span class="line">    tail = p;</span><br><span class="line">    ++modCount;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><em>LinkedHashMap重写了HashMap的newNode方法，put的时候会将新创建的node放到node的尾部。</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//插入方法使用的是HashMap的put方法</span></span><br><span class="line"><span class="comment">//hashMap.put -&gt; hashMap.putVal -&gt; LinkedHashMap.newNode</span></span><br><span class="line">Node&lt;K,V&gt; <span class="title function_">newNode</span><span class="params">(<span class="type">int</span> hash, K key, V value, Node&lt;K,V&gt; e)</span> &#123;</span><br><span class="line">  LinkedHashMap.Entry&lt;K,V&gt; p = <span class="keyword">new</span> <span class="title class_">LinkedHashMap</span>.Entry&lt;&gt;(hash, key, value, e);</span><br><span class="line">  linkNodeLast(p);</span><br><span class="line">  <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="lru查询"><a class="markdownIt-Anchor" href="#lru查询"></a> LRU查询</h3><p>当缓存中不包含查询的key时，返回空。</p><p>当查询到数据时，需要将缓存移动到链表的尾部。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h4a9m9z2lqj20tg0bewfg.jpg" alt="image-20220713094854303" style="zoom:50%;"><h3 id="lru更新"><a class="markdownIt-Anchor" href="#lru更新"></a> LRU更新</h3><p>缓存容量未满时：</p><ul><li>缓存中不包含key，直接在链表的尾部插入新的缓存</li><li>缓存中包含key，更新缓存的value，并移动到链表的尾部</li></ul><p>缓存容量满时：</p><ul><li>缓存中不包含key，移除链表头部的数据，然后在链表的尾部插入新的数据</li><li>缓存中包含key，更新缓存的value，并移动到链表的尾部</li></ul><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h4a9m9moz2j20tg0bewfg.jpg" alt="image-20220713095155195" style="zoom:50%;"><h1 id="lfu"><a class="markdownIt-Anchor" href="#lfu"></a> LFU</h1><p>LFU(Least Frequently Used)：最近最不常用算法，根据数据的历史访问频率来淘汰数据。</p><p>核心思想：最近使用频率高的数据很大概率将会再次被使用，而最近使用频率低的数据很大概率不会再使用。淘汰使用频率最小的数据。</p><p>缺点：如果一条sh数据用的频率非常高，然后在某一时刻废弃不用了，这条数据会在很长时间内存在于缓存中，不能被淘汰。</p><h2 id="lfu实现"><a class="markdownIt-Anchor" href="#lfu实现"></a> LFU实现</h2><p>LFU也使用hash+链表的实现，同样可以基于LinkedHashMap实现，但是要重写get方法。</p><h3 id="lfu查找"><a class="markdownIt-Anchor" href="#lfu查找"></a> LFU查找</h3><p>在LFU中查找并访问一条数据后，会：</p><blockquote><ol><li>将这个node的访问频率加1</li><li>将这个node移动到相同频率的node的前面</li></ol></blockquote><p>如：A(10)-&gt;B(9)-&gt;C(9)-&gt;D(8)</p><p>当D被访问后，会变成：A(10)-&gt;D(9)-&gt;B(9)-&gt;C(9)</p><h3 id="lfu插入"><a class="markdownIt-Anchor" href="#lfu插入"></a> LFU插入</h3><p>当插入一条缓存时：</p><blockquote><ol><li>如果缓存容量未满，将node放到链表尾部</li><li>如果缓存容量满了，移除链表尾部的一个node，然后将新的node放到链表尾部</li></ol></blockquote><h1 id="arc"><a class="markdownIt-Anchor" href="#arc"></a> ARC</h1><p>ARC(Adaptive Replacement Cache): 自适应缓存替换算法，它结合了LRU与LFU，来获得可用缓存的最佳使用。</p><p>ARC将整个Cache分成四部分：</p><blockquote><ul><li>最近最多使用的缓存链表，LRU链表</li><li>最近最频繁使用的缓存链表，LFU链表</li><li>最近从LRU表中淘汰的缓存链表，ghost LRU链表，只存储key，不存储真正的数据</li><li>最近从LFU表中淘汰的缓存链表，ghost LFU链表，只存储key，不存储真正的数据</li></ul></blockquote><p>初始时，LRU和LFU的空间各占一半，后续会动态适应调整partion的位置。</p><h2 id="arc查找"><a class="markdownIt-Anchor" href="#arc查找"></a> ARC查找</h2><p>先从LRU缓存中查找，如果命中LRU中的缓存，说明这个缓存时访问频率高的缓存，将node移动到LFU缓存中：</p><blockquote><ol><li>如果在LRU链表中查找到缓存，将这个node移动到LFU链表中。<ul><li>如果LFU链表没满，直接追加到尾部</li><li>如果LFU链表满了，将LFU尾部的node的key移动到<strong>ghost LFU</strong>链表中，再将新的node追加进去</li><li>ghost LFU链表按照LFU算法进行淘汰</li></ul></li><li>如果在LRU链表中没查找到缓存，从LFU中查找</li><li>如果LRU缓存和LFU缓存都没有查找到，从磁盘加载数据<ul><li>如果缓存的key存在于ghost LRU中，则将LRU链表的长度加1，LFU链表的长度减1，将缓存插入到LRU链表中</li><li>如果缓存的key存在于ghost LFU中，则将LFU链表的长度加1，LRU链表的长度减1，将缓存插入到LFU链表中</li></ul></li></ol></blockquote><h2 id="arc插入"><a class="markdownIt-Anchor" href="#arc插入"></a> ARC插入</h2><p>任何缓存的插入都要先插入到LRU缓存中：</p><blockquote><ol><li><p>如果LRU缓存没有满，直接将缓存追加到LRU缓存的尾部</p></li><li><p>如果LRU缓存满了：</p><ul><li><p>将LRU缓存的头部节点移动到<strong>ghost LRU</strong>中</p></li><li><p>将新的缓存插入到LRU的尾部</p></li><li><p>ghost LRU按照LRU算法进行淘汰</p></li></ul></li></ol></blockquote><h1 id="w-tinylfu"><a class="markdownIt-Anchor" href="#w-tinylfu"></a> W-TinyLFU</h1><p>W-TinyLFU（Window Tiny Least Frequently Used）是对LFU的的优化和加强。</p><p>W-TinyLFU算法分为三个区域，WindowLRU区域、TinyLFU区域、SLRU-主Cache区域：</p><blockquote><ol><li><p>缓存插入时，先进入WindowLRU区</p></li><li><p>WindowLRU区淘汰的数据进入TinyLFU区</p><p>被WindowLRU区淘汰，说明这个数据不是最近需要访问的数据，但是有可能其访问频率很高，进入TinyLFU区</p></li><li><p>TinyLFU区满了以后，将频率最高的数据移动到SLRU区</p></li><li><p>SLRU区满了以后，将淘汰的数据重新放到TinyLFU区</p></li></ol></blockquote><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h4bii54r6ij21ia0nywgr.jpg" alt="img" style="zoom:35%;"><p>另外，LFU通常使用一个map来保存key的访问频率，由于使用map，就会产生hash冲突。caffeine使用了Count-Min Sketch算法存储访问频率。</p><h2 id="hash算法"><a class="markdownIt-Anchor" href="#hash算法"></a> hash算法</h2><p>Count-Min Sketch算法类似于布隆过滤器，采用4个hash函数进行hash计算，取得四个位置的频率后，取最小值。另外，Count-Min Sketch算法使用四个数组来保存频率。</p><p><img src="/.io//34d432e4f2cd21c4ef18c76074940f81-20220718234745930.png" alt="img"></p><h2 id="驱逐策略"><a class="markdownIt-Anchor" href="#驱逐策略"></a> 驱逐策略</h2><p>但是存在一个问题，如果一个访问频率超级高的数据，突然没有用了，会一直在SLRU区和TinyLFU区中倒腾，就是不能被淘汰，因此caffeine还提供了三种驱逐策略：</p><blockquote><ol><li><p>基于大小：</p><p>可以使用Caffeine.maximumSize(long)方法来指定缓存的最大容量。当缓存超出这个容量的时候，会使用<a href="https://github.com/ben-manes/caffeine/wiki/Efficiency">Window TinyLfu策略</a>来删除缓存。</p></li><li><p>基于时间：</p><ul><li>expireAfterAccess(long, TimeUnit)：在最后一次访问或者写入后开始计时，在指定的时间后过期。</li><li>expireAfterWrite(long, TimeUnit)： 在最后一次写入缓存后开始计时，在指定的时间后过期。</li><li>expireAfter(Expiry)： 自定义策略，过期时间由Expiry实现独自计算。</li></ul></li><li><p>基于引用：没有引用指向数据时，才会驱逐缓存。</p></li></ol></blockquote><h1 id="一点想法"><a class="markdownIt-Anchor" href="#一点想法"></a> 一点想法</h1><p>对于某些缓存在一定时间内访问的频率很高，积攒了很高的访问频率，导致这些缓存长期存在而不能被淘汰，可以定时对缓存的使用频率进行平滑处理，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">newFrequency = f(oldFrequency) </span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">缓存淘汰算法LRU、LFU、W-TinyLFU等</summary>
    
    
    
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
</feed>
