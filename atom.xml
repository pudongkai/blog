<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Eoccc的博客</title>
  
  
  <link href="https://eoccc.gitee.io/atom.xml" rel="self"/>
  
  <link href="https://eoccc.gitee.io/"/>
  <updated>2023-07-02T10:28:18.754Z</updated>
  <id>https://eoccc.gitee.io/</id>
  
  <author>
    <name>Eoccc</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Mysql- SQL优化</title>
    <link href="https://eoccc.gitee.io/2023/06/23/Mysql-%20SQL%E4%BC%98%E5%8C%96/"/>
    <id>https://eoccc.gitee.io/2023/06/23/Mysql-%20SQL%E4%BC%98%E5%8C%96/</id>
    <published>2023-06-23T08:25:19.000Z</published>
    <updated>2023-07-02T10:28:18.754Z</updated>
    
    <content type="html"><![CDATA[<p>数据库插入也有门道。</p><span id="more"></span><h1 id="插入优化"><a class="markdownIt-Anchor" href="#插入优化"></a> 插入优化</h1><h2 id="插入"><a class="markdownIt-Anchor" href="#插入"></a> 插入</h2><p><strong>批量插入</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> table_name <span class="keyword">values</span> (<span class="number">1</span>, col) (<span class="number">2</span>, col);</span><br></pre></td></tr></table></figure><p><strong>手动提交事务</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">start</span> transaction;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> table_name <span class="keyword">values</span> (<span class="number">1</span>, col) (<span class="number">2</span>, col);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> table_name <span class="keyword">values</span> (<span class="number">3</span>, col);</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure><p><strong>主键顺序插入</strong></p><p>按照主键顺序插入，效率会比乱序插入高。如果是乱序插入的，会导致页分裂，以及页之间的指针重排。</p><p><strong>大批量插入数据</strong></p><p>如果一次性插入大批量数据，使用insert插入的性能较低，可以使用load指令进行插入。</p><ol><li><p>连接数据库时加上参数 --local-infile</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql <span class="comment">--local-infile -u root -p</span></span><br></pre></td></tr></table></figure></li><li><p>打开加载文件开关（默认关闭）</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> <span class="keyword">local</span><span class="operator">-</span>infile<span class="operator">=</span><span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p>执行load指令</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> infile <span class="string">&#x27;file_path&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> <span class="string">&#x27;table_name&#x27;</span> fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span>;</span><br></pre></td></tr></table></figure></li></ol><h2 id="页分裂"><a class="markdownIt-Anchor" href="#页分裂"></a> 页分裂</h2><p>如下图，当需要插入新的数据50的时候：</p><ol><li><p>50需要插入到23之后，但是由于page1已经满了，所以需要申请一个新的page3</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230702172225136-8289876.png" alt="image-20230702172225136"></p></li><li><p>将23和47移动到page3，然后把50插入到23之后<br><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230702172612547-20230702172813631.png" alt="image-20230702172612547"></p></li><li><p>将page3移动到page1和page2之间（设置指针即可）</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230702172932009.png" alt="image-20230702172932009"></p></li></ol><h2 id="页合并"><a class="markdownIt-Anchor" href="#页合并"></a> 页合并</h2><p>当删除一行记录时，innodb会将这行记录标记为删除状态，当删除的记录占用的空间达到<code>MERGE_THRESHOLD</code> （默认为50%）时，会查尝试将附近的页合并，以优化空间使用。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230702173309657.png" alt="image-20230702173309657"></p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230702173616680.png" alt="image-20230702173616680"></p><h1 id="主键的优化"><a class="markdownIt-Anchor" href="#主键的优化"></a> 主键的优化</h1><ol><li>尽量降低主键的长度</li><li>插入数据时，尽量顺序插入（使用自增主键）</li><li>尽量不要使用UUID或其他自然主键，如身份证号（因为这些主键是乱序的，而且比较长）</li><li>业务操作时，尽量不要修改主键</li></ol><h1 id="order-by-优化"><a class="markdownIt-Anchor" href="#order-by-优化"></a> order by 优化</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">order</span> <span class="keyword">by</span> age;</span><br></pre></td></tr></table></figure><ul><li><p>Using filesort：不直接通过索引返回排序结果的排序。通过索引或全表扫描，读取满足条件的记录，然后在排序缓冲区sort buffer中排序。</p></li><li><p>Using index：通过有序索引顺序扫描直接返回有序记录，不需要额外排序。</p></li></ul><ol><li><p>如果索引没有覆盖排序字段，会回表查询，使用filesort排序</p></li><li><p>如果我们通过多个字断进行排序，而且排序方式不一样，会导致不使用索引：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> name,phone,age <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">order</span> <span class="keyword">by</span> phone <span class="keyword">asc</span>, age <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><p>我们可以对需要排序的字断以及排序方式建立索引：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> index idx_phone_age <span class="keyword">user</span>(phone <span class="keyword">asc</span>, age <span class="keyword">desc</span>);</span><br></pre></td></tr></table></figure></li></ol><p>总结：</p><blockquote><ol><li>根据排序字段建立合适的索引，多字段排序时，遵循最左前缀原则</li><li>使用覆盖索引</li><li>多字段排序时，一个升序一个降序，创建联合索引时制定排序规则</li><li>不可避免filesort时，可以适当增大排序缓冲区sort_buffer_size（默认256kb）</li></ol></blockquote><h1 id="group-by-优化"><a class="markdownIt-Anchor" href="#group-by-优化"></a> group by 优化</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">User</span> <span class="keyword">group</span> <span class="keyword">by</span> age;</span><br></pre></td></tr></table></figure><p>Using index：使用索引进行分组</p><p>Using temporary：使用临时表进行分组。</p><blockquote><ol><li>进行分组操作时，使用索引提高效率</li><li>通过多字段进行分组时，遵循最左前缀原则</li></ol></blockquote><h1 id="limt-优化"><a class="markdownIt-Anchor" href="#limt-优化"></a> limt 优化</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tb_sku limit <span class="number">100000</span>, <span class="number">10</span>;</span><br></pre></td></tr></table></figure><p>当表的数据量比较大了，对越靠后的记录进行limt操作时，效率越低。</p><p>通过覆盖索引 + 字查询进行优化：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> s.<span class="operator">*</span> form tb_sku s, (<span class="keyword">select</span> id <span class="keyword">from</span> tb_sku limit <span class="number">100000</span>, <span class="number">10</span>) a <span class="keyword">where</span> s.id<span class="operator">=</span>a.id;</span><br></pre></td></tr></table></figure><h1 id="count-优化"><a class="markdownIt-Anchor" href="#count-优化"></a> count 优化</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> tb_sku;</span><br></pre></td></tr></table></figure><ul><li>MyIsam 记录了表的总行数，可以直接返回</li><li>InnoDb 需要查询所有记录，进行计数</li></ul><p>优化：自己计数，如在redis中自己维护一个计数。</p><h1 id="update-优化"><a class="markdownIt-Anchor" href="#update-优化"></a> update 优化</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> age<span class="operator">=</span><span class="number">20</span> <span class="keyword">where</span> name<span class="operator">=</span><span class="string">&#x27;小明&#x27;</span>;</span><br></pre></td></tr></table></figure><p>如果where后面的条件没有使用索引，innodb会锁住整个表。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;数据库插入也有门道。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Mysql- 架构</title>
    <link href="https://eoccc.gitee.io/2023/06/20/Mysql-%20%E6%9E%B6%E6%9E%84/"/>
    <id>https://eoccc.gitee.io/2023/06/20/Mysql-%20%E6%9E%B6%E6%9E%84/</id>
    <published>2023-06-20T08:25:19.000Z</published>
    <updated>2023-07-11T02:09:00.872Z</updated>
    
    <content type="html"><![CDATA[<p>Mysql架构：组件、内存、磁盘、后台线程。</p><span id="more"></span><h1 id="系统组件"><a class="markdownIt-Anchor" href="#系统组件"></a> 系统组件</h1><img src="https://gitee.com/eoccc/pic-shack/raw/master/28d0034482b249a98168aed306faae72.png" alt="28d0034482b249a98168aed306faae72.png" style="zoom:50%;"><p>上来先看Mysql架构图（摘自《MySQL技术内幕 InnoDB存储引擎》）。Mysql主要包括以下组件：</p><blockquote><ol><li>连接器 Connectors</li><li>系统管理&amp;控制工具</li><li>连接池</li><li>Sql接口</li><li>Sql解释器</li><li>Sql优化器</li><li>缓存池</li><li>存储引擎</li><li>文件系统</li></ol></blockquote><p>接下来介绍一下每个组件的简要功能，由于每个组件都可以展开讲很多，这篇文章只会对组件做一个简要的描述，有一个简单的概念。</p><h2 id="连接器connectors"><a class="markdownIt-Anchor" href="#连接器connectors"></a> 连接器(Connectors)</h2><blockquote><p>Connectors组件是Mysql向外提供的交互组件，支持多种语言与Mysql的交互，如java, .net, php等。</p></blockquote><h2 id="系统管理控制工具management-service-utilities"><a class="markdownIt-Anchor" href="#系统管理控制工具management-service-utilities"></a> 系统管理&amp;控制工具(Management Service &amp; Utilities)</h2><blockquote><p>提供对Mysql的集成管理，如备份与恢复、安全管理、集群、配置等。</p></blockquote><h2 id="连接池connection-pool"><a class="markdownIt-Anchor" href="#连接池connection-pool"></a> 连接池(Connection Pool)</h2><blockquote><p>负责监听对客户端向Mysql Server端的各种请求，接收请求，转发请求到目标模块。Mysql会为每个成功连接Mysql Server的客户端创建或分配一个线程，该线程负责客户端与Mysql Server端的通信，接收客户端发送的命令，传递服务端的结果信息等。<br><font color="red">想必大家都听说过数据库连接数过多，就是会导致连接池不够用，造成拒绝。</font><br>查看及设置最大连接数：</p> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;%max_connections%&#x27;</span>;</span><br><span class="line"><span class="keyword">set</span> <span class="keyword">GLOBAL</span> max_connections<span class="operator">=</span><span class="number">500</span>;  <span class="operator">/</span><span class="operator">/</span>重启后失效</span><br></pre></td></tr></table></figure><p>通过配置文件修改最大连接数：my.conf -&gt; <code>max_connections=512</code><br>连接数不能过大，因为Mysql会为每个连接提供连接缓冲区。</p></blockquote><h2 id="sql接口sql-interface"><a class="markdownIt-Anchor" href="#sql接口sql-interface"></a> SQL接口(SQL Interface)</h2><blockquote><p>接受用户的sql命令，如DML、DDL、存储过程等，并且返回用户需要查询的结果。</p></blockquote><h2 id="sql解释器parser"><a class="markdownIt-Anchor" href="#sql解释器parser"></a> SQL解释器(Parser)</h2><blockquote><p>分析SQL命令语法的合法性，并尝试将sql命令分解成数据结构，若解析失败，则提示SQL语句不合法。主要功能是将sql语句分解成数据结构，并将这个结构传递到后续步骤，以后SQL语句的传递和处理就是基于这个结构的。</p></blockquote><h2 id="sql优化器optimizer"><a class="markdownIt-Anchor" href="#sql优化器optimizer"></a> SQL优化器(Optimizer)</h2><blockquote><p>查询优化器，SQL语句在查询之前会使用查询优化器对查询进行优化。他使用的是“选取-投影-联接”策略进行查询</p></blockquote><h2 id="缓冲池caches-buffers"><a class="markdownIt-Anchor" href="#缓冲池caches-buffers"></a> 缓冲池(Caches &amp; Buffers)</h2><blockquote><p>查询缓存，如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。通过LRU算法将数据的冷端溢出，未来得及刷新到磁盘的数据页，叫脏页。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等。</p></blockquote><h2 id="存储引擎pluggable-storage-engines"><a class="markdownIt-Anchor" href="#存储引擎pluggable-storage-engines"></a> 存储引擎(Pluggable Storage Engines)</h2><blockquote><p>插件式存储引擎。提供各种存储引擎，真正的负责MySQL中数据的存储和提取。<br>Mysql支持的存储引擎：InnoDB、MyISAM、MEMORY、CSV、BLACKHOLE、FEDERATED、MRG_MYISAM、ARCHIVE、PERFORMANCE_SCHEMA。其中BDB和InnoDB提供事务安全表，其他存储引擎都是非事务安全表。</p></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/20230701172516383.png" alt="20230701172516383.png" style="zoom:77%;"><h2 id="文件系统"><a class="markdownIt-Anchor" href="#文件系统"></a> 文件系统</h2><blockquote><p>数据存储层，主要是将数据存储到设备的文件系统中，并完成与存储引擎的交互。</p></blockquote><p><strong>了解完Mysql的系统架构后，我们就可以知道SQL的执行流程：</strong></p><blockquote><p>数据库通常不会被单独使用，而是由其它编程语言通过SQL支持接口调用MySQL。由MySQL处理并返回执行结果。</p><ol><li>编程语言通过SQL支持接口调用MySQL，</li><li>MySQL收到请求后，会将该请求暂时放在连接池，并由管理服务与工具进行管理。</li><li>当该请求从等待队列进入到处理队列时，管理器会将该请求传给SQL接口，SQL接口接收到请求后，它会将请求进行hash处理并与缓存中的数据进行对比，如果匹配则通过缓存直接返回处理结果；否则，去文件系统查询</li><li>由SQL接口传给后面的解析器，解析器会判断SQL语句是否正确，若正确则将其转化为数据结构。</li><li>解析器处理完毕后，便将处理后的请求传给优化器控制器，它会产生多种执行计划，最终数据库会选择最优的方案去执行。</li><li>确定最优执行计划后，SQL语句交由存储引擎处理，存储引擎将会到文件系统中取得相应的数据，并原路返回。</li></ol></blockquote><h1 id="innodb存储结构"><a class="markdownIt-Anchor" href="#innodb存储结构"></a> InnoDB存储结构</h1><h2 id="逻辑存储结构"><a class="markdownIt-Anchor" href="#逻辑存储结构"></a> 逻辑存储结构</h2><img src="https://gitee.com/eoccc/pic-shack/raw/master/v2-e44f8f9761bdbceca13dff1df91a2232_1440w.jpg" alt="v2-e44f8f9761bdbceca13dff1df91a2232_1440w.jpg" style="zoom:60%;"><h3 id="表空间"><a class="markdownIt-Anchor" href="#表空间"></a> 表空间</h3><p>表空间（Tablespace）用于存储记录、索引等数据，一个mysql实例可以有多个表空间，表空间的信息存储在<strong>ibd</strong>文件中。</p><p>如果用户启用了参数<code>innodb_file_per_table</code>，则每张表内的数据（包括数据、索引和插入缓冲Bitmap页）可以单独放到一个表空间内，但是其他数据，如回滚信息、插入缓冲索引页、系统事务信息等还是存放在原来的共享表空间内。</p><h3 id="段"><a class="markdownIt-Anchor" href="#段"></a> 段</h3><p>段（segment），常见的段有数据段、索引段、回滚段等。innoDB是索引组织表，数据段就是索引B+树的叶子节点，索引段即为B+树的非叶子节点。</p><h3 id="区"><a class="markdownIt-Anchor" href="#区"></a> 区</h3><p>区（Extent），表空间的单元结构，每个区的大小为1M，默认情况下，一个区中包含64个连续的页。</p><h3 id="页"><a class="markdownIt-Anchor" href="#页"></a> 页</h3><p>页（Page），innoDB磁盘管理的最小单元，每个页默认16kb，为了保证页的连续性，innoDB每次从磁盘中申请4～5个区。</p><h3 id="行"><a class="markdownIt-Anchor" href="#行"></a> 行</h3><p>行（Row），innoDB存储记录的最小单元，除了显式申明的字段，innoDB还会默认加入两个字段：</p><blockquote><p>事务id（Trx Id）：每次新增或修改记录时，会把对应的事物id保存到Trx Id隐藏列</p><p>回滚id（Roll pointer）：每次对记录进行修改时，innoDB会把旧版写入到undo log，然后通过Roll pointer隐藏列指向旧版的记录。</p></blockquote><h2 id="内存架构"><a class="markdownIt-Anchor" href="#内存架构"></a> 内存架构</h2><img src="/.io//image-20230710151651642.png" alt="image-20230710151651642" style="zoom:50%;"><h3 id="缓冲池"><a class="markdownIt-Anchor" href="#缓冲池"></a> 缓冲池</h3><p>缓冲池（Buffer Pool）是主内存中的一个区域，用于存储磁盘上经常进行操作的数据，在执行增删改查操作时，先操作缓冲池中的数据（若缓冲池中没有需要的数据，则从磁盘加载并缓存），然后再以一定的频率刷新到磁盘，从而减少磁盘IO，提升效率。</p><p>缓冲池中的数据以page为单位，并使用双向链表（page内部的记录使用单向链表连接）管理数据。根据page的状态，将page分为三种：</p><blockquote><p>gree page：空闲的page，未被使用</p><p>clean page：被使用过，但是没有被修改过</p><p>dirty page：数据被修改过，数据与磁盘中的数据不一致，需要刷到磁盘</p></blockquote><p><strong>缓冲池的LRU算法</strong></p><p>实际生产环境中会存在全表扫描的情况，如果数据量较大，可能会将Buffer Pool中存下来的热点数据给全部替换出去，而这样就会导致该段时间MySQL性能断崖式下跌——<strong>缓冲池污染</strong>。</p><p>为了解决这一问题，Mysql将缓冲池分成了两个部分：New Sublist 和 Old Sublist，分别占用了 Buffer Pool 的3/4和1/4。当新页插入的时候，会把新页放到New Sublist 和 Old Sublist 之间，该位置叫<strong>MidPoint</strong>。当这些数据被访问过后，会被移动到 New Sublist 的头部。这样一来，虽然这些页数据在链表中了，但是由于没有被访问过，就会被移动到后1/4的 Old Sublist中去，直到被清理掉。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230710154147502.png" alt="image-20230710154147502" style="zoom:43%;"><p>通常来说，宿主机80%的内存都应该分配给Buffer Pool，因为Buffer Pool越大，其能缓存的数据就更多，更多的操作都会发生在内存，从而达到提升效率的目的。</p><h3 id="修改缓冲区"><a class="markdownIt-Anchor" href="#修改缓冲区"></a> 修改缓冲区</h3><p>更改缓冲区 （Change Buffer，针对于非唯一二级索引页），在执行DML语句时，如果这些数据Page没有在Buffer Pool中，不会直接操作磁盘，而会将数据变更存在更改缓冲区 Change Buffer 中，在未来数据被读取时，再将数据合并恢复到Buffer Pool中，再将合并后的数据刷新到磁盘中。</p><p>是新增或者删除记录时，很有可能会影响二级索引的不相邻的页（Buffer Pool中没有二级索引），导致磁盘IO，Mysql将对二级索引的操作先缓存在 Change Buffer 中，以一定的频率（或当 Change Buffer 中的记录被访问时）合并到 Buffer Pool 中，再由 Buffer Pool 刷新到磁盘。</p><h3 id="自适应hash索引"><a class="markdownIt-Anchor" href="#自适应hash索引"></a> 自适应hash索引</h3><p>自适应hash索引（Adaptive Hash Index）用于优化对 Buffer Pool 数据的查询。lnnoDB存储引擎会监控对表上各索引页的查询，如果观察到hash索引可以提升速度，则建立hash索引，称之为自适应hash索引。</p><h3 id="日志缓冲区"><a class="markdownIt-Anchor" href="#日志缓冲区"></a> 日志缓冲区</h3><p>日志缓冲区（Log Buffer）用来存储那些即将被刷入到磁盘文件中的日志，例如Redo Log、Undo Log。Log Buffer的默认值为16M，可以通过配置参数<code>innodb_log_buffer_size</code>来进行调整。</p><p>当Log Buffer如果较大，就可以存储更多的Redo Log，这样一来在事务提交之前我们就不需要将Redo Log刷入磁盘，只需要丢到Log Buffer中去即可。因此较大的Log Buffer就可以更好的支持较大的事务运行；同理，如果有事务会大量的更新、插入或者删除行，那么适当的增大Log Buffer的大小，也可以有效的减少部分磁盘I/O操作。</p><p>Log Buffer中的数据刷入到磁盘的频率，可以通过参数<code>innodb_flush_log_at_trx_commit</code>来决定。</p><h2 id="磁盘结构"><a class="markdownIt-Anchor" href="#磁盘结构"></a> 磁盘结构</h2><h3 id="系统表空间"><a class="markdownIt-Anchor" href="#系统表空间"></a> 系统表空间</h3><p>系统表空间（System Tablespace）是更改缓冲区的存储区域。如果表是在系统表空间而不是每个表文件或通用表空间中创建的，它也可能包含表和索引数据。(在MySQL5.x版本中还包含InnoDB数据字典、undolog等)<br>参数: innodb_data file_path</p><h3 id="独立表空间"><a class="markdownIt-Anchor" href="#独立表空间"></a> 独立表空间</h3><p>独立表空间（File-Per-Table Tablespaces）包含单个InnoDB表的数据和索引，并存储在文件系统上的单个数据文件中。<br>参数: innodb_file_per_table，默认开启</p><h3 id="通用表空间"><a class="markdownIt-Anchor" href="#通用表空间"></a> 通用表空间</h3><p>通用表空间（GeneralTablespaces）需要通过 CREATE TABLESPACE 语法创建，然后在创建表时指定使用该表空间。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span>space table_space_name <span class="keyword">add</span> datafile<span class="string">&#x27;file_name.ibd&#x27;</span> engine <span class="operator">=</span> innodb;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> a(id <span class="type">int</span> <span class="keyword">primary</span> key auto increment, name <span class="type">varchar</span>(<span class="number">10</span>)) engine<span class="operator">=</span>innodb tablespace table_space_name;</span><br></pre></td></tr></table></figure><h3 id="撤销表空间"><a class="markdownIt-Anchor" href="#撤销表空间"></a> 撤销表空间</h3><p>撤销表空间（Undo Tablespaces）用于存储undo log日志，MySQL实例在初始化时会自动创建两个默认的 undo 表空间（初始大小16M）。</p><h3 id="临时表空间"><a class="markdownIt-Anchor" href="#临时表空间"></a> 临时表空间</h3><p>临时表空间（Temporary Tablespaces）存储用户创建的临时表等数据，InnoDB 使用会话临时表空间和全局临时表空间。</p><h3 id="双写缓冲区"><a class="markdownIt-Anchor" href="#双写缓冲区"></a> 双写缓冲区</h3><p>双写缓冲区（Doublewrite Buffer Files），innoDB引擎将数据页从Buffer Pool刷新到磁盘前，先将数据页写入双写缓冲区文件中，便于系统异常时恢复数据。</p><h3 id="重做日志"><a class="markdownIt-Anchor" href="#重做日志"></a> 重做日志</h3><p>重做日志（Redo Log）是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log），前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都会存到该日志中，用于在刷新脏页到磁盘发生错误时，进行数据恢复。</p><h2 id="后台线程"><a class="markdownIt-Anchor" href="#后台线程"></a> 后台线程</h2><h3 id="master-thread"><a class="markdownIt-Anchor" href="#master-thread"></a> Master Thread</h3><p>核心后台线程，负责：</p><blockquote><ol><li>调度其他线程</li><li>将缓冲池中的数据异步刷新到磁盘中，保持数据的一致性</li><li>脏页的刷新、合并插入缓存、undo页的回收</li></ol></blockquote><h3 id="io-thread"><a class="markdownIt-Anchor" href="#io-thread"></a> IO Thread</h3><p>在InnoDB存储引擎中大量使用了AIO来处理IO请求，这样可以极大地提高数据库的性能，而IO Thread主要负责这些IO请求的回调。包括4个线程：</p><table><thead><tr><th>线程类型</th><th>默认个数</th><th>职责</th></tr></thead><tbody><tr><td>Read thread</td><td>4</td><td>负责读操作</td></tr><tr><td>Write thread</td><td>4</td><td>负责写操作</td></tr><tr><td>Log thread</td><td>1</td><td>负责将日志缓冲区刷新到磁盘</td></tr><tr><td>Insert buffer thread</td><td>1</td><td>负责将写缓冲区内容刷新到磁盘</td></tr></tbody></table><h3 id="purge-thread"><a class="markdownIt-Anchor" href="#purge-thread"></a> Purge Thread</h3><p>主要用于回收事务已经提交了的undo log，在事务提交之后，undo log可能不用了，就用它来回收。</p><h3 id="page-cleaner-thread"><a class="markdownIt-Anchor" href="#page-cleaner-thread"></a> Page Cleaner Thread</h3><p>协助 Master Thread 刷新脏页到磁盘的线程，它可以减轻 Master Thread 的工作压力，减少阻塞。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Mysql架构：组件、内存、磁盘、后台线程。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Queue 之 help gc</title>
    <link href="https://eoccc.gitee.io/2023/06/14/Queue%20%E4%B9%8B%20help%20gc/"/>
    <id>https://eoccc.gitee.io/2023/06/14/Queue%20%E4%B9%8B%20help%20gc/</id>
    <published>2023-06-14T10:25:19.000Z</published>
    <updated>2023-06-24T16:05:01.540Z</updated>
    
    <content type="html"><![CDATA[<p><code>java.util.concurrent.LinkedBlockingQueue#dequeue</code>有一行代码<code>h.next = h</code> 被注释上了help gc，那么它到底是怎么帮助gc的呢？</p><span id="more"></span><p><code>LinkedBlockingQueue#dequeue</code>源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> E <span class="title function_">dequeue</span><span class="params">()</span> &#123;</span><br><span class="line">    Node&lt;E&gt; h = head;</span><br><span class="line">    Node&lt;E&gt; first = h.next;</span><br><span class="line">    h.next = h; <span class="comment">// help GC</span></span><br><span class="line">    head = first;</span><br><span class="line">    <span class="type">E</span> <span class="variable">x</span> <span class="operator">=</span> first.item;</span><br><span class="line">    first.item = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码移除并返回了队列的头节点，具体分成几个步骤：</p><ol><li>h指向head节点</li><li>first指向第一个node</li></ol><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624225338150.png" alt="640-20230624225338150.png"></p><ol start="3"><li>h.next 指向自己 (help gc)</li></ol><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624225534349.png" alt="640-20230624225534349.png"></p><ol start="4"><li>将 head 指向 first</li><li>取到 first 的 value （作为返回值）</li><li>将 first 的value 置为 null</li></ol><p>这段代码执行完之后，链表的变化：</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624230007345.png" alt="640-20230624230007345.png"></p><p>那么，如果说没有 <code>h.next = h</code> 这行代码，执行之后会变成：</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624230206795.png" alt="640-20230624230206795.png"></p><p>这时，头节点已经没有任何引用指向它了，也就是GC不可达，理论上会被垃圾回收器回收。</p><p>JVM大佬讲了，如果没有这行代码，会造成跨代引用，从而导致不可回收（直到发生FGC），视频第23分钟：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.infoq.com/presentations/twitter-services/</span><br></pre></td></tr></table></figure><p><strong>过程分析：</strong></p><ol><li>我们创建了一个队列，由于队列是一个大对象，或者生命比较长，被分配在了老年代，合情合理</li><li>往队列里面添加了两个新元素A、B。由于是新对象，所以被分配在了年轻代，完全ok</li></ol><p><img src="/.io//640-20230624231339106.png" alt="图片"></p><ol start="3"><li>然后插入新的元素C、D、E，干掉A、B。这时A、B已经GC不可达，会被垃圾回收器回收，没问题</li></ol><p><img src="/.io//640-20230624231640223.png" alt="图片"></p><ol start="3"><li>经过几轮的ygc之后，C节点由于一直没有被移除，晋升到老年代</li></ol><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230624235930226.png" alt="640-20230624235930226.png"></p><ol start="4"><li>这时C出队，由于C在老年代，ygc时不会被回收，直到fgc</li><li>如果接着出队D，此时老年代的C还指向D，D也不会被回收</li></ol><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230625000229506.png" alt="640-20230625000229506.png"></p><p>因此，在出队的时候，一定需要断开头节点和下一个节点的连接。</p><p><strong>那么为什么一定要指向它自己呢？改成<code>h.next = null</code>行不行？</strong></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;java.util.concurrent.LinkedBlockingQueue#dequeue&lt;/code&gt;有一行代码&lt;code&gt;h.next = h&lt;/code&gt; 被注释上了help gc，那么它到底是怎么帮助gc的呢？&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>协程-小试牛刀</title>
    <link href="https://eoccc.gitee.io/2023/06/06/%E5%8D%8F%E7%A8%8B-%E5%B0%8F%E8%AF%95%E7%89%9B%E5%88%80/"/>
    <id>https://eoccc.gitee.io/2023/06/06/%E5%8D%8F%E7%A8%8B-%E5%B0%8F%E8%AF%95%E7%89%9B%E5%88%80/</id>
    <published>2023-06-06T14:53:04.949Z</published>
    <updated>2023-07-01T09:14:59.601Z</updated>
    
    <content type="html"><![CDATA[<p>JDK还不支持协程，终究是一大遗憾。好消息是jdk19引入了虚线程，弥补了这一遗憾，但是还需要经历一定时间的验证，公司生产环境的jdk一般也没有使用这么高版本的jdk。</p><span id="more"></span><h1 id="协程的优势"><a class="markdownIt-Anchor" href="#协程的优势"></a> 协程的优势</h1><p>纤程（Fiber）是一种轻量级的并发执行单元，与线程（Thread）相比具有以下优点和缺点：</p><p><strong>优点：</strong></p><blockquote><ol><li><strong>更轻量级</strong>：纤程相对于线程更加轻量级，占用的内存资源更少，可以实现更高密度的并发执行。</li><li><strong>更高效</strong>：纤程的上下文切换比线程更加高效，因为它们是在应用程序内部进行切换，不需要进入内核态，也不需要切换地址空间。</li><li><strong>更灵活</strong>：纤程可以通过应用程序自己的调度算法进行管理和调度，因此可以实现更灵活的并发编程模型。</li><li><strong>更容易实现协作式调度</strong>：纤程可以更容易地实现协作式调度，即在纤程自己主动让出CPU资源的情况下进行切换，这可以避免线程之间的竞争和锁等并发编程中常见的问题。</li></ol></blockquote><p><strong>缺点：</strong></p><blockquote><ol><li><strong>无法充分利用多核CPU</strong>：由于纤程只能在单个线程中执行，因此不能充分利用多核CPU的能力。</li><li><strong>需要特定的编程模型</strong>：纤程需要使用特定的编程模型（比如协程）进行编程，这对于一些开发者来说可能需要一定的学习成本。</li><li><strong>可能会引起资源竞争问题</strong>：由于纤程是在应用程序内部进行调度和切换，因此可能会引起资源竞争问题，比如在纤程之间共享状态时需要进行同步和互斥处理。</li></ol></blockquote><h1 id="协程适用的场景"><a class="markdownIt-Anchor" href="#协程适用的场景"></a> 协程适用的场景</h1><p>与线程相比，纤程的上下文切换更加高效，可以更快地进行切换和恢复，因此在 I/O 密集型的应用场景下，使用纤程可以提高并发性能和吞吐量。</p><ol><li>协程更加轻量，对于IO密集型任务，使用协程可以减少资源占用</li><li>协程的上下文切换都是在用户态进行的，不需要进行内核态和用户态的切换，效率更高，因此需要进行频繁切换的任务也适合使用协程（其实改成单线程执行或许效率更高）</li></ol><p>对于CPU密集型任务，应该充分利用计算机多核的特性，使用多行程并行计算，提升处理速度。</p><h1 id="协程框架"><a class="markdownIt-Anchor" href="#协程框架"></a> 协程框架</h1><p>目前支持 java 的协程框架：</p><blockquote><ol><li>Quasar：一个基于 ASM 的轻量级协程框架，提供了完整的协程支持，包括协程调度、协程间通信等功能。</li><li>Project Reactor：一个基于 Reactive Stream 的响应式编程框架，提供了完整的反应式编程支持，包括异步、并发、流处理等功能。</li><li>Akka：一个基于 Actor 模型的分布式系统框架，提供了完整的 Actor 模型支持，包括并发、消息传递、容错等功能。</li><li>Vert.x：一个基于异步、事件驱动的应用框架，提供了完整的异步编程支持，包括网络编程、数据库操作、消息传递等功能。</li><li>Kotlin 协程：Kotlin 官方支持的协程框架，提供了完整的协程支持，包括协程调度、协程间通信等功能。</li></ol></blockquote><h1 id="协程使用示例"><a class="markdownIt-Anchor" href="#协程使用示例"></a> 协程使用示例</h1><p>这里基于 Quasar 实现一个协程的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.demo.my;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> co.paralleluniverse.fibers.Fiber;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">QuasarCoroutine</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> &#123;</span><br><span class="line">        tryFiber();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">tryFiber</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">        <span class="type">CountDownLatch</span> <span class="variable">countDownLatch</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CountDownLatch</span>(COUNT);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; COUNT; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Fiber</span>&lt;&gt;(countDownLatch::countDown).start();</span><br><span class="line">        &#125;</span><br><span class="line">        countDownLatch.await();</span><br><span class="line">        System.out.printf(<span class="string">&quot;fiber cost: %s\n&quot;</span>, System.currentTimeMillis() - start);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><em>jdk17有更严格的安全限制，不能通过反射获得对象，可配置参数开启指定包的访问权限：</em></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--add-opens java.base/java.lang=ALL-UNNAMED</span><br></pre></td></tr></table></figure><h1 id="协程与线程性能对比"><a class="markdownIt-Anchor" href="#协程与线程性能对比"></a> 协程与线程性能对比</h1><p>从执行速度和资源占用对协程和线程进行比较。</p><p>todo…</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;JDK还不支持协程，终究是一大遗憾。好消息是jdk19引入了虚线程，弥补了这一遗憾，但是还需要经历一定时间的验证，公司生产环境的jdk一般也没有使用这么高版本的jdk。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kafka-4 日志存储</title>
    <link href="https://eoccc.gitee.io/2023/04/09/kafka-4%20%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6/"/>
    <id>https://eoccc.gitee.io/2023/04/09/kafka-4%20%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6/</id>
    <published>2023-04-09T14:52:41.000Z</published>
    <updated>2023-06-06T14:53:05.080Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka中，一个分区对应一个日志，为了防止日志过大，又引入了日志段的概念（LogSegment），将日志切分为多个日志段，以便于维护和清理。一个LogSegment对应磁盘上的一个日志文件和两个索引文件。</p><span id="more"></span><h1 id="日志文件"><a class="markdownIt-Anchor" href="#日志文件"></a> 日志文件</h1><h2 id="日志分段"><a class="markdownIt-Anchor" href="#日志分段"></a> 日志分段</h2><p>在 Kafka 中，一个 topic 的消息被存储在一个或多个 partition 中，每个 partition 可以看作是一个有序、不可变的消息日志。为了便于管理和优化磁盘空间的利用，Kafka 中的每个 partition 被分成多个 segment，每个 segment 包含一段连续的消息。</p><p>当一个新消息写入 partition 时，Kafka 会将该消息追加到当前最新的 segment 中。当当前 segment 达到一定大小或者存储时间达到一定阈值时，Kafka 会自动将该 segment 封存（close）并创建一个新的 segment，作为 partition 的新的写入位置。</p><p>封存的 segment 不可修改，这就保证了 Kafka 中的消息具有不可变性和顺序性。同时，封存的 segment 可以被压缩（compaction），即删除已经过期或者被标记为删除的消息，以便更好地管理磁盘空间和减少数据复制的数据量。</p><p>Kafka 中的 segment 大小和存储时间可以通过配置文件进行设置。默认情况下，Kafka 会根据时间和大小两个因素来控制 segment 的滚动，以平衡性能和磁盘空间的利用。</p><p>需要注意的是，segment 大小和存储时间的设置应该根据业务需求和硬件资源情况进行调整。如果 segment 大小设置过小，可能会导致 segment 的切换频繁，影响 Kafka 的性能。如果 segment 存储时间设置过长，可能会导致数据的实时性下降，影响业务应用。</p><h2 id="日志文件结构"><a class="markdownIt-Anchor" href="#日志文件结构"></a> 日志文件结构</h2><img src="https://gitee.com/eoccc/pic-shack/raw/master/o9Qyhuqff.jpeg" alt="o9Qyhuqff.jpeg" style="zoom:60%;"><p>日志的文件夹的命名规则为：tpoic-partition。</p><p>向Log追加消息时是顺序写入的，只有最后一个LogSegment才能写入新的消息，最后一个LogSegment即活跃日志段。</p><p>日志段中包含一个 <strong>.log</strong> 的日志文件，一个 <strong>.index</strong> 的偏移量索引文件，一个 <strong>.timeIndex</strong> 的时间戳索引文件。日志文件和两个索引文件都是根据基准偏移量（固定为20位数字）命名的，即这个LogSegment的第一条日志的偏移量，如第一个LogSegment的基准偏移量为0，则日志文件名为 00000000000000000000.log。</p><p>LogSegment还包括 .deleted, .cleaned, .swap等临时文件，以及 .snapshot, .txnindex, leader-epoch-checkpoint等文件。</p><p>另外，kafka第一次启动的时候，还会创建以下文件：</p><blockquote><ol><li>cleaner-offset-checkpoint</li><li>log-start-offset-checkpoint</li><li>recovery-point offset-checkpoint</li><li>replicat ion-offset-checkpoint</li><li>meta.properties</li></ol></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/l6y5sq3gO.jpeg" alt="img/l6y5sq3gO.jpeg" style="zoom:60%;"><h1 id="kafka日志压缩"><a class="markdownIt-Anchor" href="#kafka日志压缩"></a> Kafka日志压缩</h1><p>Kafka 中的日志压缩可以通过参数配置来设置触发压缩的条件。Kafka 支持基于消息大小和时间的压缩触发机制，即：</p><blockquote><ol><li>消息大小触发压缩：当日志分段文件中待写入消息的大小超过了配置参数 <code>log.segment.bytes</code>，即分段文件的大小时，Kafka 会触发日志的压缩操作。</li><li>时间触发压缩：当日志分段文件中待写入消息的时间距离上一次日志压缩的时间超过了配置参数 <code>log.roll.ms</code>，即分段文件的滚动时间时，Kafka 会触发日志的压缩操作。</li></ol></blockquote><p>Kafka 提供了多种数据压缩技术，可以在不影响数据实时性的前提下，最大限度地利用磁盘空间。Kafka 支持以下三种数据压缩技术：</p><blockquote><ol><li>GZIP：GZIP 是一种基于 DEFLATE 压缩算法的数据压缩技术，可以实现较高的压缩比。GZIP 压缩后的数据体积更小，可以节省磁盘空间，但是解压缩会消耗一定的 CPU 资源，可能会影响数据的处理性能。</li><li>Snappy：Snappy 是一种基于 Google 的 Zippy 压缩算法的数据压缩技术，可以实现较快的压缩和解压缩速度。Snappy 压缩后的数据体积相对较小，可以在不影响数据处理性能的前提下，实现数据的压缩和解压缩。</li><li>LZ4：LZ4 是一种基于 Lempel-Ziv 算法的数据压缩技术，可以实现较高的压缩和解压缩速度。LZ4 压缩后的数据体积相对较小，可以在不影响数据处理性能的前提下，实现数据的压缩和解压缩。</li></ol></blockquote><p>Kafka 中的数据压缩技术可以通过配置文件中的 <code>compression.type</code> 参数进行设置，支持多种压缩算法。需要注意的是，不同的压缩算法适用于不同的场景和数据类型，需要根据实际情况选择合适的压缩算法，以达到最优的压缩效果和数据处理性能。</p><p><strong><font color="red">注意：</font>活跃的日志分段不会参与日志压缩。</strong></p><h1 id="日志清理"><a class="markdownIt-Anchor" href="#日志清理"></a> 日志清理</h1><p>Kafka通过三种策略来清理日志文件：基于时间、基于日志大小、基于日志起始偏移量。</p><h2 id="基于时间清理日志"><a class="markdownIt-Anchor" href="#基于时间清理日志"></a> 基于时间清理日志</h2><p>日志删除任务会检查当前日志文件中是否有保留时间超过阈值的日志分段集合，保留时间可以配置毫秒、分钟和小时，优先级依次降低：</p><blockquote><p>log.retention.hours  默认为168，即7天</p><p>log.retention.minutes</p><p><a href="http://log.retention.ms">log.retention.ms</a></p></blockquote><p>查找过期日志分段文件时，先从 .timeindex 时间戳索引文件中获取最后一条索引的时间戳，如果时间戳大于0，则取其值，否则取最后修改时间。</p><p>如果所有的日志分段都已经过期，会先切出一个新的日志分段作为活跃日志分段，再把过期的日志分段删除。</p><p>删除日志分段时，会先从Log对象所维护的日志分段跳跃表中移除待删除的日志分段，以保证没有线程会读取这些日志，然后对日志分段的所有文件添加上 <strong>.deleted</strong> 后缀，最后由 <strong>delete-file</strong> 删除任务删除这些文件。delete-file 任务的执行周期通过 <code>file.delete.delay.ms</code> 配置，默认为1分钟。</p><h2 id="基于大小清理日志"><a class="markdownIt-Anchor" href="#基于大小清理日志"></a> 基于大小清理日志</h2><p>如果Log总size大于 <code>log.retention.bytes</code> 配置的阈值（默认为-1，即不限制），则会先计算需要删除的日志文件的大小，即总size和阈值的差值，然后从第一个日志分段开始计算，找出需要删除的日志分段，然后由删除任务执行删除。</p><p>单个日志分段的大小由 <code>log.segment.bytes</code> 配置，默认为1GB。</p><h2 id="基于起始偏移量清理日志"><a class="markdownIt-Anchor" href="#基于起始偏移量清理日志"></a> 基于起始偏移量清理日志</h2><p>kafka有一个logStartOffset记录了日志文件的起始偏移量，一般是第一个日志文件的 baseOffset，但是可能会改变。可以使用 KafkaAdminClient 的 <code>deleteRecords()</code> 方法、或使用 <a href="http://kafka-delete-records.sh">kafka-delete-records.sh</a> 脚本修改。</p><p>kafka会将偏移量小于 logStartOffset 的日志分段删除。如下图会将日志分段1和2删除。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/kFXC6GPCV.jpeg" alt="img/kFXC6GPCV.jpeg" style="zoom:50%;"><h1 id="零拷贝"><a class="markdownIt-Anchor" href="#零拷贝"></a> 零拷贝</h1><p>所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序，减少了内核和用户模式之间的上下文切换 。</p><p>一般情况下，如果我们要把一个数据发送给用户，会经过4次复制，进行了4次上下文切换：</p><blockquote><ol><li>调用 read() 方法，将文件中的内容被复制到内核模式下的 ReadBuffer 中；</li><li>CPU 控制将内核模式数据复制到用户模式下；</li><li>调用 write() 方法，将用户模式下的内容复制到内核模式下的 Socket Buffer 中；</li><li>将 SocketBuffer 中的数据复制到网卡设备中传迭。</li></ol></blockquote><p>在零拷贝中，直接将 SocketBuffer 中的数据复制到网卡设备中传迭，只需要进行2次复制，进行了2次上下文切换：</p><blockquote><ol><li>read() 方法，将文件的内容复制到内核模式下的 ReadBuffer 中；</li><li>将<strong>包含数据的位置和长度信息的文件描述符</strong>添加到 Socket Buffer 中；</li><li>将 SocketBuffer 中的数据复制到网卡设备中传送。</li></ol></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;Kafka中，一个分区对应一个日志，为了防止日志过大，又引入了日志段的概念（LogSegment），将日志切分为多个日志段，以便于维护和清理。一个LogSegment对应磁盘上的一个日志文件和两个索引文件。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>写出整洁代码的tips</title>
    <link href="https://eoccc.gitee.io/2023/04/04/%E5%86%99%E5%87%BA%E6%95%B4%E6%B4%81%E4%BB%A3%E7%A0%81%E7%9A%84tips/"/>
    <id>https://eoccc.gitee.io/2023/04/04/%E5%86%99%E5%87%BA%E6%95%B4%E6%B4%81%E4%BB%A3%E7%A0%81%E7%9A%84tips/</id>
    <published>2023-04-04T14:52:41.000Z</published>
    <updated>2023-04-05T11:39:44.483Z</updated>
    
    <content type="html"><![CDATA[<p>一开始就要写整洁的代码，如果有不整洁的代码就要及时的整改，绝对不要有以后再改,以后再说的想法，因为：</p><p><strong><font color="red">letter equals never!</font></strong></p><span id="more"></span><p>不整洁的代码随着时间的增加而增加时，生产力会随之降低，导致的结果就是：</p><ul><li>代码不易扩展或扩展容易引发其他问题</li><li>程序崩溃</li><li>加班</li></ul><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230404210606658.png" alt="image-20230404210606658"></p><h1 id="命名"><a class="markdownIt-Anchor" href="#命名"></a> 命名</h1><p>好的命名可提高代码的可读性，让人见码知意，降低理解成本，提高效率，减少加班！</p><p><strong>1. 无意义的命名</strong></p><p>从命名上完全看不出方法或类的功能，没有任何意义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ABC</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">abc</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好的命名可以直接看出功能，开发者不需要阅读代码细节就能知道其作用。good case：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Animal</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">walk</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>2. 混淆的命名</strong></p><p>命名前后不一致，相同的功能，在不同的方法中使用不同的命名，造成混淆：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">StudentRepository</span> &#123;</span><br><span class="line">    </span><br><span class="line">    Student <span class="title function_">findOneById</span><span class="params">(<span class="meta">@Param(&quot;id&quot;)</span> String id)</span>;</span><br><span class="line"></span><br><span class="line">    List&lt;Student&gt; <span class="title function_">queryAllStudent</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>两个方法都是查Student，唯一的区别就是查一个和查全部，但是用了<font color=" #DB7093">find</font>和<font color=" #DB7093">query</font>命名。优化后：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">StudentRepository</span> &#123;</span><br><span class="line">   </span><br><span class="line">    Student <span class="title function_">findOne</span><span class="params">(<span class="meta">@Param(&quot;id&quot;)</span> String id)</span>;</span><br><span class="line"></span><br><span class="line">    List&lt;Student&gt; <span class="title function_">findAll</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="单一职责"><a class="markdownIt-Anchor" href="#单一职责"></a> 单一职责</h1><p><strong>类应该短小，类或模块应有且只有一条加以修改的理由</strong>，如果一个类过于庞大的话,那么说明它承担的职责过多了。</p><p>类的名称描述其全责，如果无法为某个类命以准确的名称，这个类大概就太长了，类名越含糊，可能拥有越多的职责。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">UpdateDB</span> &#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insertUser</span><span class="params">(User user)</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insertOrder</span><span class="params">(Order order)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个类的职责太大了，从类名不能直接看出这个类操作的是哪个数据库，将职责抽开：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">UpdateUserDB</span> &#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insertUser</span><span class="params">(User user)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="开闭原则"><a class="markdownIt-Anchor" href="#开闭原则"></a> 开闭原则</h1><p>开闭原则：面向修改关闭，面向扩展开放。</p><p>面向修改关闭意味着增加新的逻辑不会修改原有的代码，降低了出错的可能性。</p><p>面向扩展开放则是提高了代码的可扩展性，可很容易的增加新的代码逻辑。</p><p>不满足开闭原则的例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">insert</span><span class="params">(User user)</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">(User user)</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">delete</span><span class="params">(User user)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果我们要新增查询操作，就得修改这个类，没有做到面向修改关闭。优化后：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">invoke</span><span class="params">(User user)</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">InsertSql</span> <span class="keyword">extends</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">invoke</span><span class="params">(User user)</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UpdateSql</span> <span class="keyword">extends</span> <span class="title class_">Sql</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">invoke</span><span class="params">(User user)</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用：</span></span><br><span class="line"><span class="meta">@Resource</span></span><br><span class="line">Sql insertSql;</span><br><span class="line"></span><br><span class="line">insertSql.invoke(user);</span><br></pre></td></tr></table></figure><h1 id="高内聚低耦合"><a class="markdownIt-Anchor" href="#高内聚低耦合"></a> 高内聚低耦合</h1><p>将一个复杂的系统分解成更小的、可管理的部分，并通过将这些部分彼此隔离来降低它们之间的耦合度。</p><p>函数的第一规则是短小，第二规则是更短小，短小到只做一件事情。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String <span class="title function_">upload</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">// 校验图片的方法 代码80行</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 压缩图片的方法 代码50行</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 返回成功或失败标识 0,1 代码5行</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;0&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>原有的upload方法做了很多的事情，重构后只做了一件事情：<strong>把大一些的概念拆分为另一抽象层上的一系列步骤：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String <span class="title function_">upload</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">// 校验图片的方法</span></span><br><span class="line">    check();</span><br><span class="line">    <span class="comment">// 压缩图片的方法</span></span><br><span class="line">    compress();</span><br><span class="line">    <span class="comment">// 返回成功或失败标识 0,1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;0&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="函数命名"><a class="markdownIt-Anchor" href="#函数命名"></a> 函数命名</h1><p>函数要有描述性的名称，不要害怕长名称。</p><p>不好的命名方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String <span class="title function_">addCharacter</span><span class="params">(String originString, <span class="type">char</span> ch)</span>;</span><br></pre></td></tr></table></figure><p>从函数字面意思看是给某个字符串添加一个字符。但是到底是在原有字符串首部添加，还是在原有字符串末尾追加呢？亦或是在某个固定位置插入呢？从函数名字完全看不出来这个函数的真正意图，只能继续往下读这个函数的具体实现才知道。</p><p>优化后：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 追加到末尾</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">appendCharacter</span><span class="params">(String originString, <span class="type">char</span> ch)</span>;   </span><br><span class="line"></span><br><span class="line"><span class="comment">// 插入指定位置</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">insertCharacter</span><span class="params">(String originString, <span class="type">char</span> ch, <span class="type">int</span> insertPosition)</span>;</span><br></pre></td></tr></table></figure><h1 id="参数"><a class="markdownIt-Anchor" href="#参数"></a> 参数</h1><p><strong>参数越少越好</strong></p><p>参数越少，越容易理解，参数超过三个可以将参数进行封装，要按参数的语义进行封装，不一定封装成一个大而全的参数，可以封装为多个，原则是按语义补充。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;Student&gt; <span class="title function_">findStudent</span><span class="params">(<span class="type">int</span> age, String name, String country, <span class="type">int</span> gender)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//封装参数</span></span><br><span class="line"><span class="keyword">public</span> List&lt;Student&gt; <span class="title function_">findStudent</span><span class="params">(Student student)</span>;</span><br></pre></td></tr></table></figure><p><strong>不要使用标识参数</strong></p><p>标识参数是参数为 Boolean 类型，用户传递 true or false。不要使用标识参数因为这意味着你的函数违背了单一职责(true false 两套逻辑)。正确的做法是拆分为两个方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//标识参数方法</span></span><br><span class="line">order4User(<span class="type">boolean</span> isNewUser);</span><br><span class="line"></span><br><span class="line"><span class="comment">//重构为两个方法</span></span><br><span class="line">order4NewUser();</span><br><span class="line">order4OldUser();</span><br></pre></td></tr></table></figure><p><strong>不要使用输出参数</strong></p><p>输出参数就是将变量作为参数传入方法，并且将变量返回。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">findStudent</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">Student</span> <span class="variable">student</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Student</span>();</span><br><span class="line">    doSomething(student);</span><br><span class="line">    <span class="keyword">return</span> student;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> Student <span class="title function_">doSomething</span><span class="params">(Student student)</span>&#123;</span><br><span class="line">    <span class="comment">// 省略一些student逻辑</span></span><br><span class="line">    <span class="keyword">return</span> student;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果只看方法名称，我们不知道doSomething做了些什么，返回的参数和传入的参数是不是同一个，需要看具体的逻辑才知道。</p><p>正确的方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将doSomething()方法内聚到student对象本身</span></span><br><span class="line">student.doSomething();</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;一开始就要写整洁的代码，如果有不整洁的代码就要及时的整改，绝对不要有以后再改,以后再说的想法，因为：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;font color=&quot;red&quot;&gt;letter equals never!&lt;/font&gt;&lt;/strong&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>kafka-3 客户端</title>
    <link href="https://eoccc.gitee.io/2023/04/03/kafka-3%20%E5%AE%A2%E6%88%B7%E7%AB%AF/"/>
    <id>https://eoccc.gitee.io/2023/04/03/kafka-3%20%E5%AE%A2%E6%88%B7%E7%AB%AF/</id>
    <published>2023-04-03T14:52:41.000Z</published>
    <updated>2023-06-06T14:53:05.083Z</updated>
    
    <content type="html"><![CDATA[<p>总结kafka客户端的分区策略、幂等性和事务。</p><span id="more"></span><h1 id="消费者分区分配策略"><a class="markdownIt-Anchor" href="#消费者分区分配策略"></a> 消费者分区分配策略</h1><p>消费者消费消息之前，首先得进行分区分配，kafka提供了三种分区分配策略。</p><ol><li><p><strong>RangeAssignor 按跨度进行分配</strong></p><p>kafka会先按照分区总数和消费者总数进行整除，获得一个跨度，然后按照分区跨度进行平均分配，确保分区尽可能平均的分配给所有的消费者。对于剩余的分区（分区总数 % 消费者总数），则前面的消费者（消费者名称按字典序排序）会多分配一个分区。</p><p>假设 n=分区数/消费者数量， m=分区数%消费者数量，那么前 m 个消费者每个分配 n+1 个 分区，后面的(消费者数量～m)个消费者每个分配 n个分区。</p><p>这种分配方式存在一个问题，如果存在多个topic的分区不是消费者总数的整数倍，那么排在前面的消费者会被多分配多个分区。</p><blockquote><p>假设有两个topic，每个topic有4个分区，分配结果为：</p><p>Consumer0:  t0p0,t0p1, t1p0,t1p1</p><p>Consumer1:  t0p2,t0p3, t1p2,t1p3</p><p>但是如果有两个topic，且个topic有3个分区，分配结果为：</p><p>Consumer0:  t0p0,tp1, t1p0,t1p1</p><p>Consumer1:  t0p2,t1p2</p></blockquote></li><li><p><strong>RoundRobinAssignor 按顺序分配</strong></p><p>将消费组内所有的消费者及消费者订阅的所有topic的分区按照字典序排序，然后通过轮询的方式将分区依此分配给每个消费者。</p><p>这种分配方式如果消费组内所有的消费者订阅的topic都是相同的，那么分区会被很均匀的分配给每个消费者，但是如果消费者订阅的topic不同，就会导致分配不均匀。</p><blockquote><p>假设消费者C0订阅了主题t0；假设消费者C1订阅了主题t0和t1；假设消费者C2订阅了主题t0，t1和t2。t0、t1、t2的分区数分别为1、2、3。此时分配结果为：</p><p>C0: t0p0</p><p>C1: t1p0</p><p>C2: t1p1, t2p0,t2p1,t2p2</p><p>这种分配方式不完美，因为可以将 t1p1分配给C1。</p></blockquote></li><li><p><strong>StickyAssignor 粘性分配</strong></p><p>这是目前最优秀的分区分配策略。Kafka从0.11x开始引入这种分配策略，尽可能保证：分区分配均匀，分区分配尽可能与上一次分配相同</p><p>再分配的时候，会将需要分配的分区平均的分配给消费者。</p><blockquote><p>RoundRobinAssignor中提到的例子，使用StickyAssignor的分配结果为：</p><p>C0: t0p0</p><p>C1: t1p0, <strong>t1p1</strong></p><p>C2: t2p0,t2p1,t2p2</p><p>假设StickyAssignor当前的分区分配为：</p><p>C0: t0p0, t1p1, t3p0</p><p>C1: t0p1, t2p1, t3p1</p><p>C2: t1p0, t2p1</p><p>消费者C1脱离了消费组，则分配结果为：</p><p>C0: t0p0, t1p1, t3p0, <strong>t201</strong></p><p>C2: t1p0, t2p1, <strong>t0p1, t3p1</strong></p></blockquote></li><li><p>自定义分区分配策略</p><p>实现PartitionAssignor接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">PartitionAssignor</span> &#123;</span><br><span class="line">  <span class="comment">//提供订阅的消息</span></span><br><span class="line">  Subscription <span class="title function_">subscription</span><span class="params">(Set&lt;String&gt; topics)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//实现具体的分配逻辑</span></span><br><span class="line">  Map&lt;String, Assignment&gt; <span class="title function_">assign</span><span class="params">(Cluster metadata, Map&lt;String, Subscription&gt; subscriptions)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//执行分配的时候会调用这个方法</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onAssignment</span><span class="params">(Assignment assignment)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">default</span> <span class="keyword">void</span> <span class="title function_">onAssignment</span><span class="params">(Assignment assignment, <span class="type">int</span> generation)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.onAssignment(assignment);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//这个分配策略的名字</span></span><br><span class="line">  String <span class="title function_">name</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h1 id="幂等"><a class="markdownIt-Anchor" href="#幂等"></a> 幂等</h1><p>kafka开启幂等性功能：</p><blockquote><ol><li>将生产者的<code>enable.idempotence</code>配置为true，默认为false</li><li>生产者客户端的retries必须大于0</li><li><code>max.in.flight.requests.per.connection</code>不能大于5</li><li>acks设置为-1，即所有副本都同步完成，才给生产者返回成功</li></ol></blockquote><p>为了实现幂等性，kafka引入了producer id（PID）和sequence number的概念。kafka会为每个producer分配一个id，每个生产者发送到每个分区的每条消息都有一个序列号，每发送一条消息，&lt;PID，分区&gt;对应的序列号就会加1。</p><p>broker端会为每个&lt;PID，分区&gt;维护一个序列号：</p><blockquote><p>当收到消息时，只有序列号（SN_new）比旧的序列号（SN_old）大1时，即<code>SN_new = SN_old+1</code>，才会接受它</p><p>如果<code>SN_new &lt; SN_old</code>，则说明这是重复消息，会被丢弃</p><p>如果<code>SN_new &gt; SN_old+1</code>，则说明中间有消息没有写入，出现乱序，即有消息丢失，会抛出OutOfOrderSequenceException异常</p></blockquote><h1 id="事务"><a class="markdownIt-Anchor" href="#事务"></a> 事务</h1><p>要开启事务功能，首先必须开启生产者的幂等性功能。</p><p>通过事务，可以保证跨生产者会话的消息幂等发送和事务恢复。</p><p>需要手动的指定transactionalId，transactionalld与PID一一对应，同时通过一个单调递增的producer epoch保证transactionalld的唯一性。</p><p>Kafka 并不能保证己提交的事务中的所有消息都能够被消费 :</p><blockquote><ol><li>对采用日志压缩策略的主题而言，事务中的某些消息有可能被清理(相同 key 的消息， 后写入的消息会覆盖前面写入的消息)。</li><li>事务中消息可能分布在同一个分区的多个日志分段(LogSegment)中，当老的日志分段被删除时，对应的消息可能会丢失。</li><li>消费者可以通过 seek() 方法访问任意offset的消息，从而可能遗漏事务中的部分消息。</li><li>消费者在消费时可能没有分配到事务内的所有分区，因此它也就不能读取事务中的所有消息。</li></ol></blockquote>]]></content>
    
    
    <summary type="html">kafka客户端的一些细节。</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka-2 消费者</title>
    <link href="https://eoccc.gitee.io/2023/03/30/kafka-2%20%E6%B6%88%E8%B4%B9%E8%80%85/"/>
    <id>https://eoccc.gitee.io/2023/03/30/kafka-2%20%E6%B6%88%E8%B4%B9%E8%80%85/</id>
    <published>2023-03-30T14:52:41.000Z</published>
    <updated>2023-04-06T15:12:42.293Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka的消费者负责订阅topic，并从订阅的topic上拉取消息。kafka的消费层还有一个消费组（consumer group），每个consumer都有一个消费组，消息会发给订阅了这个topic的<strong>所有</strong>消费组，并由消费组中的<strong>一个</strong>消费者进行消费。</p><span id="more"></span><h1 id="消费者与消费组"><a class="markdownIt-Anchor" href="#消费者与消费组"></a> 消费者与消费组</h1><p>某个主题中共有4个分区(Partition)：P0、P1、P2、P3。有两个消费组A和B都订阅了这个主题，消费组A中有4个消费者(C0、C1、C2和C3)，消费组B中有2个消费者C4和C5)。按照Kafka默认的规则，最后的分配结果是消费组A中的每一个消费者分配到1个分区，消费组B中的每一个消费者分配到2个分区，两个消费组之间互不影响。每个消费者只能消费所分配到的分区中的消息。换言之，每一个分区只能被一个消费组中的一个消费者所消费。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20220803203252462.png" alt="image-20220803203252462" style="zoom:65%;"><p>如果消费者的个数大于分区的个数，则有的消费者会分配不到分区。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20220803203324669.png" alt="image-20220803203324669" style="zoom:50%;"><p>一个消费者只会属于一个消费组，消费模式可以分为点对点模式和发布订阅模式：</p><blockquote><ul><li><p>点对点模式：</p><p>所有消费者都属于同一个消费组，partition会均衡地分配给每一个消费者，从而消息会均衡地发送给消费者，每条消息只会被消费一次</p></li><li><p>发布/订阅模式（广播）：</p><p>每个消费者属于一个单独的消费组，每个消费组都订阅topic，消息会发送给所有的消费组，即一条消息会被每个消费者都消费一遍</p></li></ul></blockquote><h1 id="订阅消息"><a class="markdownIt-Anchor" href="#订阅消息"></a> 订阅消息</h1><p>Kafka一个消费者可以订阅一个或多个消息主题，支持多种订阅消息的方式。</p><ul><li><p>订阅一个或多个topic</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">subscribe</span><span class="params">(Collection&lt;String&gt; topics)</span></span><br></pre></td></tr></table></figure></li><li><p>根据正则表达式订阅主题</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">subscribe</span><span class="params">(Pattern pattern)</span></span><br></pre></td></tr></table></figure></li><li><p>订阅指定的分区</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">assign</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br></pre></td></tr></table></figure><p>TopicPartition对象中包含了topic和partation两个参数。</p></li></ul><p>如果我们需要知道某个topic的分区信息，可以通过<code>KafkaConsumer.partitionsFor(String tpoic)</code>进行查询，返回一个<code>List&lt;PartitionInfo&gt;</code>列表，PartitionInfo包含了这个topic的分区信息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Part</span>工tioninfo &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> String topic;              <span class="comment">//topic</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> partition;             <span class="comment">//分区</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Node leader;               <span class="comment">//这个分区的leader节点</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span>  Node[] replicas;          <span class="comment">//所有副本 ASR</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span>  Node[] inSyncReplicas;    <span class="comment">//同步副本 ISR</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Node[] offlineReplicas;    <span class="comment">//离线副本 OSR</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="消费消息"><a class="markdownIt-Anchor" href="#消费消息"></a> 消费消息</h1><p>Kafka采用poll的方式从服务端拉取消息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> ConsumerRecords&lt;K, V&gt; <span class="title function_">poll</span><span class="params">(<span class="keyword">final</span> Duration timeout)</span></span><br></pre></td></tr></table></figure><p>ConsumerRecords的内部包括了ConsumerRecord，用来存储一次拉取获得的消息集，提供了一个iterator来遍历消息集内部的消息。</p><p>我们可以通过下面的方法获取一个分区的消息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;ConsumerRecord&lt;K, V&gt; <span class="title function_">records</span><span class="params">(TopicPartition partition)</span></span><br></pre></td></tr></table></figure><p>ConsumerRecord中比较关键的属性：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConsumerRecord</span>&lt;K, V&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;                 <span class="comment">//主题</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> partition;                <span class="comment">//分区</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> offset;                  <span class="comment">//这个消息在分区中的偏移量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> timestamp;               <span class="comment">//时间戳</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> TimestampType timestampType;  <span class="comment">//时间戳的类型，有CreateTime和LogAppendTime两种类型</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> serializedKeySize;        <span class="comment">//key序列化器</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> serializedValueSize;      <span class="comment">//value序列化器</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers headers;              <span class="comment">//</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;                        <span class="comment">//消息的key</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> V value;                      <span class="comment">//消息的value</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Optional&lt;Integer&gt; leaderEpoch;<span class="comment">//leader的纪元</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> Long checksum;             <span class="comment">//CRC32校验值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="位移提交"><a class="markdownIt-Anchor" href="#位移提交"></a> 位移提交</h1><p>Kafka中每条消息都有唯一的offset，用来表示消息在分区中的位置。消费者也保存了一个offset，用来记录消费到分区中某个消息所在的位置。</p><p>在旧的消费者客户端中，offset是保存在zookeeper中的，而在新的消费者客户端中，是保存在kafka的内部主题__consumer_offsets中。</p><p>如果消费者当前消费到了x，需要提交的位移为x+1。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/ktk3vy8Mu.jpeg" alt="ktk3vy8Mu.jpeg"></p><p><strong>消费者提交偏移量的时机</strong></p><p>消费者提交偏移量，有可能会造成重复消费和消息丢失现象。</p><blockquote><ul><li>拉取到消息立即提交offset，如果这批消息消费的过程中出现了异常，导致部分消息没有消费，就会导致消息丢失</li><li>消息消费完再提交offset，如果这批消息消费的过程中出现了异常，消费了部分消息，但是由于没有消费完，没有提交offset，就会导致消息重复消费</li></ul></blockquote><p>kafka默认是自动提交的，即定期提交，默认是5s提交一次。<code>enable.auto.commit</code>开启自动提交，<code>auto.commit.interval.ms</code>配置提交的时间。自动提交的操作是在KafkaConsumer#poll()中完成的。消费者每隔5秒就会拉取每个分区中的最小offset进行提交，另外，每次向服务端发起拉取消息的请求的时候，都会检查是否可以提交offset，如果可以，就会提交。</p><p>自动提交存在的问题：</p><blockquote><ul><li>重复消费：消费者拉取了一批消息x+1～x+5，消费到x+3的时候，自动提交了一次offset，这一批消息消费完了，但是拉取消息的时候没有提交offset（条件不满足，还不可以自动提交），然后消费者继续消费，消费到x+7的时候，消费者崩溃了，就需要重新从x+3的offset处开始消费，就会导致重复消费。可以减小自动提交的时间窗口。</li><li>消息丢失：异步拉取消息，并发消费这种情况下会导致消息丢失。比如有一个异步线程一直在拉取消息，然后保存在本地，然后有两个线程并发的消费消息，线程A消费x+1～x+5的batch，线程B消费x+6～x+10的batch，消费者自动提交了x+8的offset，但是线程A才消费到了x+3，这是线程A发生了异常，重新消费的时候，就会从x+6的位置开始消费，x+3～x+5的消息就会丢失，而且x+6～x+10的消息会被重复消费。</li></ul></blockquote><p>kafka可以手动提交偏移量，需要将配置<code>enable.auto.commit</code>关闭，然后使用<code>commitSync()</code>方法提交offset。</p><p>一个示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (isRunning.get()) &#123;</span><br><span class="line">ConsumerRecords&lt;String, String&gt; records= consumer.poll(<span class="number">1000</span>);</span><br><span class="line">  <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line"><span class="comment">//do some logical processing .</span></span><br><span class="line">&#125;</span><br><span class="line">  consumer.commitSync();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="控制消费"><a class="markdownIt-Anchor" href="#控制消费"></a> 控制消费</h1><p>KafkaConsumer可以使用pause方法暂停消费，使用resume方法恢复消费：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">pause</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">resume</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br></pre></td></tr></table></figure><p>关闭客户端：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">(Duration timeout)</span></span><br></pre></td></tr></table></figure><h1 id="指定消费位移"><a class="markdownIt-Anchor" href="#指定消费位移"></a> 指定消费位移</h1><p>当一个新的消费组建立的时候，或订阅一个新的tpoic的时候，或当__consumer_offsets主题中关于这个消费组的偏移量消息过期后，没有可以查找的offset，这时会根据消费者的<code>auto.offset.reset</code>配置来决定从什么地方开始消费：</p><blockquote><ul><li>latest：默认值，从下一条写入的消息开始消费</li><li>earliest：从起始处开始消费</li><li>none：抛出NoOffsetForPartitionException异常</li></ul></blockquote><p>kafka还可以通过seek()方法，更细粒度的从指定的位置开始消费。seek()只能重置分配到分区的消费者的位置，所以在重置之前，还得先poll()一次。</p><p>kafka还提供了两个快速seek的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">seekToBeginning</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">seekToEnd</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br></pre></td></tr></table></figure><p>另外可以通过offsetsForTimes方法获取指定时间的offset：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Map&lt;TopicPartition, OffsetAndTimestamp&gt; <span class="title function_">offsetsForTimes</span><span class="params">(Map&lt;TopicPartition, Long&gt; timestampsToSearch)</span></span><br></pre></td></tr></table></figure><p>kafka有再均衡监听器ConsumerRebalanceListener，可以在再均衡之前和重新分配分区之后做一些操作，如在再均衡之前提交当前的offset</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ConsumerRebalanceListener</span> &#123;</span><br><span class="line">  <span class="comment">//再均衡之前调用</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; var1)</span>;</span><br><span class="line"><span class="comment">//重新分配分区之后调用</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; var1)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="消费者拦截器"><a class="markdownIt-Anchor" href="#消费者拦截器"></a> 消费者拦截器</h1><p>消费者拦截器可以在消费消息或者提交偏移量的时候做一些操作，实现ConsumerInterceptor接口即可：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ConsumerInterceptor</span>&lt;K, V&gt; <span class="keyword">extends</span> <span class="title class_">Configurable</span>, AutoCloseable &#123;</span><br><span class="line">  <span class="comment">//消费消息之前会调用这个方法</span></span><br><span class="line">  <span class="comment">//我们可以通过这个方法修改消息，或者做一些过滤等</span></span><br><span class="line">  ConsumerRecords&lt;K, V&gt; <span class="title function_">onConsume</span><span class="params">(ConsumerRecords&lt;K, V&gt; var1)</span>;</span><br><span class="line">  <span class="comment">//提交偏移量之前会调用</span></span><br><span class="line">  <span class="comment">//我们可以通过这个方法获取一些偏移量提交的细节</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onCommit</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; var1)</span>;</span><br><span class="line">  <span class="comment">//关闭的时候会调用</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;Kafka的消费者负责订阅topic，并从订阅的topic上拉取消息。kafka的消费层还有一个消费组（consumer group），每个consumer都有一个消费组，消息会发给订阅了这个topic的&lt;strong&gt;所有&lt;/strong&gt;消费组，并由消费组中的&lt;strong&gt;一个&lt;/strong&gt;消费者进行消费。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka-1 生产者</title>
    <link href="https://eoccc.gitee.io/2023/03/29/kafka-1%20%E7%94%9F%E4%BA%A7%E8%80%85/"/>
    <id>https://eoccc.gitee.io/2023/03/29/kafka-1%20%E7%94%9F%E4%BA%A7%E8%80%85/</id>
    <published>2023-03-29T14:52:41.000Z</published>
    <updated>2023-04-03T15:20:56.712Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka的生产者发送数据时，先将数据缓存到记录收集器RecordAccumulator中，再由发送线程Sender将消息批量地发送给服务端。</p><span id="more"></span><p>Kafka生产者的客户端是KafkaProducer。发送消息的入口是KafkaProducer.send，提供了同步和异步的方式，异步的方式支持回调功能：</p><blockquote><p>同步：send(ProducerRecord&lt;K, V&gt; record)</p><p>异步：send(ProducerRecord&lt;K, V&gt; record, Callback callback)</p></blockquote><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20220731211734632.png" alt="image-20220731211734632" style="zoom:45%;"><h1 id="序列化"><a class="markdownIt-Anchor" href="#序列化"></a> 序列化</h1><p>Kafka在发送消息之前，会先进行序列化，key和value可以使用不同的序列化器：</p><blockquote><ul><li>key的序列化器通过<code>key.serializer</code>配置，默认使用JsonSerializer</li><li>value的序列化器通过<code>value.serializer</code>配置，默认使用JsonSerializer</li></ul></blockquote><p>JsonSerializer底层使用的是<code>com.fasterxml.jackson.databind.ObjectMapper</code>进行序列化。</p><p>手动指定序列化方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;10.0.55.229:9092&quot;</span>);</span><br><span class="line">props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(props);</span><br></pre></td></tr></table></figure><h2 id="自定义序列化"><a class="markdownIt-Anchor" href="#自定义序列化"></a> 自定义序列化</h2><p>和内置的StringSerializer字符串序列化一样，如果要自定义序列化方式，需要实现接口<strong>Serializer</strong>。下面是一个简单的自定义实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySerializer</span> <span class="keyword">implements</span> <span class="title class_">Serializer</span>&lt;Order&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; configs, <span class="type">boolean</span> isKey)</span> &#123;</span><br><span class="line">        Serializer.<span class="built_in">super</span>.configure(configs, isKey);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">byte</span>[] serialize(String s, Order order) &#123;</span><br><span class="line">        <span class="keyword">return</span> JSON.toJSONString(order).getBytes();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">byte</span>[] serialize(String topic, Headers headers, Order data) &#123;</span><br><span class="line">        <span class="keyword">return</span> JSON.toJSONString(data).getBytes();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">        Serializer.<span class="built_in">super</span>.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="自定义反序列化"><a class="markdownIt-Anchor" href="#自定义反序列化"></a> 自定义反序列化</h2><p>和内置的StringDeserializer字符串反序列化一样，如果要自定义反序列化方式，需要实现接口<strong>Deserializer</strong>。下面是一个简单的自定义实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyDeserializer</span> <span class="keyword">implements</span> <span class="title class_">Deserializer</span>&lt;Order&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map configs, <span class="type">boolean</span> isKey)</span> &#123;</span><br><span class="line">        Deserializer.<span class="built_in">super</span>.configure(configs, isKey);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Order <span class="title function_">deserialize</span><span class="params">(String s, <span class="type">byte</span>[] bytes)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">json</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(bytes);</span><br><span class="line">        <span class="keyword">return</span> JSON.parseObject(json, Order.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Order <span class="title function_">deserialize</span><span class="params">(String topic, Headers headers, <span class="type">byte</span>[] data)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">json</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(data);</span><br><span class="line">        <span class="keyword">return</span> JSON.parseObject(json, Order.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">        Deserializer.<span class="built_in">super</span>.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="选择分区"><a class="markdownIt-Anchor" href="#选择分区"></a> 选择分区</h1><p>Kafka的消息分为有key和没有key两种，通常情况下是没有key的。针对两种情况，有不同的分区逻辑。</p><p><strong>有key的消息</strong></p><p>对于有key的消息，kafka会根据key进行散列，key相同的消息会发送到相同的分区中。</p><p><strong>没有key的消息</strong></p><p>当消息没有指定key时，如果是第一次向服务端发送消息（这个topic还没有分配过分区），则随机分配一个分区，否则采用轮询的方式分配分区。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes, Cluster cluster)</span> &#123;</span><br><span class="line">  List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">  <span class="type">int</span> <span class="variable">numPartitions</span> <span class="operator">=</span> partitions.size();</span><br><span class="line">  <span class="comment">// 没有key的时候，随机分配分区</span></span><br><span class="line">  <span class="keyword">if</span> (keyBytes == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="comment">// 选择分区</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">nextValue</span> <span class="operator">=</span> nextValue(topic);</span><br><span class="line">    List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">    <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="type">int</span> <span class="variable">part</span> <span class="operator">=</span> Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">      <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">      <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 有key的时候直接根据key的hash值进行散列</span></span><br><span class="line">    <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">    <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="title function_">nextValue</span><span class="params">(String topic)</span> &#123;</span><br><span class="line">  <span class="type">AtomicInteger</span> <span class="variable">counter</span> <span class="operator">=</span> topicCounterMap.get(topic);</span><br><span class="line">  <span class="keyword">if</span> (<span class="literal">null</span> == counter) &#123;</span><br><span class="line">    <span class="comment">// 如果这个topi是第一次推送消息，随机分配一个分区</span></span><br><span class="line">    counter = <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(ThreadLocalRandom.current().nextInt());</span><br><span class="line">    <span class="type">AtomicInteger</span> <span class="variable">currentCounter</span> <span class="operator">=</span> topicCounterMap.putIfAbsent(topic, counter);</span><br><span class="line">    <span class="keyword">if</span> (currentCounter != <span class="literal">null</span>) &#123;</span><br><span class="line">      counter = currentCounter;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 轮询分配分区</span></span><br><span class="line">  <span class="keyword">return</span> counter.getAndIncrement();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>直接指定分区</strong></p><p>Kafka支持直接指定分区，可以在创建ProducerRecord的时候，直接指定分区。ProducerRecord提供了多个指定分区的构造方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(ProducerRecord&lt;K, V&gt; record, <span class="type">byte</span>[] serializedKey, <span class="type">byte</span>[] serializedValue, Cluster cluster)</span> &#123;</span><br><span class="line">  <span class="type">Integer</span> <span class="variable">partition</span> <span class="operator">=</span> record.partition();</span><br><span class="line">  <span class="comment">// 优先使用指定的分区</span></span><br><span class="line">  <span class="keyword">return</span> partition != <span class="literal">null</span> ?</span><br><span class="line">    partition :</span><br><span class="line">  partitioner.partition(</span><br><span class="line">    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>**注意：**分配分区的时候，会过滤掉不健康的分区。</p><p>kafka节点健康的标准：</p><ol><li>存在于ISR集合中（保持正常的同步）</li><li>与zookeeper保持心跳（健康检查）</li></ol><h1 id="客户端消息收集器"><a class="markdownIt-Anchor" href="#客户端消息收集器"></a> 客户端消息收集器</h1><p>Kafka的生产者发送数据时，先将数据缓存到记录收集器RecordAccumulator中，再由发送线程Sender将消息批量地发送给服务端。</p><p>每个分区都有一个<strong>双端队列</strong>来缓存客户端的消息，队列中的每个元素是一个批记录（ProducerBatch），如果一个批记录满了，就会创建一个新的批记录，并将已经满的批记录交给sender线程发送到服务端。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RecordAccumulator.<span class="type">RecordAppendResult</span> <span class="variable">result</span> <span class="operator">=</span> accumulator.append(tp, timestamp, serializedKey,</span><br><span class="line">                    serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line"><span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">  <span class="comment">// 如果批记录满了，唤醒sender线程</span></span><br><span class="line">  <span class="built_in">this</span>.sender.wakeup();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>批记录的大小通过<code>batch.size</code>来配置，默认是16kb。如果一条消息的大小超过了16kb，会创建一个能够容纳这条消息的批记录。</p><p>另外，如果一个批记录很长时间没有满，sender线程会定时的将批记录发送给服务端，避免过长的延时。延时通过<code>linger.ms</code>来配置，默认是0ms，即有消息就会马上发送到服务端。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20220727101124764.png" alt="image-20220727101124764" style="zoom:50%;"><h1 id="客户端消息发送线程"><a class="markdownIt-Anchor" href="#客户端消息发送线程"></a> 客户端消息发送线程</h1><p>Kafka发送消息时，为了减少网络的开销，会将属于一个节点的所有partation的消息放在一个批次，同时进行发送。如果我们有两台服务器，topic有6个partation，每台服务器有3个partation，如果迭代每个partation的批记录，直接发送到主副本节点，则会有6次请求；如果把属于同一个节点的所有partation放在一起发送，就只会有2次请求。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/_REu1TGqm.jpeg" alt="_REu1TGqm.jpeg" style="zoom:80%;"><p>消息发送线程发送消息的步骤：</p><blockquote><ol><li>获取可以发送的批记录（每个批记录属于一个partation）</li><li>遍历每个批记录，获取每个批记录对应的主副本节点：nodeId</li><li>将所有的批记录以nodeId为key，group成一个map：modeId -&gt; List&lt;ProducerBatch&gt;</li><li>发送消息到每个主副本节点</li></ol></blockquote><p>客户端发送完消息后，会执行<code>KafkaClient#poll</code>方法，执行回调方法以及一些后续的处理。回调方法时保存在ClientRequest中的，为了在收到服务端返回后能够执行回调方法，发送线程会保存目标节点到客户端请求的映射关系。</p><ul><li><p>**不需要响应的流程 ：**开始发送请求→添加客户端请求到队列→发送请求→请求发送成功→从队列中删除发送请求→构造客户端响应。</p></li><li><p>**需要晌应的流程：**开始发送请求→添加客户端请求到队列→发送请求→请求发送成功→等待接收响应→接收响应→接收到完整的响应→从队列中删除客户端请求→构造客户端响应。</p></li></ul><p>整体流程：</p><blockquote><ol><li>KafkaProducer将消息存到消息收集器RecordAccumulator中</li><li>Sender从RecordAccumulator获取消息</li><li>Sender将需要发送的批记录根据目标节点进行分类</li><li>Sender创建ClientRequest</li><li>Sender调用KafkaClient.send方法发送消息（具体实现是NetworkClient）</li><li>NetworkClient调用Selector.send</li><li>Selector创建KafkaChanel，并将请求写入通道</li><li>Sender调用KafkaClient.poll方法触发KafkaChanel真正执行发送，并执行回调方法</li></ol></blockquote><h1 id="生产者拦截器"><a class="markdownIt-Anchor" href="#生产者拦截器"></a> 生产者拦截器</h1><p>生产者拦截器既可以用来在消息发送前做一些准备工作， 比如按照某个规则过滤不符合要求的消息、修改消息的内容等， 也可以用来在执行回调逻辑前做一些定制化的需求，比如统计类工作。</p><p>使用生产者拦截器，只需要实现Producerlnterceptor，然后配置<code>interceptor.classes </code>即可，包含三个方法：</p><ol><li>onSend()方法：在将消息序列化和计算分区之前会调用，对消息进行相应的定制化操作；</li><li>onAcknowledgement()方法：在消息被应答(Acknowledgement)之前或消息发送失败时调用，在callback之前。<strong>这个方法在producer的I/O线程中，所以逻辑应该尽量简单，否则会影响消息的发送。</strong></li><li>close()方法：在关闭拦截器时执行一些资源的清理工作。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ProducerInterceptor</span>&lt;K, V&gt; <span class="keyword">extends</span> <span class="title class_">Configurable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> ProducerRecord&lt;K, V&gt; <span class="title function_">onSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="重要的消费者参数"><a class="markdownIt-Anchor" href="#重要的消费者参数"></a> 重要的消费者参数</h1><ol><li><p>acks</p><blockquote><ul><li>acks=1。默认值。生产者需要收到服务端的响应才算发送消息成功。<em>如果服务端leader收到数据，但是follower还没有同步数据，此时leader副本崩溃，会丢失消息。如果发生leader选举，会返回一个错误消息。</em></li><li>acks=0。生产者发送消息之后不需要等待服务端响应。</li><li>acks=-1或acks=all。生产者发送消息之后，需要等待ISR中所有副本都成功写入消息之后，才能收到服务端的成功响应。<em>ISR中只有一个副本时，还是会丢失消息</em></li></ul></blockquote></li><li><p>max.request.size</p><blockquote><p>生产者客户端能发送消息的最大值，默认1MB。修改这个参数的时候还需要修改broker<code>message.max.bytes</code>参数，比如生产者的<code>max.request.size</code>配置成20，但是broker的<code>message.max.bytes</code>配置成10，此时发送了一个15B的消息，服务端就接收不了。</p></blockquote></li><li><p><a href="http://xn--retriesretry-4l2u.backoff.ms">retries和retry.backoff.ms</a></p><blockquote><ul><li><code>retries</code>用来配置生产者的重试次数，默认为0，即发生异常时不重试。如果重试的次数超过配置的次数，仍然失败，就会返回异常</li><li><code>retry.backoff.ms</code>用来配置两次重试之间的时间间隔，默认为100。</li></ul></blockquote><p>Kafka的同一个topic中的消息时有序的，生产者会按照发送的顺序发送给服务端，消费者也可以按照同样的顺序进行消费。如果配置了重试，而且配置的发送消息的并发数大于1（max.in.flight.requests.per.connection），此时第一批消息写入失败，而第二批消息写入成功，就会导致消息的顺序不一致。</p></li><li><p>batch.size</p><blockquote><p>生产者客户端发送消息，一个批次的大小，一个批次满了以后，就会发送到服务端。</p></blockquote></li><li><p><a href="http://linger.ms">linger.ms</a></p><blockquote><p>生产者客户端等待发送一批消息的最长时间，默认为0。即有消息就会发送到服务端。</p></blockquote></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;Kafka的生产者发送数据时，先将数据缓存到记录收集器RecordAccumulator中，再由发送线程Sender将消息批量地发送给服务端。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo远程调用将对象转成了Map</title>
    <link href="https://eoccc.gitee.io/2023/03/23/Dubbo%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E5%B0%86%E5%AF%B9%E8%B1%A1%E8%BD%AC%E6%88%90%E4%BA%86Map/"/>
    <id>https://eoccc.gitee.io/2023/03/23/Dubbo%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E5%B0%86%E5%AF%B9%E8%B1%A1%E8%BD%AC%E6%88%90%E4%BA%86Map/</id>
    <published>2023-03-23T06:10:32.000Z</published>
    <updated>2023-03-26T08:43:20.713Z</updated>
    
    <content type="html"><![CDATA[<p>Dubbo远程调用返回结果后，反序列化的时候将对象反序列化成了Map，对象的属性作为key。</p><span id="more"></span><p>事情是这样的，在一个正常的dubbo接口升级过程中，我们升级了下游系统的jar包，然后调用下游接口的时候，拿到的返回结果中，有一个对象转成了HashMap。离了大谱。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230324102621382.png" alt="image-20230324102621382"></p><p>对比了一番线上代码和本地代码，发下这个<strong>对象中多了一个字段，而且这个字段对应的类在本地代码中没有</strong>。</p><p>然后又找下游系统沟通，发现这个类其实是在另一个jar包中！也就是说这个接口的返回值中的对象来自于两个jar包，但是这两个jar包在我们系统中是分别单独引用的，而又只升级了其中的一个，所以导致新节点的对象不存在。</p><p>随后就简单了，升级另一个jar包，重新部署就解决问题了。</p><p><strong>那么</strong></p><p><font color="red"><strong>为什么少了类会导致对象反序列化成了HashMap？</strong></font></p><p>Hassian反序列化的入口是<code>Hessian2Input#readObject()</code>。</p><ol><li><code>readObject</code>执行反序列化</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Object <span class="title function_">readObject</span><span class="params">(List&lt;Class&lt;?&gt;&gt; expectedTypes)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">tag</span> <span class="operator">=</span> _offset &lt; _length ? (_buffer[_offset++] &amp; <span class="number">0xff</span>) : read();</span><br><span class="line">    <span class="keyword">switch</span> (tag) &#123;</span><br><span class="line">        ...</span><br><span class="line">      <span class="keyword">case</span> <span class="number">0x6f</span>: &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">ref</span> <span class="operator">=</span> tag - <span class="number">0x60</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (_classDefs == <span class="literal">null</span>)</span><br><span class="line">                <span class="keyword">throw</span> error(<span class="string">&quot;No classes defined at reference &#x27;&#123;0&#125;&#x27;&quot;</span> + tag);</span><br><span class="line"></span><br><span class="line">            <span class="type">ObjectDefinition</span> <span class="variable">def</span> <span class="operator">=</span> (ObjectDefinition) _classDefs.get(ref);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> readObjectInstance(<span class="literal">null</span>, def);</span><br><span class="line">        &#125;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>接着调用<code>Hessian2Input#readObjectInstance</code></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Object <span class="title function_">readObjectInstance</span><span class="params">(Class cl, ObjectDefinition def)</span></span><br><span class="line">        <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">type</span> <span class="operator">=</span> def.getType();</span><br><span class="line">    String[] fieldNames = def.getFieldNames();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cl != <span class="literal">null</span>) &#123;</span><br><span class="line">        Deserializer reader;</span><br><span class="line">        reader = findSerializerFactory().getObjectDeserializer(type, cl);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> reader.readObject(<span class="built_in">this</span>, fieldNames);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> findSerializerFactory().readObject(<span class="built_in">this</span>, type, fieldNames);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>核心代码：<code>findSerializerFactory().getObjectDeserializer(type, cl);</code></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Reads the object as a map.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> Deserializer <span class="title function_">getObjectDeserializer</span><span class="params">(String type, Class cl)</span></span><br><span class="line">        <span class="keyword">throws</span> HessianProtocolException &#123;</span><br><span class="line">    <span class="comment">// 获取反序列化具体实现</span></span><br><span class="line">    <span class="type">Deserializer</span> <span class="variable">reader</span> <span class="operator">=</span> getObjectDeserializer(type);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cl == <span class="literal">null</span></span><br><span class="line">            || cl.equals(reader.getType())</span><br><span class="line">            || cl.isAssignableFrom(reader.getType())</span><br><span class="line">            || reader.isCustom()</span><br><span class="line">            || HessianHandle.class.isAssignableFrom(reader.getType())) &#123;</span><br><span class="line">        <span class="keyword">return</span> reader;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (log.isLoggable(Level.FINE)) &#123;</span><br><span class="line">        log.fine(<span class="string">&quot;hessian: expected &#x27;&quot;</span> + cl.getName() + <span class="string">&quot;&#x27; at &#x27;&quot;</span> + type + <span class="string">&quot;&#x27; (&quot;</span></span><br><span class="line">                + reader.getType().getName() + <span class="string">&quot;)&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> getDeserializer(cl);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Reads the object as a map.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> Deserializer <span class="title function_">getObjectDeserializer</span><span class="params">(String type)</span></span><br><span class="line">        <span class="keyword">throws</span> HessianProtocolException &#123;</span><br><span class="line">    <span class="type">Deserializer</span> <span class="variable">deserializer</span> <span class="operator">=</span> getDeserializer(type);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 因为不存在类型，所以这里 deserializer 为null</span></span><br><span class="line">    <span class="keyword">if</span> (deserializer != <span class="literal">null</span>)</span><br><span class="line">        <span class="keyword">return</span> deserializer;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (_hashMapDeserializer != <span class="literal">null</span>)</span><br><span class="line">        <span class="comment">// 如果缓存中有 _hashMapDeserializer，直接返回</span></span><br><span class="line">        <span class="keyword">return</span> _hashMapDeserializer;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 否则创建一个MapDeserializer，保存在缓存中，然后返回</span></span><br><span class="line">        _hashMapDeserializer = <span class="keyword">new</span> <span class="title class_">MapDeserializer</span>(HashMap.class);</span><br><span class="line">        <span class="keyword">return</span> _hashMapDeserializer;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="4"><li>获取反序列化器</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Returns a deserializer based on a string type.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> Deserializer <span class="title function_">getDeserializer</span><span class="params">(String type)</span></span><br><span class="line">        <span class="keyword">throws</span> HessianProtocolException &#123;</span><br><span class="line">    <span class="keyword">if</span> (type == <span class="literal">null</span> || type.equals(<span class="string">&quot;&quot;</span>) || _typeNotFoundDeserializerMap.containsKey(type))</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">    Deserializer deserializer;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果之前已经获取过了，直接从缓存里面取出来返回</span></span><br><span class="line">    <span class="keyword">if</span> (_cachedTypeDeserializerMap != <span class="literal">null</span>) &#123;</span><br><span class="line">        deserializer = (Deserializer) _cachedTypeDeserializerMap.get(type);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (deserializer != <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span> deserializer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 静态类型的反序列化器</span></span><br><span class="line">    deserializer = (Deserializer) _staticTypeMap.get(type);</span><br><span class="line">    <span class="keyword">if</span> (deserializer != <span class="literal">null</span>)</span><br><span class="line">        <span class="keyword">return</span> deserializer;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 集合类型</span></span><br><span class="line">    <span class="keyword">if</span> (type.startsWith(<span class="string">&quot;[&quot;</span>)) &#123;</span><br><span class="line">        <span class="type">Deserializer</span> <span class="variable">subDeserializer</span> <span class="operator">=</span> getDeserializer(type.substring(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (subDeserializer != <span class="literal">null</span>)</span><br><span class="line">            deserializer = <span class="keyword">new</span> <span class="title class_">ArrayDeserializer</span>(subDeserializer.getType());</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            deserializer = <span class="keyword">new</span> <span class="title class_">ArrayDeserializer</span>(Object.class);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (_unrecognizedTypeCache.get(type) == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 未识别出来的类型</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 因为class不存在，这里会抛异常</span></span><br><span class="line">            <span class="type">Class</span> <span class="variable">cl</span> <span class="operator">=</span> loadSerializedClass(type);</span><br><span class="line">            deserializer = getDeserializer(cl);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// 缓存到 _unrecognizedTypeCache 中，以免一直抛异常，影响性能</span></span><br><span class="line">            log.warning(<span class="string">&quot;Hessian/Burlap: &#x27;&quot;</span> + type + <span class="string">&quot;&#x27; is an unknown class in &quot;</span> + _loader + <span class="string">&quot;:\n&quot;</span> + e);</span><br><span class="line">            _typeNotFoundDeserializerMap.put(type, PRESENT);</span><br><span class="line">            log.log(Level.FINER, e.toString(), e);</span><br><span class="line">            _unrecognizedTypeCache.put(type, <span class="keyword">new</span> <span class="title class_">AtomicLong</span>(<span class="number">1L</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 记录次数，到了2000次后重置为1</span></span><br><span class="line">        <span class="comment">// 为什么要重置为1？到最大值后就不再累加不是更好？</span></span><br><span class="line">        ((AtomicLong) _unrecognizedTypeCache.get(type)).incrementAndGet();</span><br><span class="line">        <span class="keyword">if</span> (((AtomicLong) _unrecognizedTypeCache.get(type)).get() % <span class="number">2000L</span> == <span class="number">0L</span>)</span><br><span class="line">            ((AtomicLong) _unrecognizedTypeCache.get(type)).getAndSet(<span class="number">1L</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (deserializer != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (_cachedTypeDeserializerMap == <span class="literal">null</span>)</span><br><span class="line">            _cachedTypeDeserializerMap = <span class="keyword">new</span> <span class="title class_">ConcurrentHashMap</span>(<span class="number">8</span>);</span><br><span class="line"></span><br><span class="line">        _cachedTypeDeserializerMap.put(type, deserializer);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 因为前面抛异常了，所以这里 deserializer 仍然为null</span></span><br><span class="line">    <span class="keyword">return</span> deserializer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="5"><li>经过前面的一通操作，最后获取到了MapDeserializer序列化器，就是反序列化成HashMap。<code>MapDeserializer#readObject</code>：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">readObject</span><span class="params">(AbstractHessianInput in,</span></span><br><span class="line"><span class="params">                         String[] fieldNames)</span></span><br><span class="line">        <span class="keyword">throws</span> IOException &#123;bhjl0</span><br><span class="line">    <span class="type">Map</span> <span class="variable">map</span> <span class="operator">=</span> createMap();</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> <span class="variable">ref</span> <span class="operator">=</span> in.addRef(map);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; fieldNames.length; i++) &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> fieldNames[i];</span><br><span class="line"></span><br><span class="line">        map.put(name, in.readObject());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> map;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;Dubbo远程调用返回结果后，反序列化的时候将对象反序列化成了Map，对象的属性作为key。&lt;/p&gt;</summary>
    
    
    
    
    <category term="踩坑" scheme="https://eoccc.gitee.io/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>Http、TCP和UDP</title>
    <link href="https://eoccc.gitee.io/2023/03/14/Http%E3%80%81TCP%E5%92%8CUDP/"/>
    <id>https://eoccc.gitee.io/2023/03/14/Http%E3%80%81TCP%E5%92%8CUDP/</id>
    <published>2023-03-14T07:25:43.000Z</published>
    <updated>2023-03-26T09:09:44.530Z</updated>
    
    <content type="html"><![CDATA[<p>从 Http1.1 到 Http2，Http 协议一直都是使用 TCP 作为传输协议。然而在最新的 Http3把 TCP 抛弃了，而是基于 UDP 协议的基础上，在应用层实现了一个可靠的传输协议 —— QUIC。</p><span id="more"></span><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319173208876.png" alt="640-20230319173208876.png" style="zoom:80%;"><h1 id="tcp的特点"><a class="markdownIt-Anchor" href="#tcp的特点"></a> TCP的特点</h1><h2 id="超时重传"><a class="markdownIt-Anchor" href="#超时重传"></a> 超时重传</h2><p>TCP协议是一种面向连接的可靠的传输层协议，它保证数据可靠传输的基本原理是在发送一个数据之后，就开启一个定时器，若是在这个时间内没有收到刚才发送数据的ACK确认报文（是通过确认序号的方式进行确认，即刚才发送数据的序列号+1），则对该报文进行重传。如果一直失败，满一定次数后就会放弃并发送一个复位信号。</p><h2 id="按序接收"><a class="markdownIt-Anchor" href="#按序接收"></a> 按序接收</h2><p>TCP协议是一种面向连接的可靠的传输层协议，它保证数据可靠传输的基本原理是在发送一个数据之后，就开启一个定时器，若是在这个时间内没有收到刚才发送数据的ACK确认报文（是通过确认序号的方式进行确认，即刚才发送数据的序列号+1），则对该报文进行重传。如果一直失败，满一定次数后就会放弃并发送一个复位信号。</p><ol><li>为了保证数据包的可靠传递，发送方必须把已发送的数据包保留在缓冲区；</li><li>并为每个已发送的数据包启动一个超时定时器；</li><li>如在定时器超时之前收到了对方发来的应答信息（可能是对本包的应答，也可以是对本包后续包的应答），则释放该数据包占用的缓冲区;</li><li>否则，重传该数据包，直到收到应答或重传次数超过规定的最大次数为止。</li><li>接收方收到数据包后，先进行CRC校验，如果正确则把数据交给上层协议，然后给发送方发送一个累计应答包，表明该数据已收到，如果接收方正好也有数据要发给发送方，应答包也可方在数据包中捎带过去。</li></ol><h2 id="流量控制"><a class="markdownIt-Anchor" href="#流量控制"></a> 流量控制</h2><p>如果发送者发送数据过快，接收者来不及接收，那么就会有分组丢失。为了避免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。</p><p>流量控制由滑动窗口协议（连续ARQ协议）实现。滑动窗口协议既保证了分组无差错、有序接收，也实现了流量控制。主要的方式就是接收方返回的 ACK 中会包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。</p><h3 id="流量控制引发死锁"><a class="markdownIt-Anchor" href="#流量控制引发死锁"></a> 流量控制引发死锁</h3><p>当发送者收到了一个窗口为0的应答，发送者便停止发送，等待接收者的下一个应答。但是如果这个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁。<br>为了避免流量控制引发死锁，TCP使用了持续计时器。每当发送者收到一个0窗口的ack后就启动该计时器。时间一到便主动发送报文询问接收者的窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生。</p><h2 id="拥塞控制"><a class="markdownIt-Anchor" href="#拥塞控制"></a> 拥塞控制</h2><p>拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况；常用的方法就是：慢开始，拥塞避免，快重传，快恢复。</p><h3 id="慢开始算法"><a class="markdownIt-Anchor" href="#慢开始算法"></a> 慢开始算法</h3><p>慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口cwnd（congestion window）的大小。</p><p>一个传输轮次所经历的时间其实就是往返时间RTT，而且每经过一个传输轮次（transmission round），拥塞窗口cwnd就加倍。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230320010432039.png" alt="image-20230320010432039" style="zoom:46%;"><p>为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量。ssthresh的用法如下：</p><ol><li>当cwnd &lt; ssthresh时，使用慢开始算法</li><li>当cwnd = ssthresh时，慢开始与拥塞避免算法任意</li><li>当cwnd &gt; ssthresh时，改用拥塞避免算法</li></ol><h3 id="拥塞避免算法"><a class="markdownIt-Anchor" href="#拥塞避免算法"></a> 拥塞避免算法</h3><p>拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。</p><p>无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理）：</p><ol><li>把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半（但不能小于2）</li><li>把拥塞窗口cwnd重新设置为1，执行慢开始算法</li></ol><p>这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230320011037345.png" alt="image-20230320011037345" style="zoom:50%;"><blockquote><ol><li>拥塞窗口cwnd初始化为1个报文段，慢开始门限初始值为16</li><li>执行慢开始算法，指数规律增长到第4轮，即cwnd=16=ssthresh，改为执行拥塞避免算法，拥塞窗口按线性规律增长</li><li>假定cwnd=24时，网络出现超时（拥塞），则更新后的ssthresh=12，cwnd重新设置为1，并执行慢开始算法</li><li>当cwnd=12=ssthresh时，改为执行拥塞避免算法</li></ol></blockquote><h3 id="快重传算法"><a class="markdownIt-Anchor" href="#快重传算法"></a> 快重传算法</h3><p>快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方，可提高网络吞吐量约20%）。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230320011420526.png" alt="image-20230320011420526" style="zoom: 50%;"><h3 id="快恢复算法"><a class="markdownIt-Anchor" href="#快恢复算法"></a> 快恢复算法</h3><p>当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞）。但是接下去并不执行慢开始算法（如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞）。</p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20230320011607939.png" alt="image-20230320011607939" style="zoom:50%;"><h1 id="tcp-存在队头阻塞问题"><a class="markdownIt-Anchor" href="#tcp-存在队头阻塞问题"></a> TCP 存在队头阻塞问题</h1><p>TCP 队头阻塞的问题要从两个角度看，一个是<strong>发送窗口的队头阻塞</strong>，另外一个是<strong>接收窗口的队头阻塞</strong>。</p><h2 id="发送窗口的队头阻塞"><a class="markdownIt-Anchor" href="#发送窗口的队头阻塞"></a> 发送窗口的队头阻塞</h2><p>TCP 发送出去的数据，都是需要按序确认的，只有在数据都被按顺序确认完后，发送窗口才会往前滑动。举个例子，比如下图的发送方把发送窗口内的数据全部都发出去了，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据的。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640.png" alt="640.png"></p><p>接着，当发送方收到对第 32~36 字节的 ACK 确认应答后，则<strong>滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认</strong>，接下来第 52~56 字节又变成了可用窗口，那么后续也就可以发送 52~56 这 5 个字节的数据了。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319173701699.png" alt="640-20230319173701699.png"></p><p><strong>但是如果某个数据报文丢失或者其对应的 ACK 报文在网络中丢失，会导致发送方无法移动发送窗口，这时就无法再发送新的数据</strong>，只能超时重传这个数据报文，直到收到这个重传报文的 ACK，发送窗口才会移动，继续后面的发送行为。</p><p>举个例子，比如下图，客户端是发送方，服务器是接收方。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319173855342.png" alt="640-20230319173855342.png"></p><p>客户端发送了第 5～9 字节的数据，但是第 5 字节的 ACK 确认报文在网络中丢失了，那么即使客户端收到第 6～9 字节的 ACK 确认报文，发送窗口也不会往前移动。</p><p><strong>此时的第 5 字节相当于“队头”，因为没有收到“队头”的 ACK 确认报文，导致发送窗口无法往前移动，此时发送方就无法继续发送后面的数据，相当于按下了发送行为的暂停键，这就是发送窗口的队头阻塞问题</strong>。</p><h2 id="接收窗口的队头阻塞"><a class="markdownIt-Anchor" href="#接收窗口的队头阻塞"></a> 接收窗口的队头阻塞</h2><p>接收方收到的数据范围必须在接收窗口范围内，如果收到超过接收窗口范围的数据，就会丢弃该数据，比如下图接收窗口的范围是 32 ～ 51 字节，如果收到第 52 字节以上数据都会被丢弃。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319174054907.png" alt="640-20230319174054907.png"></p><p>当接收窗口收到有序数据时，接收窗口才能往前滑动，然后那些已经接收并且被确认的「有序」数据就可以被应用层读取。</p><p>但是，<strong>当接收窗口收到的数据不是有序的，比如收到第 33～40 字节的数据，由于第 32 字节数据没有收到， 接收窗口无法向前滑动，那么即使先收到第 33～40 字节的数据，这些数据也无法被应用层读取的</strong>。只有当发送方重传了第 32 字节数据并且被接收方收到后，接收窗口才会往前滑动，然后应用层才能从内核读取第 32～40 字节的数据。</p><h2 id="http2的队头阻塞"><a class="markdownIt-Anchor" href="#http2的队头阻塞"></a> Http2的队头阻塞</h2><p>Http2 通过抽象出 Stream 的概念，实现了 Http 并发传输，一个 Stream 就代表 Http1.1 里的请求和响应。不同 Stream 的帧可以乱序发送（因此可以并发不同的 Stream ），因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 Http 消息，而同一 Stream 内部的帧必须是严格有序的。</p><p><strong>但是 Http2 多个 Stream 请求都是在一条 TCP 连接上传输，这意味着多个 Stream 共用同一个 TCP 滑动窗口，那么当发生数据丢失，滑动窗口是无法往前移动的，此时就会阻塞住所有的 Http 请求，这属于 TCP 层队头阻塞</strong>。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319223934662.png" alt="640-20230319223934662.png"></p><h1 id="http3-quic"><a class="markdownIt-Anchor" href="#http3-quic"></a> Http3 QUIC</h1><h2 id="没有队头阻塞的-quic"><a class="markdownIt-Anchor" href="#没有队头阻塞的-quic"></a> 没有队头阻塞的 QUIC</h2><p>QUIC 也借鉴 HTTP/2 里的 Stream 的概念，在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (Stream)。但是<strong>QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口</strong>。</p><p>假如 Stream2 丢了一个 UDP 包，也只会影响 Stream2 的处理，不会影响其他 Stream。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319224200820.png" alt="640-20230319224200820.png"></p><h2 id="减少建立连接延迟"><a class="markdownIt-Anchor" href="#减少建立连接延迟"></a> 减少建立连接延迟</h2><p>对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，<strong>先 TCP 握手（1RTT），再 TLS 握手（2RTT）</strong>，所以需要 3RTT 的延迟才能传输数据，就算 Session 会话复用，也需要至少 2 个 RTT，这在一定程序上增加了数据传输的延迟。</p><p><em>RTT(Round-Trip Time)：表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认，不包含数据传输时间）总共经历的时间。</em></p><p><strong>HTTP/3首次建立连接的步骤：</strong></p><blockquote><ol><li><p>第一次握手：客户端向服务器发送一个Initial Packet，该数据包包含以下信息：</p><ul><li>目标服务器的IP地址和端口号</li><li>客户端的Connection ID</li><li>客户端的TLS证书</li></ul><p>服务器收到Initial Packet后，发送一个Response Packet，该数据包包含以下信息：</p><ul><li>服务器的Connection ID</li><li>服务器的TLS证书</li></ul></li><li><p>第二次握手：客户端向服务器发送一个0-RTT Packet，该数据包包含客户端的请求信息。由于客户端发送了0-RTT数据包，因此在第二次握手中，服务器不需要等待客户端发送请求数据。</p><p>服务器收到0-RTT Packet后，发送一个Handshake Packet，该数据包包含以下信息：</p><ul><li>服务器的Connection ID</li><li>ACK确认客户端的Connection ID</li><li>传输参数，例如初始拥塞窗口大小和最大数据包大小等</li></ul></li><li><p>连接建立完成：客户端收到服务器发送的Handshake Packet后，连接建立完成，客户端可以开始发送请求数据。</p></li></ol></blockquote><p>在重新连接的时候，HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</p><p>HTTP/3 的 QUIC 协议并不是与 TLS 分层（因为 QUIC 也是应用层实现的协议），所以可以<strong>将 QUIC 和 TLS 协议握手的过程合并在一起</strong>，QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/640-20230319231040877.png" alt="640-20230319231040877.png"></p><h3 id="0-rtt-重放攻击"><a class="markdownIt-Anchor" href="#0-rtt-重放攻击"></a> 0-RTT 重放攻击</h3><p><strong>什么是重放攻击</strong></p><p>重放攻击（Replay Attack）是指攻击者在通信过程中截获了合法的通信报文，将其保存下来，并在稍后的某个时间重放这些报文，以达到欺骗或攻击的目的。重放攻击通常用于绕过身份验证或者欺骗服务器接受恶意请求，从而造成安全问题。</p><p>为了防止重放攻击，常用的方法是在通信过程中添加<strong>时间戳</strong>或者<strong>随机数</strong>等非重复性的因素，并对每个通信报文进行唯一性标识，以确保每个报文只能被使用一次。同时，还可以使用<strong>数字签名</strong>等技术对通信报文进行验证和加密，从而确保数据的完整性和安全性。</p><p><strong>HTTP/3解决0-RTT导致的重放攻击方式：</strong></p><p>为了解决这个问题，HTTP/3采用了“0-RTT数据包使用0-RTT密钥”的机制，即客户端和服务器在0-RTT数据传输期间使用不同的密钥进行加密和解密。客户端在发送0-RTT数据包时使用之前的会话密钥，而服务器只有在验证了该密钥的有效性后才会使用新生成的密钥。这样可以确保0-RTT数据包的安全性，但也会增加一些复杂性和延迟。因此，在使用0-RTT技术时，需要权衡安全性和性能之间的关系，谨慎决策。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;从 Http1.1 到 Http2，Http 协议一直都是使用 TCP 作为传输协议。然而在最新的 Http3把 TCP 抛弃了，而是基于 UDP 协议的基础上，在应用层实现了一个可靠的传输协议 —— QUIC。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>JVM虚拟机-ZGC</title>
    <link href="https://eoccc.gitee.io/2022/12/08/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA-ZGC/"/>
    <id>https://eoccc.gitee.io/2022/12/08/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA-ZGC/</id>
    <published>2022-12-08T07:25:43.000Z</published>
    <updated>2023-02-07T03:49:44.798Z</updated>
    
    <content type="html"><![CDATA[<p>ZGC(Z Garbage Collector)是一款在JDK 11中新加入的具有实验性质的低延迟垃圾收集器。</p><span id="more"></span><p>ZGC希望在尽可能对吞吐量影响不太大的前提下，实现在任意堆内存大小下都可以把垃圾收集的停顿时间限制在10ms以内的低延迟。</p><p>ZGC基于Region内存布局，(暂时) 不设分代，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-整理算法。</p><h1 id="内存布局"><a class="markdownIt-Anchor" href="#内存布局"></a> 内存布局</h1><p>ZGC采用基于Region的堆内存布局，ZGC的Region具有动态性——动态创建和销毁，以及动态的区域容量大小。在x64硬件平台下，ZGC的Region可以具有如图3-19所示的大、中、小三类容量：</p><ul><li>小型Region：容量为2MB，用于放置小于256KB的小对象</li><li>中型Region：容量为32MB，用于放置大于等于256KB，小于4MB的对象</li><li>大型Region：容量不固定，可以动态变化，但必须为2MB的整数倍。用于放置大于4MB的大对象。大型Region不会被重分配。</li></ul><h1 id="染色指针"><a class="markdownIt-Anchor" href="#染色指针"></a> 染色指针</h1><p>ZGC收集器有一个标志性的设计是它采用的染色指针技术(Colored Pointer)，直接将少量额外的信息存储在指针上。</p><p>Linux下64位指针的高18位不能用来寻址，但剩余的46位指针所能支持的64T B内存在今天仍然能够充分满足大型服务器的需要。鉴于此，ZGC的染色指针技术继续盯上了这剩下的46位指针宽度，将其高4位提取出来存储四个标志信息。通过这些标志位，虚拟机可以直接从指针中看到其引用对 象的三色标记状态、是否进入了重分配集(即被移动过)、是否只能通过finaliz e()方法才能被访问 到，如图3-20所示。当然，由于这些标志位进一步压缩了原本就只有46位的地址空间，也直接导致ZGC能够管理的内存不可以超过4TB(2的42次幂)。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20221211183456746.png" alt="image-20221211183456746"></p><p>虽然染色指针有4TB的内存限制，不能支持32位平台，不能支持压缩指针(-XX:+UseCompressedOops)等诸多约束，但它带来的收益也是非常可观的：</p><ol><li>一旦某个Region的存活对象被移走以后，这个region可以立即被释放掉，而不必等整个堆中所有指向该Region的引用都被修正后才能清理。（好处：ZGC只要有一个空闲的Region，就能够完成收集。）</li><li>可以减少在垃圾收集过程中内存屏障的使用，提高性能。设置内存屏障，尤其是写屏障的目的通常是为了记录对象引用的变动情况，如果将这些信息直接维护在指针中，显然就可以省去一些 专门的记录操作。（实际上，到目前为止ZGC都并未使用任何写屏障，只使用了读屏障。）</li><li>染色指针可以作为一种可扩展的存储结构用来记录更多与对象标记、重定位过程相关的数据，以便日后进一步提高性能。比如可以开发Linux下的64位指针中剩余的18位，用来记录一些其他信息。</li></ol><h1 id="垃圾回收"><a class="markdownIt-Anchor" href="#垃圾回收"></a> 垃圾回收</h1><p>ZGC的垃圾回收过程大致可划分为四个大的阶段。全部四个阶段都是可以并发执行的，仅是两个阶段中间会存在短暂的停顿小阶段。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20221211202804016.png" alt="image-20221211202804016"></p><ol><li><p>并发标记</p><p>遍历对象图做可达性分析，类似于G1，也会经过初始标记、最终标记的短暂STW，但是ZGC的标记是在指针上完成的，而不是在对象上。</p></li><li><p>并发预备重分配</p><p>根据特定的查询条件统计出本次收集过程要清理哪些region，这些region组成重分配集（Relocation Set），注意，ZGC每次回收都会扫描所有的region，用更大范围的扫描成本替换G1中的记忆集的维护成本。重分配集里面的对象会被复制到其他region中，里面的region会被释放。</p></li><li><p>并发重分配</p><p>把重分配集中的存活对象复制到新的region上，并为重分配集中的每个region维护一个转发表，记录从旧对象到新对象的转向关系。</p><p>ZGC根据染色指针就能知道一个对象是否处于重分配集中，当访问这个对象的时候，会被读内存屏障捕获，然后根据转发表将访问转发到新的对象上，同时更新引用的值（ZGC将这一过程称为“自愈”，类似于redis的rehash过程）。</p></li><li><p>并发重映射</p><p>修正重分配集中存活对象的引用，但是这个阶段ZGC并没有主动去完成，而是放在了下一次GC的并发标记阶段，反正并发标记的时候要遍历堆的所有对象。</p></li></ol><h1 id="zgc的缺点"><a class="markdownIt-Anchor" href="#zgc的缺点"></a> ZGC的缺点</h1><ol><li><p>没有分代</p><p>ZGC没有引入分代，每次回收都需要扫描整个堆的所有对象。</p></li><li><p>浮动垃圾</p><p>ZGC每次都会对整个堆进行回收，回收垃圾的整个过程耗时较长，并发标记的时候会产生浮动垃圾，如果系统持续高速的产生浮动垃圾的话，回收到的内存空间持续小于回收期间产生的浮动垃圾占用的空间，就会导致堆可用的空间越来越小，最终OOM。目前唯一的办法就是增加堆的容量，让ZGC获得更多的喘息空间。</p><p>要根本解决这个问题，还是得引入分代，让新对象在一个专门的区域中创建，然后对这块区域进行频率更高、更快的收集。</p></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;ZGC(Z Garbage Collector)是一款在JDK 11中新加入的具有实验性质的低延迟垃圾收集器。&lt;/p&gt;</summary>
    
    
    
    
    <category term="JVM" scheme="https://eoccc.gitee.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>JVM虚拟机-G1</title>
    <link href="https://eoccc.gitee.io/2022/12/04/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA-G1/"/>
    <id>https://eoccc.gitee.io/2022/12/04/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA-G1/</id>
    <published>2022-12-04T07:25:43.000Z</published>
    <updated>2023-04-19T06:48:05.014Z</updated>
    
    
    
    
    
    <category term="JVM" scheme="https://eoccc.gitee.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>JVM虚拟机-jdk工具</title>
    <link href="https://eoccc.gitee.io/2022/12/04/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA-jdk%E5%B7%A5%E5%85%B7/"/>
    <id>https://eoccc.gitee.io/2022/12/04/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA-jdk%E5%B7%A5%E5%85%B7/</id>
    <published>2022-12-04T07:25:43.000Z</published>
    <updated>2023-03-10T09:49:12.146Z</updated>
    
    <content type="html"><![CDATA[<p>JDK自带了很多小工具，打包、部署、签名、调试、监控、运维等 各种场景都可能会用到它们。</p><span id="more"></span><h1 id="jps虚拟机进程状态"><a class="markdownIt-Anchor" href="#jps虚拟机进程状态"></a> jps：虚拟机进程状态</h1><p>jps类似于linux的ps命令，可以列出正在运行的虚拟机进程，显示主类的名称及该进程的id。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps [options] [hostid]</span><br></pre></td></tr></table></figure><p>列出java进程：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">jps -l</span></span><br><span class="line">22407 org.jetbrains.jps.cmdline.Launcher</span><br><span class="line">22408 com.intellij.rt.junit.JUnitStarter</span><br><span class="line">22415 jdk.jcmd/sun.tools.jps.Jps</span><br></pre></td></tr></table></figure><p>jps还可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态，hostid的定义：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;hostid&gt;:      &lt;hostname&gt;[:&lt;port&gt;]</span><br></pre></td></tr></table></figure><p>jps可选参数：</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>-q</td><td>只列出进程id</td></tr><tr><td>-m</td><td>输出虚拟机进程启动时传给主类main函数的参数</td></tr><tr><td>-l</td><td>输出主类的全名，如果进程执行的是jar包，则数据jar的路径</td></tr><tr><td>-v</td><td>输出jvm虚拟机的执行参数</td></tr></tbody></table><h1 id="jstat虚拟机统计信息监视工具"><a class="markdownIt-Anchor" href="#jstat虚拟机统计信息监视工具"></a> jstat：虚拟机统计信息监视工具</h1><p>Jstat可以显示本地或者远程虚拟机进程中的类加载、内存、垃圾收集、即时编译等运行时数据。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstat [ option vmid [interval[s|ms] [count]] ]</span><br></pre></td></tr></table></figure><p>vmid：对于本地虚拟机进程，填LVMID就可以；对于远程虚拟机，格式为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[protocol:][//]lvmid[@hostname[:port]/servername]</span><br></pre></td></tr></table></figure><p>参数int erval和count 代表查询间隔和次数，如果省略这2个参数，说明只查询一次。假设需要每250 毫秒查询一次进程2764垃圾收集状况，一共查询20次，那命令应当是:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstat -gc 2764 250 20</span><br></pre></td></tr></table></figure><p>选项option代表用户希望查询的虚拟机信息，主要分为三类：类加载、垃圾收集、运行期编译状况。</p><p><img src="/.io//image-20221213102254091.png" alt="image-20221213102254091"></p><h1 id="jinfo-java配置信息工具"><a class="markdownIt-Anchor" href="#jinfo-java配置信息工具"></a> jinfo: Java配置信息工具</h1><p>实时查看和调整虚拟机各项参数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jinfo [ option ] pid</span><br></pre></td></tr></table></figure><p>jinfo还可以使用-sysprops选项把虚拟机 进程的System.getProperties()的内容打印出来。</p><p>jinfo还可以在运行期 修改部分参数值。</p><h1 id="jmap-java内存映像工具"><a class="markdownIt-Anchor" href="#jmap-java内存映像工具"></a> jmap: Java内存映像工具</h1><p>生成堆转储快照(一般称为heapdump或dump文件)。可以查询finaliz e执行队列、Java堆和方法区的 详细信息，如空间使用率、当前用的是哪种收集器等。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap [ option ] vmid</span><br></pre></td></tr></table></figure><p>如果不使用jmap 命令，要想获取Java堆转储快照可以使用-XX:+HeapDumpOnOutOfMemoryError参数，让虚拟机在内存溢出异常出现之后自动生成堆转储快照文件，或者使用-XX:+HeapDumpOnCtrlBreak参数，然后使用kill -3让虚拟机生成堆转储快照。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20221213192925832.png" alt="image-20221213192925832"></p><h1 id="jhat-虚拟机堆转储快照分析工具"><a class="markdownIt-Anchor" href="#jhat-虚拟机堆转储快照分析工具"></a> jhat: 虚拟机堆转储快照分析工具</h1><p>与jmap搭配使用，来分析jmap生成的堆转储快照。内置了一个微型的HTTP/Web服务器，可以通过<a href="http://localhost:7000/%E6%9F%A5%E7%9C%8B%E5%88%86%E6%9E%90%E7%BB%93%E6%9E%9C%E3%80%82">http://localhost:7000/查看分析结果。</a></p><p>jhat的分析功能相对来说比较简陋，可以使用其他的分析工具如VisualVM，以及专业用于分析堆转储快照文件的EclipseMemoryAnalyzer、IBMHeapAnalyzer等工具。</p><h1 id="jstack-java堆栈跟踪工具"><a class="markdownIt-Anchor" href="#jstack-java堆栈跟踪工具"></a> jstack: Java堆栈跟踪工具</h1><p>用于生成虚拟机当前时刻的线程快照(一般称为threaddump或者 javacore文件)。通常可以用于定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间挂起等，都是导致线程长时间停顿的常见原因。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstack [ option ] vmid</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20221213193724742.png" alt="image-20221213193724742"></p><h1 id="jdk日志参数"><a class="markdownIt-Anchor" href="#jdk日志参数"></a> JDK日志参数</h1><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/image-20221213100624431.png" alt="image-20221213100624431"></p><p><img src="/.io//image-20221213100659078.png" alt="image-20221213100659078"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;JDK自带了很多小工具，打包、部署、签名、调试、监控、运维等 各种场景都可能会用到它们。&lt;/p&gt;</summary>
    
    
    
    
    <category term="JVM" scheme="https://eoccc.gitee.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>Mysql知识整理</title>
    <link href="https://eoccc.gitee.io/2022/11/02/Mysql%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"/>
    <id>https://eoccc.gitee.io/2022/11/02/Mysql%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</id>
    <published>2022-11-02T07:25:19.000Z</published>
    <updated>2023-07-02T08:15:12.025Z</updated>
    
    <content type="html"><![CDATA[<p>整理一些mysql的知识。</p><span id="more"></span><h1 id="mysql"><a class="markdownIt-Anchor" href="#mysql"></a> Mysql</h1><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/g7_US3L4q.jpeg" alt="g7_US3L4q.jpeg"></p><h2 id="不常用sql语法"><a class="markdownIt-Anchor" href="#不常用sql语法"></a> 不常用sql语法</h2><h3 id="创建数据库"><a class="markdownIt-Anchor" href="#创建数据库"></a> 创建数据库</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database name;</span><br></pre></td></tr></table></figure><h3 id="创建table"><a class="markdownIt-Anchor" href="#创建table"></a> 创建table</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> name (</span><br><span class="line"># 字段</span><br><span class="line">)engine<span class="operator">=</span>Innodb <span class="keyword">default</span> charset<span class="operator">=</span>utf8;</span><br></pre></td></tr></table></figure><h3 id="更改table名"><a class="markdownIt-Anchor" href="#更改table名"></a> 更改table名</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> name rename <span class="keyword">to</span> newName;</span><br></pre></td></tr></table></figure><h3 id="更改字段类型"><a class="markdownIt-Anchor" href="#更改字段类型"></a> 更改字段类型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> tableName modify columName newType <span class="keyword">not</span> <span class="keyword">null</span>;</span><br></pre></td></tr></table></figure><h3 id="更改字段名称及类型"><a class="markdownIt-Anchor" href="#更改字段名称及类型"></a> 更改字段名称及类型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> tableName change columName newName newType <span class="keyword">not</span> <span class="keyword">null</span>;</span><br></pre></td></tr></table></figure><h3 id="创建用户"><a class="markdownIt-Anchor" href="#创建用户"></a> 创建用户</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">user</span> <span class="string">&#x27;demo&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> identified <span class="keyword">by</span> <span class="string">&#x27;demo&#x27;</span>;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> users.<span class="operator">*</span> <span class="keyword">to</span> <span class="string">&#x27;demo&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span>;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><h3 id="drop-delete与truncate"><a class="markdownIt-Anchor" href="#drop-delete与truncate"></a> drop、delete与truncate</h3><table><thead><tr><th></th><th>delete</th><th>truncate</th><th>drop</th></tr></thead><tbody><tr><td>回滚</td><td>可回滚</td><td>不可回滚</td><td>不可回滚</td></tr><tr><td>删除内容</td><td>保留表结构，删除一条或多条记录</td><td>保留表结构，删除所有记录</td><td>从数据库中删除表，删除所有的记录、索引、权限</td></tr><tr><td>删除速度</td><td>删除速度慢，需要逐行删除</td><td>删除速度快</td><td>删除速度最快</td></tr></tbody></table><h2 id="索引"><a class="markdownIt-Anchor" href="#索引"></a> 索引</h2><h3 id="什么是索引"><a class="markdownIt-Anchor" href="#什么是索引"></a> 什么是索引</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">索引是一种特殊的文件，包含对数据表里所有记录的引用指针；</span><br><span class="line">索引是一种数据结构，通常使用B树或B+树实现，用来协助快速地查询、更新数据库；</span><br><span class="line">通俗的说，索引就是为了快速的查询和更新数据库而建立的一种目录，存储于文件中，需要占用物理空间。</span><br></pre></td></tr></table></figure><h3 id="索引的优缺点"><a class="markdownIt-Anchor" href="#索引的优缺点"></a> 索引的优缺点</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">优点：</span><br><span class="line"><span class="bullet">  1.</span> 可以加快检索数据的速度</span><br><span class="line"><span class="bullet">  2.</span> 可以加速表与表之间的连接</span><br><span class="line"><span class="bullet">  3.</span> 提升排序和分组的性能</span><br><span class="line"><span class="bullet">  4.</span> 查询过程中，通过索引使用优化隐藏器，提升系统性能</span><br><span class="line"><span class="bullet">  6.</span> 通过创建唯一索引，保证数据的唯一性</span><br><span class="line">缺点：</span><br><span class="line"><span class="bullet">  1.</span> 创建和维护索引都需要时间，耗费的时间随数据量增加而增加</span><br><span class="line"><span class="bullet">  2.</span> 插入、修改和删除数据都需要维护索引，会降低数据库的更新速度</span><br><span class="line"><span class="bullet">  3.</span> 索引需要占用物理空间，随数据量的增加而增加</span><br></pre></td></tr></table></figure><h3 id="有哪些索引"><a class="markdownIt-Anchor" href="#有哪些索引"></a> 有哪些索引</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="strong">**主键索引**</span>不允许重复，不允许null值，一个表只能有一个主键索引</span><br><span class="line"><span class="strong">**唯一索引**</span> 与单列索引类似，但是<span class="strong">**索引列的值必须唯一，允许出现一个null值**</span></span><br><span class="line"><span class="strong">**普通索引（单列索引）**</span> 是最基本的索引，没有任何限制。</span><br><span class="line"><span class="strong">**组合索引**</span> 在多个字段上创建的索引。遵守最左前缀原则，即<span class="strong">**在查询语句中用到复合索引的第一个字段，索引才会被使用**</span></span><br><span class="line"><span class="strong">**全文索引**</span> 与其他索引不一样，更像是一个搜索引擎，主要用来查找文本中的关键字，而不是直接与索引中的值进行比较</span><br></pre></td></tr></table></figure><h3 id="非聚簇索引一定会回表查询吗"><a class="markdownIt-Anchor" href="#非聚簇索引一定会回表查询吗"></a> 非聚簇索引一定会回表查询吗</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">不一定，当查询语句需要查询的字段全部命中索引，就不需要回表查询。</span><br></pre></td></tr></table></figure><h3 id="索引失效的情况"><a class="markdownIt-Anchor" href="#索引失效的情况"></a> 索引失效的情况？</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1. 复合索引遵守“最左前缀”原则，即在查询条件中使用了复合索引的第一个字段，索引才会被使用</span><br><span class="line">2. 对索引字段进行计算（包括隐式转换）</span><br><span class="line">3. 使用like，like查询是以%开头</span><br><span class="line">4. 在where后使用or，导致索引失效（如果or两侧都有索引，不会失效）</span><br><span class="line">5. 使用 &gt; 进行范围查询（但是使用 &gt;= 的时，当存在端点值时不会导致索引失效）</span><br><span class="line">6. 当扫描比使用索引快时，不使用索引（is 或 is not问题）</span><br></pre></td></tr></table></figure><h3 id="sql提示"><a class="markdownIt-Anchor" href="#sql提示"></a> sql提示</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">我们可以向mysql建议或者指定使用某一个索引</span><br><span class="line"><span class="bullet">1.</span> 建议使用某一个索引</span><br><span class="line"><span class="code">``` sql</span></span><br><span class="line"><span class="code">select * from table_name use index(index_name);</span></span><br><span class="line"><span class="code">```</span></span><br><span class="line"><span class="bullet">2.</span> 建议不使用某一个索引</span><br><span class="line"><span class="code">``` sql</span></span><br><span class="line"><span class="code">select * from table_name ignore index(index_name);</span></span><br><span class="line"><span class="code">```</span></span><br><span class="line"><span class="bullet">3.</span> 强制使用某一个索引</span><br><span class="line"><span class="code">``` sql</span></span><br><span class="line"><span class="code">select * from table_name force index(index_name);</span></span><br><span class="line"><span class="code">```</span></span><br></pre></td></tr></table></figure><h3 id="设计索引的原则"><a class="markdownIt-Anchor" href="#设计索引的原则"></a> 设计索引的原则</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.最左匹配原则</span><br><span class="line">2.对频繁的查询条件字段加索引</span><br><span class="line">3.更新频繁的字段不要加索引</span><br><span class="line">4.对区分度高的字段加索引</span><br><span class="line">5.尽量拓展索引，而不是新增索引。如已经有a索引，要加(a,b)索引，应该修改a索引</span><br><span class="line">6.定义有外键的数据一定要加索引</span><br><span class="line">7.使用短索引，如果要对长字符串加索引，尽量限制前缀长度</span><br><span class="line">8.不要过度加索引</span><br><span class="line">9.不要对text、image和bit加索引</span><br></pre></td></tr></table></figure><h3 id="最左前缀原则"><a class="markdownIt-Anchor" href="#最左前缀原则"></a> 最左前缀原则</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.顾名思义，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。</span><br><span class="line">2.mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</span><br><span class="line">3.=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式</span><br></pre></td></tr></table></figure><h3 id="innodb-索引如何实现"><a class="markdownIt-Anchor" href="#innodb-索引如何实现"></a> InnoDB 索引如何实现</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">（1）B+树，减少IO次数。一个节点就是一页的大小，而索引中B+树，它的层级一般是3层，也就意味着我们需要3次IO</span><br><span class="line">（2）叶子节点有链表，节点包含数据行的所有信息，加快区间访问速度</span><br><span class="line">（3）主键索引、辅助索引的区别？（叶子节点存什么）</span><br><span class="line"><span class="code">聚集索引：表中行的物理顺序与键值的逻辑（索引）顺序相同。叶子节点包含数据行的所有信息。一个表只能包含一个聚集索引，提供更快的数据访问速度，适用于很少对基表进行增删改操作的情况。</span></span><br><span class="line"><span class="code">    二级索引：又叫辅助索引、非聚集索引。B+tree结构，但是叶子节点保存的是&lt;键值，主键值&gt;</span></span><br><span class="line"><span class="code">InnoDB的主键索引是聚集索引，即包含了数据行的所有信息。</span></span><br><span class="line"><span class="code">InnoDB的二级索引（辅助索引）叶子包含的数据就是该行的主键。</span></span><br><span class="line"><span class="code">（4）InnoDB这么设计是利用了缓存机制，减少IO访问次数</span></span><br></pre></td></tr></table></figure><h3 id="执行计划"><a class="markdownIt-Anchor" href="#执行计划"></a> 执行计划</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">explain  查询语句会得到如下信息：</span><br><span class="line"><span class="code">table | type | possible_keys | key | key_len | ref | rows | Extra</span></span><br><span class="line"><span class="code">table：显示这一行的数据是关于哪张表的</span></span><br><span class="line"><span class="code">**type：**这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、index和ALL</span></span><br><span class="line"><span class="code">possible_keys：显示可能应用在这张表中的索引。</span></span><br><span class="line"><span class="code">**key：**实际使用的索引，查看是否使用我们想要的key</span></span><br><span class="line"><span class="code">key_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好</span></span><br><span class="line"><span class="code">ref：显示索引的哪一列被使用了，如果可能的话，是一个常数</span></span><br><span class="line"><span class="code">rows：MYSQL认为必须检查的用来返回请求数据的行数</span></span><br><span class="line"><span class="code">**extra：**是否有耗性能的操作，比如：</span></span><br><span class="line"><span class="code">Using filesort: mysql需要进行额外的步骤来发现如何对返回的行排序</span></span><br><span class="line"><span class="code">Using temporary: mysql需要创建一个临时表来存储结果</span></span><br><span class="line"><span class="code">Using index condition: 使用了索引，但是需要回表查询</span></span><br></pre></td></tr></table></figure><h3 id="sql如何调优"><a class="markdownIt-Anchor" href="#sql如何调优"></a> SQL如何调优</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">（1）查看执行计划（如上）</span><br><span class="line">（2）优化索引</span><br><span class="line">最左前缀原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配</span><br><span class="line">覆盖索引，索引中包含了满足查询语句中字段与条件的数据，避免回表查询</span><br><span class="line">使用索引排序，而不是file sort</span><br><span class="line">主键使用合适的数据类型</span><br><span class="line">选用区分度较高的索引</span><br><span class="line">（3）反范式设计</span><br><span class="line">在表里增加一些与主键不直接相关的列</span><br><span class="line">（4）Join内连接的优化</span><br><span class="line">小表驱动大表（Mysql优化器可优化、减少循环次数），在被驱动表中连接的字段要走索引。EXPLAIN结果中，第一行出现的表就是驱动表</span><br><span class="line">（4）万变不离其宗，主要就是为了减少IO次数</span><br><span class="line"></span><br><span class="line">具体的：</span><br><span class="line"><span class="bullet">1.</span> 指定查询的列，只查询需要的结果，避免查询所有列</span><br><span class="line"><span class="bullet">2.</span> 使用覆盖索引，避免回表查询</span><br><span class="line"><span class="bullet">3.</span> 空值判断使用<span class="code">`is not null`</span>， 使用<span class="code">`is null`</span>会导致全表扫描</span><br><span class="line"><span class="bullet">4.</span> 使用组合索引要注意最左前缀原则</span><br><span class="line"><span class="bullet">5.</span> where、order by、group、多表连接条件中的字段应该创建索引</span><br><span class="line"><span class="bullet">6.</span> 使用like匹配时，通配符%不能放在最前</span><br><span class="line"><span class="bullet">7.</span> 分页查询不要使用offset，而是使用范围查询+limit</span><br><span class="line"><span class="bullet">8.</span> 避免对查询条件使用函数，会导致索引失效</span><br><span class="line"><span class="bullet">9.</span> 隐式转换会导致索引失效</span><br><span class="line"><span class="bullet">10.</span> 避免使用or，会导致索引失效，而应该用union连接</span><br></pre></td></tr></table></figure><h3 id="b树和b树的区别"><a class="markdownIt-Anchor" href="#b树和b树的区别"></a> B树和B+树的区别</h3><table><thead><tr><th>B树</th><th>B+树</th></tr></thead><tbody><tr><td>有k个元素的中间节点包含k+1个子树</td><td>有k个元素的中间节点包含k个子树</td></tr><tr><td>子树中不包含中间节点的元素</td><td>子树中包含中间节点的元素</td></tr><tr><td>叶子节点之间没有链接，范围查询要不断进行中序遍历</td><td>叶子节点为有序链表，方便范围查询</td></tr><tr><td>每个节点都包含数据</td><td>只有叶子节点包含数据</td></tr><tr><td>查询性能最好为1，最差为树高的次数（每次都要IO）</td><td>查询次数为树高，只需要一次IO</td></tr></tbody></table><h3 id="hash索引和b树索引"><a class="markdownIt-Anchor" href="#hash索引和b树索引"></a> Hash索引和B树索引</h3><table><thead><tr><th></th><th>Hash索引</th><th>B树索引</th></tr></thead><tbody><tr><td>等值查询</td><td>更快，但是存在大量hash冲突时会大大降低查询效率</td><td>查询效率比较稳定</td></tr><tr><td>范围查询</td><td>不支持</td><td>支持</td></tr><tr><td>排序</td><td>不支持</td><td>支持</td></tr><tr><td>模糊查询</td><td>不支持</td><td>支持</td></tr><tr><td>前缀查询</td><td>不支持</td><td>支持</td></tr><tr><td>回表查询</td><td>每次查询都要回表</td><td>聚集索引不需要回表</td></tr></tbody></table><h2 id="存储引擎"><a class="markdownIt-Anchor" href="#存储引擎"></a> 存储引擎</h2><h3 id="innodb和myisam"><a class="markdownIt-Anchor" href="#innodb和myisam"></a> InnoDB和MyIsam</h3><table><thead><tr><th></th><th>MyIsam</th><th>Memory</th><th>InnoDB</th></tr></thead><tbody><tr><td>全文索引</td><td>yes</td><td>no</td><td>no</td></tr><tr><td>哈希索引</td><td>no</td><td>yes</td><td>no</td></tr><tr><td>B树索引</td><td>yes</td><td>yes</td><td>yes</td></tr><tr><td>集群索引</td><td>no</td><td>no</td><td>yes</td></tr><tr><td>数据索引</td><td>no</td><td>yes</td><td>yes</td></tr><tr><td>外键</td><td>no</td><td>no</td><td>yes</td></tr><tr><td>锁支持</td><td>表级锁</td><td></td><td>行级锁、表级锁，锁粒度小并发能力更高</td></tr><tr><td>事务</td><td>不支持</td><td></td><td>支持</td></tr><tr><td>外键</td><td>不支持</td><td></td><td>支持</td></tr><tr><td>记录存储顺序</td><td>按记录插入顺序保存</td><td></td><td>按主键大小顺序保存</td></tr><tr><td>存储空间</td><td>MyISAM可被压缩，存储空间较小</td><td></td><td>InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引</td></tr><tr><td>select count(*)</td><td>更快，因为维护了一个计数器</td><td></td><td>通过索引计算</td></tr></tbody></table><h3 id="b树和b树"><a class="markdownIt-Anchor" href="#b树和b树"></a> B树和B+树</h3><table><thead><tr><th>B树</th><th>B+树</th></tr></thead><tbody><tr><td>子树中不包含中间节点的元素</td><td>子树中包含中间节点的元素</td></tr><tr><td></td><td>叶子节点为有序链表，方便范围查询</td></tr><tr><td>每个节点都包含数据</td><td>只有叶子节点包含数据</td></tr><tr><td>查询性能最好为1，最差为树高的次数（每次都要IO）</td><td>查询次数为树高，只需要一次IO</td></tr></tbody></table><p>一个数据结构可视化网站：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html</span><br></pre></td></tr></table></figure><h2 id="事务"><a class="markdownIt-Anchor" href="#事务"></a> 事务</h2><h3 id="事务的特性-acid"><a class="markdownIt-Anchor" href="#事务的特性-acid"></a> 事务的特性-ACID</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Atomic（原子性）：事务中的操作，要么都成功，都失败</span><br><span class="line">Consistency（一致性）：数据从一个正确的状态到另一个正确的状态</span><br><span class="line">Isolation（隔离性）：事务之间互相影响，保证同时执行的事务互相之间没有干扰</span><br><span class="line">Durability（持久性）：存到磁盘中，即使机器断电，数据还是有的</span><br></pre></td></tr></table></figure><h3 id="并发事务带来的问题"><a class="markdownIt-Anchor" href="#并发事务带来的问题"></a> 并发事务带来的问题</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="strong">**更新丢失:**</span> 两个事务同时更新一行数据，最后一个事务的更新会覆盖掉第一个事务的更新，从而导致第一个事务更新的数据丢失，这是由于没有加锁造成的；</span><br><span class="line"><span class="strong">**脏读:**</span> 事务读取尚未提交的数据;</span><br><span class="line"><span class="strong">**不可重复读:**</span> 更新行导致，在同一事务中，两次读取同一数据，得到内容不同，也就是有其他事务更改了这些数据</span><br><span class="line"><span class="strong">**幻读:**</span> 插入行导致，一个事务在执行过程中读取到了另一个事务已提交的插入数据。</span><br></pre></td></tr></table></figure><h3 id="事务的隔离级别"><a class="markdownIt-Anchor" href="#事务的隔离级别"></a> 事务的隔离级别</h3><table><thead><tr><th style="text-align:center">隔离级别</th><th style="text-align:center">脏读</th><th style="text-align:center">不可重复读</th><th style="text-align:center">幻读</th></tr></thead><tbody><tr><td style="text-align:center">Read Uncommitted(一个事务可以读取另一个未提交事务的数据)</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">Read Committed(一个事务要等另一个事务提交后才能读取数据)</td><td style="text-align:center"></td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">Repeatable Read（默认，在开始读取数据时，不再允许修改操作<br>实现：间隙锁锁住叶子节点的next指针）</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">Serializable(事务串行化顺序执行，效率低下)</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MySql默认的隔离级别：RR</span><br><span class="line">Oracle默认的隔离级别：RC</span><br></pre></td></tr></table></figure><h3 id="mvcc"><a class="markdownIt-Anchor" href="#mvcc"></a> MVCC</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">多版本并发控制（MVCC），解决不可重复读。</span><br><span class="line">为每个数据增加一个版本号，每次修改会对该记录版本号递增，可重复读（RR），读取事务开始前最新的版本号；读已提交（RC，通过间隙锁实现），每次读取最新的数据。</span><br></pre></td></tr></table></figure><h3 id="分布式事务"><a class="markdownIt-Anchor" href="#分布式事务"></a> 分布式事务</h3><p>写的很好的博客：<a href="https://www.cnblogs.com/yaochunhui/p/15594250.html">https://www.cnblogs.com/yaochunhui/p/15594250.html</a></p><h4 id="xa协议"><a class="markdownIt-Anchor" href="#xa协议"></a> XA协议</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">XA分布式事务协议，包含二阶段提交（2PC），三阶段提交（3PC）两种实现。</span><br><span class="line"><span class="strong">**二阶段提交**</span></span><br><span class="line"><span class="code">1.准备阶段</span></span><br><span class="line"><span class="code">  事务协调者，向所有事务参与者发送事务内容，询问是否可以提交事务，并等待参与者回复；</span></span><br><span class="line"><span class="code">  事务参与者收到事务内容，开始执行事务操作，将 undo 和 redo 信息记入事务日志中（但此时并不提交事务）；</span></span><br><span class="line"><span class="code">  如果参与者执行成功，给协调者回复yes,表示可以进行事务提交。如果执行失败，给协调者回复no,表示不可提交。</span></span><br><span class="line"><span class="code">2.提交阶段</span></span><br><span class="line"><span class="code">  如果协调者收到了参与者的失败信息或超时，直接给所有参与者发送回滚（rollback）信息进行事务回滚，否则，发送提交（commit）信息。</span></span><br><span class="line"><span class="code">存在的问题：</span></span><br><span class="line"><span class="code">  性能问题：所有参与者在事务提交阶段处于同步阻塞状态，占用系统资源，容易导致性能瓶颈。</span></span><br><span class="line"><span class="code">可靠性问题：如果协调者存在单点故障问题，如果协调者出现故障，参与者将一直处于锁定状态。</span></span><br><span class="line"><span class="code">数据一致性问题：在阶段2中，如果发生网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。</span></span><br><span class="line"><span class="code">**三阶段提交**</span></span><br><span class="line"><span class="code">  三阶段提交是在二阶段提交上的改进版本，主要是加入了超时机制。同时在协调者和参与者中都引入超时机制，在等待超时后协调者或参与者会中断事务，避免了协调者单点问题。</span></span><br><span class="line"><span class="code">  1. preCommit</span></span><br><span class="line"><span class="code">     协调者向所有参与者发出包含事务内容的 canCommit 请求，询问是否可以提交事务，并等待所有参与者答复。</span></span><br><span class="line"><span class="code">     参与者收到 canCommit 请求后，如果认为可以执行事务操作，则反馈 yes 并进入预备状态，否则反馈 no。</span></span><br><span class="line"><span class="code">  2. preCommit</span></span><br><span class="line"><span class="code">     阶段1所有参与者均反馈 yes</span></span><br><span class="line"><span class="code">        协调者向所有参与者发出 preCommit 请求，进入准备阶段</span></span><br><span class="line"><span class="code">        参与者收到 preCommit 请求后，执行事务操作，将 undo 和 redo 信息记入事务日志中（但不提交事务）</span></span><br><span class="line"><span class="code">        各参与者向协调者反馈 ack 响应或 no 响应，并等待最终指令</span></span><br><span class="line"><span class="code">     阶段1任何一个参与者反馈 no</span></span><br><span class="line"><span class="code">        协调者向所有参与者发出 abort 请求</span></span><br><span class="line"><span class="code">        无论收到协调者发出的 abort 请求，或者在等待协调者请求过程中出现超时，参与者均会中断事务。</span></span><br><span class="line"><span class="code">  3. do Commit</span></span><br><span class="line"><span class="code">     阶段2所有参与者均反馈 yes</span></span><br><span class="line"><span class="code">        如果协调者处于工作状态，则向所有参与者发出 do Commit 请求</span></span><br><span class="line"><span class="code">        参与者收到 do Commit 请求后，会正式执行事务提交，并释放整个事务期间占用的资源</span></span><br><span class="line"><span class="code">        各参与者向协调者反馈 ack 完成的消息</span></span><br><span class="line"><span class="code">        协调者收到所有参与者反馈的 ack 消息后，即完成事务提交</span></span><br><span class="line"><span class="code">     阶段2任何一个参与者反馈 no</span></span><br><span class="line"><span class="code">        如果协调者处于工作状态，向所有参与者发出 abort 请求</span></span><br><span class="line"><span class="code">        参与者使用阶段1中的 undo 信息执行回滚操作，并释放整个事务期间占用的资源</span></span><br><span class="line"><span class="code">        各参与者向协调者反馈 ack 完成的消息</span></span><br><span class="line"><span class="code">        协调者收到所有参与者反馈的 ack 消息后，即完成事务中断</span></span><br><span class="line"><span class="code">     注意：进入阶段3后，如果参与者超时了还没有收到协调者的信息，会提交事务。</span></span><br><span class="line"><span class="code">  存在的问题：数据不一致问题依然存在，当在参与者收到 preCommit 请求后等待 do commite 指令时，此时如果协调者请求中断事务，而协调者无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。</span></span><br></pre></td></tr></table></figure><h4 id="tcc事务"><a class="markdownIt-Anchor" href="#tcc事务"></a> TCC事务</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">TCC（Try-Confirm-Cancel）：实现最终一致性。</span><br><span class="line">TCC 是服务化的二阶段编程模型，其Try、Confirm、Cancel个方法均由业务编码实现（可以理解为SQL事务中的Lock、Commit、Rollback）：</span><br><span class="line"><span class="code">Try 操作作为一阶段，负责资源的检查和预留。</span></span><br><span class="line"><span class="code">Confirm 操作作为二阶段提交操作，执行真正的业务。</span></span><br><span class="line"><span class="code">Cancel 是预留资源的取消。</span></span><br><span class="line"><span class="code">Try 阶段是一个初步的操作：</span></span><br><span class="line"><span class="code">完成所有业务检查( 一致性 ) 。</span></span><br><span class="line"><span class="code">预留必须业务资源( 准隔离性 ) 。</span></span><br><span class="line"><span class="code">Try 尝试执行业务。</span></span><br><span class="line"><span class="code">Confirm 阶段：如果事务正常执行，进入Confirm阶段，执行事务提交。</span></span><br><span class="line"><span class="code">Cancel 阶段：如果事务执行异常，进入Cancel阶段，回滚事务，释放资源。</span></span><br></pre></td></tr></table></figure><h4 id="saga事务"><a class="markdownIt-Anchor" href="#saga事务"></a> Saga事务</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Saga 事务也是保证最终一致性。</span><br><span class="line">Saga 事务核心思想是将长事务拆分为多个本地短事务，由 Saga 事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。</span><br><span class="line">Saga 事务基本协议如下：</span><br><span class="line"><span class="code">每个 Saga 事务由一系列幂等的有序子事务(sub-transaction) Ti 组成。</span></span><br><span class="line"><span class="code">每个 Ti 都有对应的幂等补偿动作 Ci，补偿动作用于撤销 Ti 造成的结果。</span></span><br></pre></td></tr></table></figure><h2 id="innodb中的锁"><a class="markdownIt-Anchor" href="#innodb中的锁"></a> InnoDB中的锁</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">行锁（Record lock）：锁住单个行记录</span><br><span class="line">间隙锁（Gap lock）：锁定一个范围，不包括记录本身</span><br><span class="line">范围锁（Next-key lock）：record+gap 锁定一个范围，包含记录本身</span><br><span class="line">注意：innoDB的锁是通过索引来实现的，如果查询条件不是索引，将锁住整张表</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="乐观锁-悲观锁的实现区别使用场景"><a class="markdownIt-Anchor" href="#乐观锁-悲观锁的实现区别使用场景"></a> 乐观锁、悲观锁的实现？区别？使用场景？</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">乐观锁：</span><br><span class="line">  通过 where 条件中的版本号来确定是否更新，版本号递增，当版本号相同时才做修改操作。</span><br><span class="line">悲观锁：</span><br><span class="line">  排他锁：for update</span><br><span class="line">共享锁：in share mode（只能读）</span><br><span class="line">行锁、表锁</span><br><span class="line">  innodb，走索引，能走到行锁</span><br></pre></td></tr></table></figure><h2 id="log"><a class="markdownIt-Anchor" href="#log"></a> log</h2><h3 id="redo-log的作用"><a class="markdownIt-Anchor" href="#redo-log的作用"></a> redo log的作用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">是重做日志，提供前滚操作。WAL，write ahead log，随机写变顺序写，提高性能，保证数据的持久性（D）</span><br></pre></td></tr></table></figure><h3 id="undo-log的作用"><a class="markdownIt-Anchor" href="#undo-log的作用"></a> undo log的作用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">回退日志，提供回滚操作。保证原子性（A）（隔离性(I)由锁保证）</span><br></pre></td></tr></table></figure><h3 id="binlog的作用"><a class="markdownIt-Anchor" href="#binlog的作用"></a> binlog的作用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">备份、主备同步。binlog是一个二进制格式的文件，用于记录用户对数据库更新的SQL语句信息。</span><br></pre></td></tr></table></figure><h3 id="innodb和myisam的区别"><a class="markdownIt-Anchor" href="#innodb和myisam的区别"></a> InnoDB和MyIsam的区别？</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">InnoDB（默认，公司用的都是这个）</span><br><span class="line">  1、支持事务处理、ACID事务特性；</span><br><span class="line">  2、实现了SQL标准的四种隔离级别；</span><br><span class="line">  3、支持行级锁和外键约束；</span><br><span class="line">  4、锁级别为行锁，行锁优点是适用于高并发的频繁表修改，高并发是性能优于 MyISAM。缺点是系统消耗较大。</span><br><span class="line">  5、索引存储数据（聚集索引），相比 MyISAM 需要更大的内存。</span><br><span class="line">MyIsam</span><br><span class="line">  1.高性能读取；</span><br><span class="line">  2.因为它保存了表的行数，当使用COUNT统计时不会扫描全表</span><br><span class="line">  3.支持全文本索引（更好的选择是EleasticSearch）</span><br></pre></td></tr></table></figure><h2 id="数据库设计的三大范式"><a class="markdownIt-Anchor" href="#数据库设计的三大范式"></a> 数据库设计的三大范式</h2><pre class="highlight"><code class="markdown">（1）每个属性都是原子的（必须遵循的，方便查）（2）表中每个列都和主键相关(也是要遵循的)，不能部分相关（3）表中的每列和主键直接相关，不能间接相关</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;整理一些mysql的知识。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>回溯算法</title>
    <link href="https://eoccc.gitee.io/2022/10/27/%E7%AE%97%E6%B3%95-%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/"/>
    <id>https://eoccc.gitee.io/2022/10/27/%E7%AE%97%E6%B3%95-%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/</id>
    <published>2022-10-27T07:10:35.000Z</published>
    <updated>2023-04-22T11:01:49.185Z</updated>
    
    <content type="html"><![CDATA[<p>回溯算法。</p><span id="more"></span><p>回溯算法模版：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">void backtracking(参数) &#123;</span><br><span class="line">    if (终止条件) &#123;</span><br><span class="line">        存放结果;</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for (选择：本层集合中元素（树中节点孩子的数量就是集合的大小）) &#123;</span><br><span class="line">        处理节点;</span><br><span class="line">        backtracking(路径，选择列表); // 递归</span><br><span class="line">        回溯，撤销处理结果</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;回溯算法。&lt;/p&gt;</summary>
    
    
    
    
    <category term="算法" scheme="https://eoccc.gitee.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>红黑树</title>
    <link href="https://eoccc.gitee.io/2022/10/02/%E7%BA%A2%E9%BB%91%E6%A0%91/"/>
    <id>https://eoccc.gitee.io/2022/10/02/%E7%BA%A2%E9%BB%91%E6%A0%91/</id>
    <published>2022-10-02T07:25:19.000Z</published>
    <updated>2022-10-06T14:24:35.421Z</updated>
    
    <content type="html"><![CDATA[<p>红黑树是特殊的AVL树(二叉平衡树)，设计红黑树的目的，就是解决平衡树的维护起来比较麻烦的问题，红黑树读取略逊于AVL，维护强于AVL，每次插入和删除的平均旋转次数应该是远小于平衡树。</p><span id="more"></span><h1 id="红黑树的应用"><a class="markdownIt-Anchor" href="#红黑树的应用"></a> 红黑树的应用</h1><ol><li>IO多路复用的实现采用红黑树组织管理，以支持快速的增删改查</li><li>ngnix中用红黑树管理timer，因为红黑树是有序的，可以很快的得到距离当前最小的定时器</li><li>java中TreeMap，jdk1.8的hashMap实现</li></ol><h1 id="红黑树的特征"><a class="markdownIt-Anchor" href="#红黑树的特征"></a> 红黑树的特征</h1><p><strong>红定理：</strong> 不会有连续的红色节点，红色节点的子节点必定为黑色。</p><p><strong>黑定理：</strong> 根节点必须是黑节点，所有叶子节点都是黑色。</p><blockquote><ol><li>每个节点要么是黑色，要么是红色</li><li>根节点是黑色</li><li>每个叶子节点（NIL）是黑色</li><li>每个红色结点的两个子结点一定都是黑色</li><li>任意一节点到每个叶子结点的路径都包含数量相同的黑结点</li></ol></blockquote><h1 id="红黑树的插入"><a class="markdownIt-Anchor" href="#红黑树的插入"></a> 红黑树的插入</h1><p>基本操作是添加、删除和旋转。在对红黑树进行添加或删除后，会用到旋转方法。旋转的目的是让树保持红黑树的特性。旋转包括两种：左旋 和 右旋</p><h2 id="左旋"><a class="markdownIt-Anchor" href="#左旋"></a> 左旋</h2><p>父节点（P）左沉，右节点的的左节点（R）变成父节点的右子节点，右节点（V）变成新的父节点。</p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhnbkg17j30ta094jrp.jpg" alt="image-20221006123731381" style="zoom:50%;"><h2 id="右旋"><a class="markdownIt-Anchor" href="#右旋"></a> 右旋</h2><p>父节点（P）右沉，左节点的的右节点（K）变成父节点的左子节点，左节点（F）变成新的父节点。</p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhniugauj30xg094q3a.jpg" alt="image-20221006124133170" style="zoom:50%;"><h2 id="插入节点"><a class="markdownIt-Anchor" href="#插入节点"></a> 插入节点</h2><p>插入红色节点，不需要做自平衡</p><p>插入黑色节点，需要做自平衡</p><h3 id="插入红色节点"><a class="markdownIt-Anchor" href="#插入红色节点"></a> 插入红色节点</h3><p><strong>叔叔节点存在且为红色</strong></p><p>将父节点和叔叔节点变成黑色，将主父节点变成红色（主父节点违反了红黑树的规则，要继续做变色处理，最后如果根节点变成了红色，要做自旋）。</p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhnm2i70j30k60963zb.jpg" alt="image-20221006125541140" style="zoom:50%;">   <img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhnplw2cj30kc090t9i.jpg" alt="image-20221006130117125" style="zoom:50%;"></p><p><strong>叔叔节点不存在或为黑色</strong></p><ol><li><p>插入节点的父节点为左节点</p><ul><li><p>插入节点为左节点</p><p>右旋</p></li></ul><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhntajkcj30ki09474y.jpg" alt="image-20221006130459279" style="zoom:50%;"><ul><li><p>插入节点为右节点</p><p>先左旋，再右旋</p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhnuqyepj30xc0a8dh4.jpg" alt="image-20221006130658504" style="zoom:45%;"></li></ul></li><li><p>插入节点的父节点为右节点</p><ul><li><p>插入节点为左节点</p><p>先右旋，再左旋</p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vhnwxpx4j30xc0as75p.jpg" alt="image-20221006130906594" style="zoom:45%;"></li><li><p>插入节点为右节点</p><p>左旋</p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1h6vho0a6tnj30t60e2ta4.jpg" alt="image-20221006130925077" style="zoom:40%;"></li></ul></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;红黑树是特殊的AVL树(二叉平衡树)，设计红黑树的目的，就是解决平衡树的维护起来比较麻烦的问题，红黑树读取略逊于AVL，维护强于AVL，每次插入和删除的平均旋转次数应该是远小于平衡树。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据结构" scheme="https://eoccc.gitee.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Mysql-ShardingSphere分库分表</title>
    <link href="https://eoccc.gitee.io/2022/09/27/Mysql-ShardingSphere%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    <id>https://eoccc.gitee.io/2022/09/27/Mysql-ShardingSphere%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</id>
    <published>2022-09-27T08:25:19.000Z</published>
    <updated>2022-10-08T05:57:28.052Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://shardingsphere.apache.org/document/current/cn/overview/#shardingsphere-jdbc">Apache ShardingSphere</a>是一款开源的分布式数据库中间件组成的生态圈。它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（规划中）组成。提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。</p><span id="more"></span><p>Inline 不支持范围查找</p><p>Standard 支持范围查找</p><p>Complex  支持范围查找、支持多分片键</p><p>Hint 通过Hint指定分片值而非从SQL中提取分片值的方式进行分片</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://shardingsphere.apache.org/document/current/cn/overview/#shardingsphere-jdbc&quot;&gt;Apache ShardingSphere&lt;/a&gt;是一款开源的分布式数据库中间件组成的生态圈。它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（规划中）组成。提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Mysql-分库分表</title>
    <link href="https://eoccc.gitee.io/2022/09/26/Mysql-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    <id>https://eoccc.gitee.io/2022/09/26/Mysql-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</id>
    <published>2022-09-26T08:25:19.000Z</published>
    <updated>2023-03-28T02:21:13.537Z</updated>
    
    <content type="html"><![CDATA[<p>不管是IO瓶颈，还是CPU瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承载活跃连接数的阈值。在业务Service来看就是，可用数据库连接少甚至无连接可用。</p><span id="more"></span><h1 id="数据库瓶颈"><a class="markdownIt-Anchor" href="#数据库瓶颈"></a> 数据库瓶颈</h1><p>数据量增长过快或者业务规模扩大导致单个数据库实例无法满足系统的性能和容量需求，需要通过分布式扩展来解决这些问题。</p><p>具体来说，以下情况可能需要进行分库分表：</p><ol><li>数据量过大：当单个数据库实例存储的数据量达到了数据库系统的承载极限，无法再继续扩展时，需要进行分库分表来分散存储数据的压力。</li><li>数据访问频繁度不同：某些数据表可能会被频繁访问，而其他表则很少被访问，此时可以通过分表将热点数据和冷数据分开存储，从而提高数据库的性能。</li><li>数据访问模式不同：当数据表中的数据被不同的业务模块访问时，可能需要将这些数据分散到不同的数据库中，以提高系统的性能。</li><li>业务扩展需要：当业务规模扩大时，可能需要通过分库分表来增加数据库的并发能力和容量，以满足业务需求。</li><li>分布式部署需要：当系统需要进行分布式部署时，可能需要将数据库进行分库分表来支持分布式部署架构。</li></ol><p>需要注意的是，在进行数据库分库时，需要考虑数据的一致性和分布式事务的处理。此外，需要根据具体的业务场景和数据特点选择最合适的分库方式。</p><h2 id="io瓶颈"><a class="markdownIt-Anchor" href="#io瓶颈"></a> IO瓶颈</h2><ol><li><p>磁盘IO瓶颈</p><p>热点数据太多，mysql的缓存放不下，产生大量的回表查询，导致查询数据降低。</p><p>解决：分库，垂直分表</p></li><li><p>网络IO瓶颈</p><p>请求的数据太多，带宽不够</p><p>解决：分库分集群</p></li></ol><h2 id="cpu瓶颈"><a class="markdownIt-Anchor" href="#cpu瓶颈"></a> CPU瓶颈</h2><ol><li><p>SQL问题</p><p>如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运算的操作</p><p>解决：SQL优化，建立合适的索引，在业务Service层进行业务计算</p></li><li><p>单表数据量太大</p><p>查询时扫描的行数太多，sql效率低</p><p>解决：水平分表</p></li></ol><h1 id="分库"><a class="markdownIt-Anchor" href="#分库"></a> 分库</h1><h2 id="水平分库horizontal-sharding"><a class="markdownIt-Anchor" href="#水平分库horizontal-sharding"></a> 水平分库（Horizontal Sharding）</h2><p>水平分库是指按照数据行的关系将数据拆分到不同的数据库中。例如，可以将用户表按照用户ID的范围进行拆分，将不同范围的用户存储在不同的数据库中。</p><p>根据分库键，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。</p><ul><li>每个库中的表结构都是一样的</li><li>每个库中的数据都不一样，没有交集</li><li>所有库中的数据的并集为全量数据</li></ul><p>适用场景：一个库的数据量太大，导致cpu、磁盘io、网络io的压力都很高。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/-wKcOJIPb.jpeg" alt="-wKcOJIPb.jpeg"></p><h2 id="垂直分库vertical-sharding"><a class="markdownIt-Anchor" href="#垂直分库vertical-sharding"></a> 垂直分库（Vertical Sharding）</h2><p>垂直分库是指按照数据表或列的关系将数据拆分到不同的数据库中。例如，可以将订单表和用户表分别存储在不同的数据库中，这样可以避免数据表之间的冗余和重复。</p><p>以表或列为依据，按照业务归属不同，将不同的表拆分到不同的库中。</p><ul><li>每个库中存放不同的表</li><li>每个库中的数据都不同</li><li>所有库中的数据的并集为全部数据</li></ul><p>适用场景：数据库中的表越来越多，导致数据库连接数不足。业务发展到这种情况，可以考虑拆分服务。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/99Watzd9D.jpeg" alt="99Watzd9D.jpeg"></p><h2 id="分片sharding"><a class="markdownIt-Anchor" href="#分片sharding"></a> 分片（Sharding）</h2><p>分片是指将数据按照某种规则进行分割，并将不同的分片存储在不同的数据库中。例如，可以按照用户的地理位置将用户数据分割成不同的分片，并将每个分片存储在不同的数据库中。</p><p>和水平分库相似。</p><h2 id="混合分库hybrid-sharding"><a class="markdownIt-Anchor" href="#混合分库hybrid-sharding"></a> 混合分库（Hybrid Sharding）</h2><p>混合分库是指将垂直分库和水平分库结合起来，以实现更精细的数据划分。例如，可以将用户表按照用户ID的范围进行水平分割，并将不同的用户表存储在不同的数据库中，同时将订单表和商品表等其他表垂直分割到不同的数据库中。</p><h1 id="分表"><a class="markdownIt-Anchor" href="#分表"></a> 分表</h1><h2 id="水平分表"><a class="markdownIt-Anchor" href="#水平分表"></a> 水平分表</h2><p>根据分表键，按照一定策略（hash、range等），将一个库中的数据拆分到多个表中。</p><ul><li>每个表中的表结构都是一样的</li><li>每个表中的数据都不一样，没有交集</li><li>所有表中的数据的并集为全量数据</li></ul><p>适用场景：单表的数据量太大，导致查询效率降低。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/VNwsPuzzM.jpeg" alt="VNwsPuzzM.jpeg"></p><p>一些水平分表的方式：</p><ol><li>按照数据量分表：按照数据量的大小将数据分散存储到不同的表中，每个表存储一定量的数据。这种方式比较简单，但需要预估数据增长量并及时进行迁移，否则可能会导致某些表数据过大而影响系统性能。</li><li>按照数据业务属性分表：将数据按照业务属性进行分表，例如将订单表按照用户ID分表，将商品表按照商品类别分表等。这种方式可以提高查询效率，但需要对业务进行分析，合理设计分表规则。</li><li>按照数据地理位置分表：将数据按照地理位置进行分表，例如将用户按照所在省份进行分表。这种方式适用于需要根据地理位置进行查询的业务，可以减少跨节点查询的开销。</li><li>按照时间分表：将数据按照时间进行分表，例如将日志表按照日期分表，每天一个表。这种方式可以提高查询效率，同时方便数据的归档和清理。</li></ol><h2 id="垂直分表"><a class="markdownIt-Anchor" href="#垂直分表"></a> 垂直分表</h2><p>以字段为依据，按照字段的活跃度，将表中字段拆到不同的表（主表和扩展表）中。</p><ul><li>每个表的结构不一样</li><li>每个表中只有一个关联键是一样的，其他数据都不一样</li><li>所有表的所有列的并集为全量数据</li></ul><p>适用场景：单表的字段过多，同时存在热数据和冷数据，单行数据占用的空间大，导致叶缓存能够保存的数据条数减少，查询时产生大量IO。另外，字段过多，查询条件也会很多，就需要建立更多的索引，导致插入、更新和删除效率降低，索引文件很大。</p><p><img src="https://gitee.com/eoccc/pic-shack/raw/master/a_YCOhAzj.jpeg" alt="a_YCOhAzj.jpeg"></p><p>需要注意：分表以后，进行联合查询的时候要<strong>尽量不要使用join</strong>，因为join不仅会增加CPU负担并且会将两个表耦合在一起（必须在一个数据库实例上）。关联数据应该在业务Service层做文章，分别获取主表和扩展表数据然后用关联字段关联得到全部数据。</p><h2 id="组合分库分表"><a class="markdownIt-Anchor" href="#组合分库分表"></a> 组合分库分表</h2><p>在一些场景下，只有分库或者分表是不能解决问题的。这时我们可以结合分库和分表，灵活进行配。</p><p>我们可以先根据第一个key进行分库，然后根据第二个key进行分表。</p><p>并且可以根据不同的业务情况，设定不同的分配策略，比如订单表，对于订单较多的月份，我们可以分配更多的表，使用hash策略将订单均匀的写到不同的表中。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;不管是IO瓶颈，还是CPU瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承载活跃连接数的阈值。在业务Service来看就是，可用数据库连接少甚至无连接可用。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Mysql" scheme="https://eoccc.gitee.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Lombok @Builder注解导致默认值失效</title>
    <link href="https://eoccc.gitee.io/2022/09/11/Lombok%20@Builder%E6%B3%A8%E8%A7%A3%E5%AF%BC%E8%87%B4%E9%BB%98%E8%AE%A4%E5%80%BC%E5%A4%B1%E6%95%88/"/>
    <id>https://eoccc.gitee.io/2022/09/11/Lombok%20@Builder%E6%B3%A8%E8%A7%A3%E5%AF%BC%E8%87%B4%E9%BB%98%E8%AE%A4%E5%80%BC%E5%A4%B1%E6%95%88/</id>
    <published>2022-09-11T07:25:19.000Z</published>
    <updated>2022-09-22T12:03:10.125Z</updated>
    
    <content type="html"><![CDATA[<p>Lombok @Builder注解可以让我们很方便的使用builder模式构建对象，但是今天发现使用@Builder注解创建对象时，不会初始化默认值。</p><p>我们测试一下，先写个demo：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Builder</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> <span class="string">&quot;haha&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 测试一下</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> User.builder().build();</span><br><span class="line">  System.out.println(user.getName());</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：null</span></span><br></pre></td></tr></table></figure><p>编译以后，会生成两个class文件，一个是User自己的class，另一个是builder生成的class：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User$UserBuilder.class</span><br><span class="line">User.class</span><br></pre></td></tr></table></figure><p>随后我们反编译一下 看看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">javap -p User.class</span><br><span class="line">javap -p User\<span class="variable">$UserBuilder</span>.class</span><br></pre></td></tr></table></figure><p>反编译结果：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line"><span class="comment">//属性上设置了默认值</span></span><br><span class="line">  <span class="keyword">private</span> <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> <span class="string">&quot;haha&quot;</span>;</span><br><span class="line"></span><br><span class="line">  User(<span class="keyword">final</span> String name) &#123;</span><br><span class="line">    <span class="built_in">this</span>.name = name;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> UserBuilder <span class="title function_">builder</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">UserBuilder</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.name;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">UserBuilder</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    UserBuilder() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> User <span class="title function_">build</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="comment">//执行build的时候，没有将默认值设置进去</span></span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">User</span>(<span class="built_in">this</span>.name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;User.UserBuilder(name=&quot;</span> + <span class="built_in">this</span>.name + <span class="string">&quot;)&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>通过反编译的结果，我们可以看出编译后的代码是没有给User设置默认值的。</strong></p><p>在1.6.X版本中，Lombok加入了@Builder.Default注解，以实现默认值的初始化：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Builder</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="meta">@Builder</span>.Default</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> <span class="string">&quot;haha&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//测试</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> User.builder().build();</span><br><span class="line">  System.out.println(user.getName());</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：haha</span></span><br></pre></td></tr></table></figure><p>反编译看看：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//User.class</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//默认值放到了这个方法里面</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> String $<span class="keyword">default</span>$name() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;haha&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  User(<span class="keyword">final</span> String name) &#123;</span><br><span class="line">    <span class="built_in">this</span>.name = name;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> UserBuilder <span class="title function_">builder</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">UserBuilder</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.name;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">UserBuilder</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> name$set;</span><br><span class="line">    <span class="keyword">private</span> String name$value;</span><br><span class="line"></span><br><span class="line">    UserBuilder() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> UserBuilder <span class="title function_">name</span><span class="params">(<span class="keyword">final</span> String name)</span> &#123;</span><br><span class="line">      <span class="built_in">this</span>.name$value = name;</span><br><span class="line">      <span class="built_in">this</span>.name$set = <span class="literal">true</span>;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> User <span class="title function_">build</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="type">String</span> <span class="variable">name$value</span> <span class="operator">=</span> <span class="built_in">this</span>.name$value;</span><br><span class="line">      <span class="keyword">if</span> (!<span class="built_in">this</span>.name$set) &#123;</span><br><span class="line"><span class="comment">//执行build方法的时候，如果name没有设置，调用设置默认值</span></span><br><span class="line">        name$value = User.$<span class="keyword">default</span>$name();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">User</span>(name$value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;User.UserBuilder(name$value=&quot;</span> + <span class="built_in">this</span>.name$value + <span class="string">&quot;)&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>所以使用Lombok的<code>@Builder</code>注解默认是不会初始化默认值的，如果需要使用默认值，需要将版本升级到1.6.x，并使用<code>@Builder.Default</code>注解标记有默认值的属性。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Lombok @Builder注解可以让我们很方便的使用builder模式构建对象，但是今天发现使用@Builder注解创建对象时，不会初始化默认值。&lt;/p&gt;
&lt;p&gt;我们测试一下，先写个demo：&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;ta</summary>
      
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
    <category term="踩坑" scheme="https://eoccc.gitee.io/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
</feed>
