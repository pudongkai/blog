<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Eoccc的博客</title>
  
  
  <link href="https://eoccc.gitee.io/atom.xml" rel="self"/>
  
  <link href="https://eoccc.gitee.io/"/>
  <updated>2022-08-12T01:38:01.442Z</updated>
  <id>https://eoccc.gitee.io/</id>
  
  <author>
    <name>Eoccc</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>protobuf序列化和反序列化</title>
    <link href="https://eoccc.gitee.io/2022/08/10/protobuf%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <id>https://eoccc.gitee.io/2022/08/10/protobuf%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/</id>
    <published>2022-08-10T10:25:19.000Z</published>
    <updated>2022-08-12T01:38:01.442Z</updated>
    
    <content type="html"><![CDATA[<p>Protobuf是一个很优秀的序列化和反序列化工具，具有较高的效率，并且能够减小内存占用，但是需要我们能够正确的使用。这篇博客就来记录一些Protobuf的使用和一些踩过的坑。</p><span id="more"></span>]]></content>
    
    
    <summary type="html">protobuf是一个很优秀的序列化和反序列化工具，具有较高的效率，并且能够减小内存占用，但是需要我们能够正确的使用。</summary>
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
    <category term="踩坑" scheme="https://eoccc.gitee.io/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>开发原则，经验总结</title>
    <link href="https://eoccc.gitee.io/2022/08/07/%E5%BC%80%E5%8F%91%E5%8E%9F%E5%88%99/"/>
    <id>https://eoccc.gitee.io/2022/08/07/%E5%BC%80%E5%8F%91%E5%8E%9F%E5%88%99/</id>
    <published>2022-08-07T14:52:41.000Z</published>
    <updated>2022-08-12T01:32:28.483Z</updated>
    
    <content type="html"><![CDATA[<p>从代码的坏味道中，总结一些开发经验。</p><span id="more"></span><h1 id="字段意义唯一性"><a class="markdownIt-Anchor" href="#字段意义唯一性"></a> 字段意义唯一性</h1><p>设计字段的时候，要尽可能保证字段所代表的逻辑的唯一性，不能一个字段控制了多个功能，否则会导致后期理解代码逻辑的成本急剧增加，并且出问题的概率也会增加，甚至是故障。</p><p>一个bad case：</p><blockquote><p>在我们的代码中存在了这样一个字段：productTypeCode，这个字段最开始是代表了商品类型，后来这个字段在后来的业务中被用作了其他的功能，比如上游系统中对商品进行分类，识别特殊的商品，因此，这个字段在业务代码中不断的被修改，有时候会换成另一个值，有时候加个后缀等等，以至于到了后来，我们都不知道这个字段到底是用来干嘛。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;从代码的坏味道中，总结一些开发经验。&lt;/p&gt;</summary>
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
    <category term="经验总结" scheme="https://eoccc.gitee.io/tags/%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>软引用和弱的使用场景</title>
    <link href="https://eoccc.gitee.io/2022/07/10/%E8%BD%AF%E5%BC%95%E7%94%A8%E5%92%8C%E5%BC%B1%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
    <id>https://eoccc.gitee.io/2022/07/10/%E8%BD%AF%E5%BC%95%E7%94%A8%E5%92%8C%E5%BC%B1%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</id>
    <published>2022-07-09T16:00:00.000Z</published>
    <updated>2022-08-01T04:58:42.278Z</updated>
    
    <content type="html"><![CDATA[<p>我们日常开发中一般不会使用到软引用，因此对这块可能比较陌生，看过一些使用场景，但是过一段时间可能就忘记了，这篇博客就整理一下软引用的使用场景。</p><span id="more"></span><h1 id="软引用"><a class="markdownIt-Anchor" href="#软引用"></a> 软引用</h1><p>软引用的特点：当系统的内存不足时，进行回收，否则不会回收。</p><p>应用场景：</p><blockquote><ol><li>保存网页资源，如图片等</li><li>Spring 缓存配置属性缓存–SoftReferenceConfigurationPropertyCache</li></ol></blockquote><h1 id="弱引用"><a class="markdownIt-Anchor" href="#弱引用"></a> 弱引用</h1><p>软引用的特点：下一次GC的时候会回收</p><p>应用场景：</p><blockquote><ol><li>ThreaLocal中的map实现，此map继承了弱引用WeakReference，防止map中的key引用的对象无法被回收（线程一直处于活跃状态，导致ThreaLocal不会被回收）；</li><li>一些高速缓存场景，缓存仅在GC之间生效。</li></ol></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;我们日常开发中一般不会使用到软引用，因此对这块可能比较陌生，看过一些使用场景，但是过一段时间可能就忘记了，这篇博客就整理一下软引用的使用场景。&lt;/p&gt;</summary>
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kafka消费者</title>
    <link href="https://eoccc.gitee.io/2022/06/21/kafka%E6%B6%88%E8%B4%B9%E8%80%85/"/>
    <id>https://eoccc.gitee.io/2022/06/21/kafka%E6%B6%88%E8%B4%B9%E8%80%85/</id>
    <published>2022-06-21T14:52:41.000Z</published>
    <updated>2022-08-07T17:14:35.504Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka的消费者负责订阅topic，并从订阅的topic上拉取消息。kafka的消费层还有一个消费组（consumer group），每个consumer都有一个消费组，消息会发给订阅了这个topic的<strong>所有</strong>消费组，并由消费组中的<strong>一个</strong>消费者进行消费。</p><span id="more"></span><h1 id="消费者与消费组"><a class="markdownIt-Anchor" href="#消费者与消费组"></a> 消费者与消费组</h1><p>某个主题中共有4个分区(Partition):P0、P1、P2、P3。有两个消费组A和B都订阅了这个主题，消费组A中有4个消费者(C0、C1、C2和C3)，消费组B中有2个消费者C4和C5)。按照Kafka默认的规则，最后的分配结果是消费组A中的每一个消费者分配到1个分区，消费组B中的每一个消费者分配到2个分区，两个消费组之间互不影响。每个消费者只能消费所分配到的分区中的消息。换言之，每一个分区只能被一个消费组中的一个消费者所消费。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h4ypbl8zq6j20nc0eeab4.jpg" alt="image-20220803203252462" style="zoom:50%;"><p>如果消费者的个数大于分区的个数，则有的消费者会分配不到分区。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h4ypbfi2vtj20my0f2dgw.jpg" alt="image-20220803203324669" style="zoom:40%;"><p>一个消费者只会属于一个消费组，消费模式可以分为点对点模式和发布订阅模式：</p><blockquote><ul><li><p>点对点模式：</p><p>所有消费者都属于同一个消费组，partition会均衡地分配给每一个消费者，从而消息会均衡地发送给消费者，每条消息只会被消费一次</p></li><li><p>发布/订阅模式（广播）：</p><p>每个消费者属于一个单独的消费组，每个消费组都订阅topic，消息会发送给所有的消费组，即一条消息会被每个消费者都消费一遍</p></li></ul></blockquote><h1 id="订阅消息"><a class="markdownIt-Anchor" href="#订阅消息"></a> 订阅消息</h1><p>Kafka一个消费者可以订阅一个或多个消息主题，支持多种订阅消息的方式。</p><ul><li><p>订阅一个或多个topic</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">subscribe</span><span class="params">(Collection&lt;Str ing&gt; topics)</span></span><br></pre></td></tr></table></figure></li><li><p>根据正则表达式订阅主题</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">subscribe</span><span class="params">(Pattern pattern)</span></span><br></pre></td></tr></table></figure></li><li><p>订阅指定的分区</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">assign</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br></pre></td></tr></table></figure><p>TopicPartition对象中包含了topic和partation两个参数。</p></li></ul><p>如果我们需要知道某个topic的分区信息，可以通过<code>KafkaConsumer.partitionsFor(String tpoic)</code>进行查询，返回一个<code>List&lt;PartitionInfo&gt;</code>列表，PartitionInfo包含了这个topic的分区信息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Part</span>工tioninfo &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> String topic;              <span class="comment">//topic</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> partition;             <span class="comment">//分区</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Node leader;               <span class="comment">//这个分区的leader节点</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span>  Node[] replicas;          <span class="comment">//所有副本 ASR</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span>  Node[] inSyncReplicas;    <span class="comment">//同步副本 ISR</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Node[] offlineReplicas;    <span class="comment">//离线副本 OSR</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="消费消息"><a class="markdownIt-Anchor" href="#消费消息"></a> 消费消息</h1><p>Kafka采用poll的方式从服务端拉取消息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> ConsumerRecords&lt;K, V&gt; <span class="title function_">poll</span><span class="params">(<span class="keyword">final</span> Duration timeout)</span></span><br></pre></td></tr></table></figure><p>ConsumerRecords的内部包括了ConsumerRecord，用来存储一次拉取获得的消息集，提供了一个iterator来遍历消息集内部的消息。</p><p>我们可以通过下面的方法获取一个分区的消息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;ConsumerRecord&lt;K, V&gt; <span class="title function_">records</span><span class="params">(TopicPartition partition)</span></span><br></pre></td></tr></table></figure><p>ConsumerRecord中比较关键的属性：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConsumerRecord</span>&lt;K, V&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;                 <span class="comment">//主题</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> partition;                <span class="comment">//分区</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> offset;                  <span class="comment">//这个消息在分区中的偏移量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> timestamp;               <span class="comment">//时间戳</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> TimestampType timestampType;  <span class="comment">//时间戳的类型，有CreateTime和LogAppendTime两种类型</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> serializedKeySize;        <span class="comment">//key序列化器</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> serializedValueSize;      <span class="comment">//value序列化器</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers headers;              <span class="comment">//</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;                        <span class="comment">//消息的key</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> V value;                      <span class="comment">//消息的value</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Optional&lt;Integer&gt; leaderEpoch;<span class="comment">//leader的纪元</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> Long checksum;             <span class="comment">//CRC32校验值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="位移提交"><a class="markdownIt-Anchor" href="#位移提交"></a> 位移提交</h1><p>Kafka中每条消息都有唯一的offset，用来表示消息在分区中的位置。消费者也保存了一个offset，用来记录消费到分区中某个消息所在的位置。</p><p>在旧的消费者客户端中，offset是保存在zookeeper中的，而在新的消费者客户端中，是保存在kafka的内部主题__consumer_offsets中。</p><p>如果消费者当前消费到了x，需要提交的位移为x+1。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h4ypavsxvoj20l80awaaj.jpg" alt="image-20220807151328147" style="zoom:50%;"><p><strong>消费者提交偏移量的时机</strong></p><p>消费者提交偏移量，有可能会造成重复消费和消息丢失现象。</p><blockquote><ul><li>拉取到消息立即提交offset，如果这批消息消费的过程中出现了异常，导致部分消息没有消费，就会导致消息丢失</li><li>消息消费完再提交offset，如果这批消息消费的过程中出现了异常，消费了部分消息，但是由于没有消费完，没有提交offset，就会导致消息重复消费</li></ul></blockquote><p>kafka默认是自动提交的，即定期提交，默认是5m提交一次。<code>enable.auto.commit</code>开启自动提交，<code>auto.commit.interval.ms</code>配置提交的时间。自动提交的操作是在KafkaConsumer#poll()中完成的。消费者每隔5秒就会拉取每个分区中的最小offset进行提交，另外，每次向服务端发起拉取消息的请求的时候，都会检查是否可以提交offset，如果可以，就会提交。</p><p>自动提交存在的问题：</p><blockquote><ul><li>重复消费：消费者拉取了一批消息x+1～x+5，消费到x+3的时候，自动提交了一次offset，这一批消息消费完了，但是拉取消息的时候没有提交offset（条件不满足，还不可以自动提交），然后消费者继续消费，消费到x+7的时候，消费者崩溃了，就需要重新从x+3的offset处开始消费，就会导致重复消费。可以减小自动提交的时间窗口。</li><li>消息丢失：异步拉取消息，并发消费这种情况下会导致消息丢失。比如有一个异步线程一直在拉取消息，然后保存在本地，然后有两个线程并发的消费消息，线程A消费x+1～x+5的batch，线程B消费x+6～x+10的batch，消费者自动提交了x+8的offset，但是线程A才消费到了x+3，这是线程A发生了异常，重新消费的时候，就会从x+6的位置开始消费，x+3～x+5的消息就会丢失，而且x+6～x+10的消息会被重复消费。</li></ul></blockquote><p>kafka可以手动提交偏移量，需要将配置<code>enable.auto.commit</code>关闭，然后使用<code>commitSync()</code>方法提交offset。</p><p>一个示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (isRunning.get()) &#123;</span><br><span class="line">ConsumerRecords&lt;String, String&gt; records= consumer.poll(<span class="number">1000</span>);</span><br><span class="line">  <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line"><span class="comment">//do some logical processing .</span></span><br><span class="line">&#125;</span><br><span class="line">  consumer.commitSync();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="控制消费"><a class="markdownIt-Anchor" href="#控制消费"></a> 控制消费</h1><p>KafkaConsumer可以使用pause方法暂停消费，使用resume方法恢复消费：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">pause</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">resume</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br></pre></td></tr></table></figure><p>关闭客户端：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">(Duration timeout)</span></span><br></pre></td></tr></table></figure><h1 id="指定消费位移"><a class="markdownIt-Anchor" href="#指定消费位移"></a> 指定消费位移</h1><p>当一个新的消费组建立的时候，或订阅一个新的tpoic的时候，或当__consumer_offsets主题中关于这个消费组的偏移量消息过期后，没有可以查找的offset，这时会根据消费者的<code>auto.offset.reset</code>配置来决定从什么地方开始消费：</p><blockquote><ul><li>latest：默认值，从下一条写入的消息开始消费</li><li>earliest：从起始处开始消费</li><li>none：抛出NoOffsetForPartitionException异常</li></ul></blockquote><p>kafka还可以通过seek()方法，更细粒度的从指定的位置开始消费。seek()只能重置分配到分区的消费者的位置，所以在重置之前，还得先poll()一次。</p><p>kafka还提供了两个快速seek的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">seekToBeginning</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">seekToEnd</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br></pre></td></tr></table></figure><p>另外可以通过offsetsForTimes方法获取指定时间的offset：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Map&lt;TopicPartition, OffsetAndTimestamp&gt; <span class="title function_">offsetsForTimes</span><span class="params">(Map&lt;TopicPartition, Long&gt; timestampsToSearch)</span></span><br></pre></td></tr></table></figure><p>kafka有再均衡监听器ConsumerRebalanceListener，可以在再均衡之前和重新分配分区之后做一些操作，如在再均衡之前提交当前的offset</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ConsumerRebalanceListener</span> &#123;</span><br><span class="line">  <span class="comment">//再均衡之前调用</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; var1)</span>;</span><br><span class="line"><span class="comment">//重新分配分区之后调用</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; var1)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="消费者拦截器"><a class="markdownIt-Anchor" href="#消费者拦截器"></a> 消费者拦截器</h1><p>消费者拦截器可以在消费消息或者提交偏移量的时候做一些操作，实现ConsumerInterceptor接口即可：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ConsumerInterceptor</span>&lt;K, V&gt; <span class="keyword">extends</span> <span class="title class_">Configurable</span>, AutoCloseable &#123;</span><br><span class="line">  <span class="comment">//消费消息之前会调用这个方法</span></span><br><span class="line">  <span class="comment">//我们可以通过这个方法修改消息，或者做一些过滤等</span></span><br><span class="line">  ConsumerRecords&lt;K, V&gt; <span class="title function_">onConsume</span><span class="params">(ConsumerRecords&lt;K, V&gt; var1)</span>;</span><br><span class="line">  <span class="comment">//提交偏移量之前会调用</span></span><br><span class="line">  <span class="comment">//我们可以通过这个方法获取一些偏移量提交的细节</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">onCommit</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; var1)</span>;</span><br><span class="line">  <span class="comment">//关闭的时候会调用</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;Kafka的消费者负责订阅topic，并从订阅的topic上拉取消息。kafka的消费层还有一个消费组（consumer group），每个consumer都有一个消费组，消息会发给订阅了这个topic的&lt;strong&gt;所有&lt;/strong&gt;消费组，并由消费组中的&lt;strong&gt;一个&lt;/strong&gt;消费者进行消费。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>缓存淘汰算法总结</title>
    <link href="https://eoccc.gitee.io/2022/06/20/%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    <id>https://eoccc.gitee.io/2022/06/20/%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</id>
    <published>2022-06-19T16:00:00.000Z</published>
    <updated>2022-08-01T04:58:42.278Z</updated>
    
    <content type="html"><![CDATA[<p>以前看到过一些缓存淘汰的算法，觉得很是精妙，比如大名鼎鼎的LRU、LFU、FIFO，以及mysql版的LRU，redis的缓存淘汰策略，GuavaCache的缓存淘汰算法，等等。写篇博客总结一下～～</p><span id="more"></span><h1 id="lru"><a class="markdownIt-Anchor" href="#lru"></a> LRU</h1><p>LRU(Least Recently Used)：最近最少使用算法。</p><p>核心思想：这种算法认为最近使用的数据是热点数据，很有可能被再次使用，而最近很少使用的数据是冷门数据，很有可能不再使用。当缓存容量满了的时候，优先淘汰最近最少使用的数据。</p><p>缓存满的状态下：</p><blockquote><ol><li>读取一条缓存，将更新这条缓存的使用时间</li><li>插入一条缓存，将移除时间最远的一条缓存</li></ol></blockquote><h2 id="lru实现"><a class="markdownIt-Anchor" href="#lru实现"></a> LRU实现</h2><p>LRU可以使用LinkedHashMap实现，从而达到O(1)的查询复杂度和更新复杂度。Hash实现O(1)的查询复杂度，链表维护缓存的新鲜度，靠近链表头部的数据是冷门数据，靠近链表尾部的数据是热点数据。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h4a9md6paaj20su0ay0tk.jpg" alt="image-20220713094354095" style="zoom:50%;"><p><em>LinkedHashMap提供了accessOrder选项，设置为true的时，访问node会将node移动到链表尾部，设置为false时会将插入的node放在链表尾部。</em></p><p><em>LinkedHashMap重写了HashMap的newNode方法，put的时候会将新创建的node放到node的尾部。</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Node&lt;K,V&gt; <span class="title function_">newNode</span><span class="params">(<span class="type">int</span> hash, K key, V value, Node&lt;K,V&gt; e)</span> &#123;</span><br><span class="line">    LinkedHashMap.Entry&lt;K,V&gt; p =</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">LinkedHashMap</span>.Entry&lt;&gt;(hash, key, value, e);</span><br><span class="line">    linkNodeLast(p);</span><br><span class="line">    <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="lru查询"><a class="markdownIt-Anchor" href="#lru查询"></a> LRU查询</h3><p>当缓存中不包含查询的key时，返回空。</p><p>当查询到数据时，需要将缓存移动到链表的尾部。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h4a9m9z2lqj20tg0bewfg.jpg" alt="image-20220713094854303" style="zoom:50%;"><h3 id="lru更新"><a class="markdownIt-Anchor" href="#lru更新"></a> LRU更新</h3><p>缓存容量未满时：</p><ul><li>缓存中不包含key，直接在链表的尾部插入新的缓存</li><li>缓存中包含key，更新缓存的value，并移动到链表的尾部</li></ul><p>缓存容量满时：</p><ul><li>缓存中不包含key，移除链表头部的数据，然后在链表的尾部插入新的数据</li><li>缓存中包含key，更新缓存的value，并移动到链表的尾部</li></ul><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h4a9m9moz2j20tg0bewfg.jpg" alt="image-20220713095155195" style="zoom:50%;"><h1 id="lfu"><a class="markdownIt-Anchor" href="#lfu"></a> LFU</h1><p>LFU(Least Frequently Used)：最近最不常用算法，根据数据的历史访问频率来淘汰数据。</p><p>核心思想：最近使用频率高的数据很大概率将会再次被使用，而最近使用频率低的数据很大概率不会再使用。淘汰使用频率最小的数据。</p><h2 id="lfu实现"><a class="markdownIt-Anchor" href="#lfu实现"></a> LFU实现</h2><p>LFU也使用hash+链表的实现，同样可以基于LinkedHashMap实现，但是要重写get方法。</p><h3 id="lfu查找"><a class="markdownIt-Anchor" href="#lfu查找"></a> LFU查找</h3><p>在LFU中查找并访问一条数据后，会：</p><blockquote><ol><li>将这个node的访问频率加1</li><li>将这个node移动到相同频率的node的前面</li></ol></blockquote><p>如：A(10)-&gt;B(9)-&gt;C(9)-&gt;D(8)</p><p>当D被访问后，会变成：A(10)-&gt;D(9)-&gt;B(9)-&gt;C(9)</p><h3 id="lfu插入"><a class="markdownIt-Anchor" href="#lfu插入"></a> LFU插入</h3><p>当插入一条缓存时：</p><blockquote><ol><li>如果缓存容量未满，将node放到链表尾部</li><li>如果缓存容量满了，移除链表尾部的一个node，然后将新的node放到链表尾部</li></ol></blockquote><h1 id="arc"><a class="markdownIt-Anchor" href="#arc"></a> ARC</h1><p>ARC(Adaptive Replacement Cache): 自适应缓存替换算法，它结合了LRU与LFU，来获得可用缓存的最佳使用。</p><p>ARC将整个Cache分成四部分：</p><blockquote><ul><li>最近最多使用的缓存链表，LRU链表</li><li>最近最频繁使用的缓存链表，LFU链表</li><li>最近从LRU表中淘汰的缓存链表，ghost LRU链表，只存储key，不存储真正的数据</li><li>最近从LFU表中淘汰的缓存链表，ghost LFU链表，只存储key，不存储真正的数据</li></ul></blockquote><p>初始时，LRU和LFU的空间各占一半，后续会动态适应调整partion的位置。</p><h3 id="arc查找"><a class="markdownIt-Anchor" href="#arc查找"></a> ARC查找</h3><p>先从LRU缓存中查找，如果命中LRU中的缓存，说明这个缓存时访问频率高的缓存，将node移动到LFU缓存中：</p><blockquote><ol><li>如果在LRU链表中查找到缓存，将这个node移动到LFU链表中。<ul><li>如果LFU链表没满，直接追加到尾部</li><li>如果LFU链表满了，将LFU尾部的node的key移动到ghost LFU链表中，再将新的node追加进去</li><li>ghost LFU链表按照LFU算法进行淘汰</li></ul></li><li>如果在LRU链表中查找到缓存，从LFU中查找</li><li>如果LRU缓存和LFU缓存都没有查找到，从磁盘加载数据<ul><li>如果缓存的key存在与ghost LRU中，则将LRU链表的长度加1，LFU链表的长度减1，将缓存插入到LRU链表中</li><li>如果缓存的key存在与ghost LFU中，则将LFU链表的长度加1，LRU链表的长度减1，将缓存插入到LFU链表中</li></ul></li></ol></blockquote><h3 id="arc插入"><a class="markdownIt-Anchor" href="#arc插入"></a> ARC插入</h3><p>任何缓存的插入都要先插入到LRU缓存中：</p><blockquote><ol><li><p>如果LRU缓存没有满，直接将缓存追加到LRU缓存的尾部</p></li><li><p>如果LRU缓存满了：</p><ul><li><p>将LRU缓存的头部节点移动到ghost LRU中</p></li><li><p>将新的缓存插入到LRU的尾部</p></li><li><p>ghost LRU按照LRU算法进行淘汰</p></li></ul></li></ol></blockquote><h1 id="w-tinylfu"><a class="markdownIt-Anchor" href="#w-tinylfu"></a> W-TinyLFU</h1><p>W-TinyLFU（Window Tiny Least Frequently Used）是对LFU的的优化和加强。</p><p>W-TinyLFU算法分为三个区域，WindowLRU区域、TinyLFU区域、SLRU-主Cache区域：</p><blockquote><ol><li><p>缓存插入时，先进入WindowLRU区</p></li><li><p>WindowLRU区淘汰的数据进入TinyLFU区</p><p>被WindowLRU区淘汰，说明这个数据不是最近需要访问的数据，但是有可能其访问频率很高，进入TinyLFU区</p></li><li><p>TinyLFU区满了以后，将频率最高的数据移动到SLRU区</p></li><li><p>SLRU区满了以后，将淘汰的数据重新放到TinyLFU区</p></li></ol></blockquote><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h4bii54r6ij21ia0nywgr.jpg" alt="img" style="zoom:35%;"><p>另外，LFU通常使用一个map来保存key的访问频率，由于使用map，就会产生hash冲突。caffeine使用了Count-Min Sketch算法存储访问频率。</p><p>Count-Min Sketch算法类似于布隆过滤器，采用4个hash函数进行hash计算，取得四个位置的频率后，取最小值。另外，Count-Min Sketch算法使用四个数组来保存频率。</p><p><img src="/.io//34d432e4f2cd21c4ef18c76074940f81-20220718234745930.png" alt="img"></p><p>但是存在一个问题，如果一个访问频率超级高的数据，突然没有用了，会一直在SLRU区和TinyLFU区中倒腾，就是不能被淘汰，因此caffeine还提供了三种驱逐策略：</p><blockquote><ol><li><p>基于大小：</p><p>可以使用Caffeine.maximumSize(long)方法来指定缓存的最大容量。当缓存超出这个容量的时候，会使用<a href="https://github.com/ben-manes/caffeine/wiki/Efficiency">Window TinyLfu策略</a>来删除缓存。</p></li><li><p>基于时间：</p><ul><li>expireAfterAccess(long, TimeUnit)：在最后一次访问或者写入后开始计时，在指定的时间后过期。</li><li>expireAfterWrite(long, TimeUnit)： 在最后一次写入缓存后开始计时，在指定的时间后过期。</li><li>expireAfter(Expiry)： 自定义策略，过期时间由Expiry实现独自计算。</li></ul></li><li><p>基于引用：没有引用指向数据时，才会驱逐缓存。</p></li></ol></blockquote><p>**一点想法：**对于某些缓存在一定时间内访问的频率很高，积攒了很高的访问频率，导致这些缓存长期存在而不能被淘汰，可以定时对缓存的使用频率进行平滑处理，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">newFrequency = h(oldFrequency) </span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;以前看到过一些缓存淘汰的算法，觉得很是精妙，比如大名鼎鼎的LRU、LFU、FIFO，以及mysql版的LRU，redis的缓存淘汰策略，GuavaCache的缓存淘汰算法，等等。写篇博客总结一下～～&lt;/p&gt;</summary>
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kafka生产者</title>
    <link href="https://eoccc.gitee.io/2022/06/19/kafka%E7%94%9F%E4%BA%A7%E8%80%85/"/>
    <id>https://eoccc.gitee.io/2022/06/19/kafka%E7%94%9F%E4%BA%A7%E8%80%85/</id>
    <published>2022-06-19T14:52:41.000Z</published>
    <updated>2022-08-01T12:22:44.144Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka的生产者发送数据时，先将数据缓存到记录收集器RecordAccumulator中，再由发送线程Sender将消息批量地发送给服务端。</p><span id="more"></span><p>Kafka生产者的客户端是KafkaProducer。发送消息的入口是KafkaProducer.send，提供了同步和异步的方式，异步的方式支持回调功能：</p><blockquote><p>同步：send(ProducerRecord&lt;K, V&gt; record)</p><p>异步：send(ProducerRecord&lt;K, V&gt; record, Callback callback)</p></blockquote><img src="/.io//image-20220731211734632.png" alt="image-20220731211734632" style="zoom:45%;"><h1 id="序列化"><a class="markdownIt-Anchor" href="#序列化"></a> 序列化</h1><p>Kafka在发送消息之前，会先进行序列化，key和value可以使用不同的序列化器：</p><blockquote><ul><li>key的序列化器通过<code>key.serializer</code>配置，默认使用JsonSerializer</li><li>key的序列化器通过<code>value.serializer</code>配置，默认使用JsonSerializer</li></ul></blockquote><p>JsonSerializer底层使用的是<code>com.fasterxml.jackson.databind.ObjectMapper</code>进行序列化。</p><h1 id="选择分区"><a class="markdownIt-Anchor" href="#选择分区"></a> 选择分区</h1><p>Kafka的消息分为有key和没有key两种，通常情况下是没有key的。针对两种情况，有不同的分区逻辑。</p><p><strong>有key的消息</strong></p><p>对于有key的消息，kafka会根据key进行散列，key相同的消息会发送到相同的分区中。</p><p><strong>没有key的消息</strong></p><p>当消息没有指定key时，如果是第一次向服务端发送消息（这个topic还没有分配过分区），则随机分配一个分区，否则采用轮询的方式分配分区。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes, Cluster cluster)</span> &#123;</span><br><span class="line">  List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">  <span class="type">int</span> <span class="variable">numPartitions</span> <span class="operator">=</span> partitions.size();</span><br><span class="line">  <span class="comment">// 没有key的时候，随机分配分区</span></span><br><span class="line">  <span class="keyword">if</span> (keyBytes == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="comment">// 选择分区</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">nextValue</span> <span class="operator">=</span> nextValue(topic);</span><br><span class="line">    List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">    <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="type">int</span> <span class="variable">part</span> <span class="operator">=</span> Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">      <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">      <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 有key的时候直接根据key的hash值进行散列</span></span><br><span class="line">    <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">    <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="title function_">nextValue</span><span class="params">(String topic)</span> &#123;</span><br><span class="line">  <span class="type">AtomicInteger</span> <span class="variable">counter</span> <span class="operator">=</span> topicCounterMap.get(topic);</span><br><span class="line">  <span class="keyword">if</span> (<span class="literal">null</span> == counter) &#123;</span><br><span class="line">    <span class="comment">// 如果这个topi是第一次推送消息，随机分配一个分区</span></span><br><span class="line">    counter = <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(ThreadLocalRandom.current().nextInt());</span><br><span class="line">    <span class="type">AtomicInteger</span> <span class="variable">currentCounter</span> <span class="operator">=</span> topicCounterMap.putIfAbsent(topic, counter);</span><br><span class="line">    <span class="keyword">if</span> (currentCounter != <span class="literal">null</span>) &#123;</span><br><span class="line">      counter = currentCounter;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 轮询分配分区</span></span><br><span class="line">  <span class="keyword">return</span> counter.getAndIncrement();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>直接指定分区</strong></p><p>Kafka支持直接指定分区，可以在创建ProducerRecord的时候，直接指定分区。ProducerRecord提供了多个指定分区的构造方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(ProducerRecord&lt;K, V&gt; record, <span class="type">byte</span>[] serializedKey, <span class="type">byte</span>[] serializedValue, Cluster cluster)</span> &#123;</span><br><span class="line">  <span class="type">Integer</span> <span class="variable">partition</span> <span class="operator">=</span> record.partition();</span><br><span class="line">  <span class="comment">// 优先使用指定的分区</span></span><br><span class="line">  <span class="keyword">return</span> partition != <span class="literal">null</span> ?</span><br><span class="line">    partition :</span><br><span class="line">  partitioner.partition(</span><br><span class="line">    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>**注意：**分配分区的时候，会过滤掉不健康的分区。</p><p>kafka节点健康的标准：</p><ol><li>存在于ISR集合中（保持正常的同步）</li><li>于zookeeper保持心跳（健康检查）</li></ol><h1 id="客户端消息收集器"><a class="markdownIt-Anchor" href="#客户端消息收集器"></a> 客户端消息收集器</h1><p>Kafka的生产者发送数据时，先将数据缓存到记录收集器RecordAccumulator中，再由发送线程Sender将消息批量地发送给服务端。</p><p>每个分区都有一个双端队列来缓存客户端的消息，队列中的每个元素是一个批记录（ProducerBatch），如果一个批记录满了，就会创建一个新的批记录，并将已经满的批记录交给sender线程发送到服务端。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RecordAccumulator.<span class="type">RecordAppendResult</span> <span class="variable">result</span> <span class="operator">=</span> accumulator.append(tp, timestamp, serializedKey,</span><br><span class="line">                    serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line"><span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">  <span class="comment">// 如果批记录满了，唤醒sender线程</span></span><br><span class="line">  <span class="built_in">this</span>.sender.wakeup();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>批记录的大小通过<code>batch.size</code>来配置，默认是16kb。如果一条消息的大小超过了16kb，会创建一个能够容纳这条消息的批记录。</p><p>另外，如果一个批记录很长时间没有满，sender线程会定时的将批记录发送给服务端，避免过长的延时。延时通过<code>linger.ms</code>来配置，默认是0ms，即有消息就会马上发送到服务端。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h4qf68kkg6j20zu0bi0uy.jpg" alt="image-20220727101124764" style="zoom:50%;"><h1 id="客户端消息发送线程"><a class="markdownIt-Anchor" href="#客户端消息发送线程"></a> 客户端消息发送线程</h1><p>Kafka发送消息时，为了减少网络的开销，会将属于一个节点的所有partation的消息放在一个批次，同时进行发送。如果我们有两台服务器，topic有6个partation，每台服务器有3个partation，如果迭代每个partation的批记录，直接发送到主副本节点，则会有6次请求；如果把属于同一个节点的所有partation放在一起发送，就只会有2次请求。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h4qf7366v4j20jg0ciabe.jpg" alt="image-20220727203032416" style="zoom:50%;"><p>消息发送线程发送消息的步骤：</p><blockquote><ol><li>获取可以发送的批记录（每个批记录属于一个partation）</li><li>遍历每个批记录，获取每个批记录对应的主副本节点：nodeId</li><li>将所有的批记录以nodeId为key，group成一个map：modeId -&gt; List<ProducerBatch></ProducerBatch></li><li>发送消息到每个主副本节点</li></ol></blockquote><p>客户端发送完消息后，会执行<code>KafkaClient#poll</code>方法，执行回调方法以及一些后续的处理。回调方法时保存在ClientRequest中的，为了在收到服务端返回后能够执行回调方法，发送线程会保存目标节点到客户端请求的映射关系。</p><ul><li><p>**不需要响应的流程 ：**开始发送请求→添加客户端请求到队列→发送请求→请求发送成功→从 队列中删除发送请求→构造客户端响应。</p></li><li><p>**需要晌应的流程：**开始发送请求→添加客户端请求到队列→发送请求→请求发送成功→等待 接收响应→接收响应→接收到完整的响应→从队列中删除客户端请求→构造客户端响应。</p></li></ul><p>整体流程：</p><blockquote><ol><li>KafkaProducer将消息存到消息收集器RecordAccumulator中</li><li>Sender从RecordAccumulator获取消息</li><li>Sender将需要发送的批记录根据目标节点进行分类</li><li>Sender创建ClientRequest</li><li>Sender调用KafkaClient.send方法发送消息（具体实现是NetworkClient）</li><li>NetworkClient调用Selector.send</li><li>Selector创建KafkaChanel，并将请求写入通道</li><li>Sender调用KafkaClient.poll方法触发KafkaChanel真正执行发送，并执行回调方法</li></ol></blockquote><h1 id="生产者拦截器"><a class="markdownIt-Anchor" href="#生产者拦截器"></a> 生产者拦截器</h1><p>生产者拦截器既可以用来在消息发送前做一些准备工作， 比如按照某个规则过滤不符合要 求的消息、修改消息的内容等， 也可以用来在发送回调逻辑前做一些定制化的需求，比如统计 类工作。</p><p>使用生产者拦截器，只需要实现Producerlnterceptor，然后配置<code>interceptor.classes </code>即可，包含三个方法：</p><ol><li>onSend()方法：在将消息序列化和计算分区之前会调用，对消息进行相应 的定制化操作；</li><li>onAcknowledgement()方法：在消息被应答( Acknowledgement)之前或消息发送失败时调用，在callback之前。这个方法在producer的I/O线程中，所以逻辑应该尽量简单，否则会影响消息的发送。</li><li>close()方法：在关闭拦截器时执行一些资源的清理工作。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ProducerInterceptor</span>&lt;K, V&gt; <span class="keyword">extends</span> <span class="title class_">Configurable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> ProducerRecord&lt;K, V&gt; <span class="title function_">onSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="重要的消费者参数"><a class="markdownIt-Anchor" href="#重要的消费者参数"></a> 重要的消费者参数</h1><ol><li><p>acks</p><blockquote><ul><li>acks=1。默认值。生产者需要收到服务端的响应才算发送消息成功。<em>如果服务端leader收到数据，但是follower还没有同步数据，此时leader副本崩溃，会丢失消息。如果发生leader选举，会返回一个错误消息。</em></li><li>acks=0。生产者发送消息之后不需要等待服务端响应。</li><li>acks=-1或acks=all。生产者发送消息之后，需要等待ISR中所有副本都成功写入消息之后，才能收到服务端的成功响应。<em>ISR中只有一个副本时，还是会丢失消息</em></li></ul></blockquote></li><li><p>max.request.size</p><blockquote><p>生产者客户端能发送消息的最大值，默认1MB。修改这个参数的时候还需要修改broker<code>message.max .bytes</code>参数，比如生产者的<code>max.request.size</code>配置成20，但是broker的<code>message.max .bytes</code>配置成10，此时发送了一个15B的消息，服务端就接收不了。</p></blockquote></li><li><p><a href="http://xn--retriesretry-4l2u.backoff.ms">retries和retry.backoff.ms</a></p><blockquote><ul><li><code>retries</code>用来配置生产者的重试次数，默认为0，即发生异常时不重试。如果重试的次数超过配置的次数，仍然失败，就会返回异常</li><li><code>retry.backoff.ms</code>用来配置两次重试之间的时间间隔，默认为100。</li></ul></blockquote><p>Kafka的同一个topic中的消息时有序的，生产者会按照发送的顺序发送给服务端，消费者也可以按照同样的顺序进行消费。如果配置了重试，而且配置的发送消息的并发数大于1（max.in.flight.requests.per .connection），此时第一批消息写入失败，而第二批消息写入成功，就会导致消息的顺序不一致。</p></li><li><p>batch.size</p><blockquote><p>生产者客户端发送消息，一个批次的大小，一个批次满了以后，就会发送到服务端。</p></blockquote></li><li><p><a href="http://linger.ms">linger.ms</a></p><blockquote><p>生产者客户端等待发送一批消息的最长时间，默认为0。即有消息就会发送到服务端。</p></blockquote></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;Kafka的生产者发送数据时，先将数据缓存到记录收集器RecordAccumulator中，再由发送线程Sender将消息批量地发送给服务端。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>深拷贝和浅拷贝工具</title>
    <link href="https://eoccc.gitee.io/2022/06/14/%E6%B7%B1%E6%8B%B7%E8%B4%9D%E5%92%8C%E6%B5%85%E6%8B%B7%E8%B4%9D%E5%B7%A5%E5%85%B7/"/>
    <id>https://eoccc.gitee.io/2022/06/14/%E6%B7%B1%E6%8B%B7%E8%B4%9D%E5%92%8C%E6%B5%85%E6%8B%B7%E8%B4%9D%E5%B7%A5%E5%85%B7/</id>
    <published>2022-06-14T07:10:35.000Z</published>
    <updated>2022-08-01T04:58:42.278Z</updated>
    
    <content type="html"><![CDATA[<p>前几天写代码的时候，需要拷贝对象，就使用了<code>org.apache.commons.beanutils.BeanUtils</code>的<code>BeanUtils.copyProperties(Object dest, Object orig)</code>拷贝对象，后面又修改了新对象的属性，就导致原对象也被修改了，仔细一研究才发现这个工具只是进行了浅拷贝。索性整理一下现在比较常用的一些深拷贝和浅拷贝工具。</p><span id="more"></span><h2 id="深拷贝"><a class="markdownIt-Anchor" href="#深拷贝"></a> 深拷贝</h2><h3 id="1-orika的mapperfactory"><a class="markdownIt-Anchor" href="#1-orika的mapperfactory"></a> 1. Orika的MapperFactory</h3><p>Orika底层采用了javassist类库生成Bean映射的字节码，之后直接加载执行生成的字节码文件，因此在速度上比使用反射进行赋值会快很多。<strong>线程安全，可以使用单例。推荐！</strong></p><p>首先引入依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>ma.glasnost.orika<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>orika-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>可以拷贝单个对象，也可以拷贝列表，这里只介绍单个对象的拷贝：</p><ul><li><p>直接克隆对象</p><p>克隆的对象可以不同，深拷贝两个对象相同的属性，跳过不同的属性。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">orikaClone</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">MapperFactory</span> <span class="variable">mapperFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMapperFactory</span>.Builder().build();</span><br><span class="line">  <span class="type">MapperFacade</span> <span class="variable">mapperFacade</span> <span class="operator">=</span> mapperFactory.getMapperFacade();</span><br><span class="line"></span><br><span class="line">  <span class="type">DemoObj</span> <span class="variable">fromObj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DemoObj</span>();</span><br><span class="line">  fromObj.setStr(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">  fromObj.setList(Lists.newArrayList(<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>));</span><br><span class="line">  <span class="type">DemoObj</span> <span class="variable">toObj</span> <span class="operator">=</span> mapperFacade.map(fromObj, DemoObj.class);</span><br><span class="line">  toObj.setStr(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">  toObj.getList().add(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">  System.out.println(JSON.toJSONString(fromObj));</span><br><span class="line">  System.out.println(JSON.toJSONString(toObj));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;],&quot;str&quot;:&quot;a&quot;&#125;</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;],&quot;str&quot;:&quot;b&quot;&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>拷贝对象属性</p><p>克隆的对象可以不同，深拷贝两个对象相同的属性，跳过不同的属性。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">orikaCopy</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">MapperFactory</span> <span class="variable">mapperFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMapperFactory</span>.Builder().build();</span><br><span class="line">  <span class="type">MapperFacade</span> <span class="variable">mapperFacade</span> <span class="operator">=</span> mapperFactory.getMapperFacade();</span><br><span class="line"></span><br><span class="line">  <span class="type">DemoObj</span> <span class="variable">fromObj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DemoObj</span>();</span><br><span class="line">  fromObj.setStr(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">  fromObj.setList(Lists.newArrayList(<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>));</span><br><span class="line">  <span class="type">DemoObj</span> <span class="variable">toObj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DemoObj</span>();</span><br><span class="line">  mapperFacade.map(fromObj, toObj);</span><br><span class="line">  toObj.setStr(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">  toObj.getList().add(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">  System.out.println(JSON.toJSONString(fromObj));</span><br><span class="line">  System.out.println(JSON.toJSONString(toObj));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;],&quot;str&quot;:&quot;a&quot;&#125;</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;],&quot;str&quot;:&quot;b&quot;&#125;</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="dozer的dozerbeanmapper"><a class="markdownIt-Anchor" href="#dozer的dozerbeanmapper"></a> Dozer的DozerBeanMapper</h3><p>dozer是一种JavaBean的映射工具，类似于apache的BeanUtils。但是dozer更强大，它可以灵活的处理复杂类型之间的映射。不但可以进行简单的属性映射、复杂的类型映射、双向映射、递归映射等，并且可以通过XML配置文件进行灵活的配置。 <strong>线程安全，可以使用单例，性能一般。</strong></p><p>引入依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>net.sf.dozer<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>dozer<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.5.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>深拷贝属性，对象可以不同，属性不同时跳过。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">dozerCopy</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">DozerBeanMapper</span> <span class="variable">dozer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DozerBeanMapper</span>();</span><br><span class="line"></span><br><span class="line">  <span class="type">DemoObj</span> <span class="variable">fromObj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DemoObj</span>();</span><br><span class="line">  fromObj.setStr(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">  fromObj.setList(Lists.newArrayList(<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>));</span><br><span class="line">  <span class="type">DemoObj2</span> <span class="variable">toObj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DemoObj2</span>();</span><br><span class="line">  dozer.map(fromObj, toObj);</span><br><span class="line">  toObj.setStr(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">  toObj.getList().add(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">  System.out.println(JSON.toJSONString(fromObj));</span><br><span class="line">  System.out.println(JSON.toJSONString(toObj));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;],&quot;str&quot;:&quot;a&quot;&#125;</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;],&quot;str&quot;:&quot;b&quot;&#125;</span></span><br></pre></td></tr></table></figure><h3 id="利用序列化实现深拷贝"><a class="markdownIt-Anchor" href="#利用序列化实现深拷贝"></a> 利用序列化实现深拷贝</h3><p>利用输入输出流，将旧对象写入到新对象，实现拷贝。<strong>性能低，不推荐。</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">DeepCloneDemo</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line">  String str;</span><br><span class="line">  List&lt;String&gt; list;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> DeepCloneDemo <span class="title function_">deepClone</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">DeepCloneDemo</span> <span class="variable">to</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="type">DeepCloneDemo</span> <span class="variable">from</span> <span class="operator">=</span> <span class="built_in">this</span>;</span><br><span class="line">    <span class="type">PipedOutputStream</span> <span class="variable">out</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PipedOutputStream</span>();</span><br><span class="line">    <span class="type">PipedInputStream</span> <span class="variable">in</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PipedInputStream</span>();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      in.connect(out);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> (<span class="type">ObjectOutputStream</span> <span class="variable">bo</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectOutputStream</span>(out);</span><br><span class="line">         <span class="type">ObjectInputStream</span> <span class="variable">bi</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectInputStream</span>(in);) &#123;</span><br><span class="line">      bo.writeObject(from);</span><br><span class="line">      to = (DeepCloneDemo) bi.readObject();</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> to;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">deepClone</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">DeepCloneDemo</span> <span class="variable">from</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DeepCloneDemo</span>();</span><br><span class="line">  from.setStr(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">  from.setList(Lists.newArrayList(<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>));</span><br><span class="line">  <span class="type">DeepCloneDemo</span> <span class="variable">to</span> <span class="operator">=</span> from.deepClone();</span><br><span class="line">  to.setStr(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">  to.getList().add(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">  System.out.println(JSON.toJSONString(from));</span><br><span class="line">  System.out.println(JSON.toJSONString(to));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;],&quot;str&quot;:&quot;a&quot;&#125;</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;],&quot;str&quot;:&quot;b&quot;&#125;</span></span><br></pre></td></tr></table></figure><h2 id="浅拷贝"><a class="markdownIt-Anchor" href="#浅拷贝"></a> 浅拷贝</h2><h3 id="1-apache的beanutils"><a class="markdownIt-Anchor" href="#1-apache的beanutils"></a> 1. apache的BeanUtils</h3><p>所处的包：<code>org.apache.commons.beanutils.BeanUtils</code></p><p>基于反射拷贝，提供了两个拷贝对象的方法：</p><ul><li><p><code>BeanUtils.cloneBean(final Object bean)</code></p><p>传入一个对象，浅拷贝生成一个新的对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">apacheClone</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">  <span class="type">DemoObj</span> <span class="variable">fromObj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DemoObj</span>();</span><br><span class="line">  fromObj.setS(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">  fromObj.setL(Lists.newArrayList(<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>));</span><br><span class="line">  <span class="type">DemoObj</span> <span class="variable">toObj</span> <span class="operator">=</span> (DemoObj) org.apache.commons.beanutils.BeanUtils.cloneBean(fromObj);</span><br><span class="line">  toObj.setStr(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">  toObj.getList().add(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">  System.out.println(JSON.toJSONString(fromObj));</span><br><span class="line">  System.out.println(JSON.toJSONString(toObj));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;],&quot;str&quot;:&quot;a&quot;&#125;</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;],&quot;str&quot;:&quot;b&quot;&#125;</span></span><br></pre></td></tr></table></figure></li><li><p><code>BeanUtils.copyProperties(final Object dest, final Object orig)</code></p><p>传入两个对象，浅拷贝相同的属性的值。两个对象的类型可以不一样，属性及属性类型相同即可，忽略不同的属性。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">apacheCopy</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">  <span class="type">DemoObj</span> <span class="variable">fromObj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DemoObj</span>();</span><br><span class="line">  fromObj.setS(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">  fromObj.setL(Lists.newArrayList(<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>));</span><br><span class="line">  <span class="type">DemoObj</span> <span class="variable">toObj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DemoObj</span>();</span><br><span class="line">  org.apache.commons.beanutils.BeanUtils.copyProperties(toObj, fromObj);</span><br><span class="line">  toObj.setStr(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">  toObj.getList().add(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">  System.out.println(JSON.toJSONString(fromObj));</span><br><span class="line">  System.out.println(JSON.toJSONString(toObj));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;],&quot;str&quot;:&quot;a&quot;&#125;</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;],&quot;str&quot;:&quot;b&quot;&#125;</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="2-springframework的beanutils"><a class="markdownIt-Anchor" href="#2-springframework的beanutils"></a> 2. springframework的BeanUtils</h3><p>所处的包：<code>org.springframework.beans.BeanUtils</code></p><p>提供了四个拷贝对象的方法，基本原理都一样，只不过是做了一些定制。这里只整理基本的拷贝方法：</p><ul><li><p><code>BeanUtils.copyProperties(Object source, Object target)</code></p><p>功能与apache的相似，需要注意的是，传入对象的顺序刚好相反，原对象在第一个，新对象在第二个</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">springCopy</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">DemoObj</span> <span class="variable">fromObj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DemoObj</span>();</span><br><span class="line">  fromObj.setStr(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">  fromObj.setList(Lists.newArrayList(<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>));</span><br><span class="line">  <span class="type">DemoObj</span> <span class="variable">toObj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DemoObj</span>();</span><br><span class="line">  org.springframework.beans.BeanUtils.copyProperties(fromObj, toObj);</span><br><span class="line">  toObj.setStr(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">  toObj.getList().add(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">  System.out.println(JSON.toJSONString(fromObj));</span><br><span class="line">  System.out.println(JSON.toJSONString(toObj));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;],&quot;str&quot;:&quot;a&quot;&#125;</span></span><br><span class="line"><span class="comment">//&#123;&quot;list&quot;:[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;],&quot;str&quot;:&quot;b&quot;&#125;</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;前几天写代码的时候，需要拷贝对象，就使用了&lt;code&gt;org.apache.commons.beanutils.BeanUtils&lt;/code&gt;的&lt;code&gt;BeanUtils.copyProperties(Object dest, Object orig)&lt;/code&gt;拷贝对象，后面又修改了新对象的属性，就导致原对象也被修改了，仔细一研究才发现这个工具只是进行了浅拷贝。索性整理一下现在比较常用的一些深拷贝和浅拷贝工具。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术笔记" scheme="https://eoccc.gitee.io/tags/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    
    <category term="踩坑" scheme="https://eoccc.gitee.io/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>dubbo优雅停机</title>
    <link href="https://eoccc.gitee.io/2022/05/14/dubbo%E4%BC%98%E9%9B%85%E5%81%9C%E6%9C%BA/"/>
    <id>https://eoccc.gitee.io/2022/05/14/dubbo%E4%BC%98%E9%9B%85%E5%81%9C%E6%9C%BA/</id>
    <published>2022-05-13T16:00:00.000Z</published>
    <updated>2022-08-01T04:58:42.247Z</updated>
    
    <content type="html"><![CDATA[<p>优雅停机是Dubbo的重要特性之一，因为核心业务运行时突然中断可能带来严重的后果。</p><span id="more"></span><p>Dubbo 是通过 JDK 的 ShutdownHook 来完成优雅停机的，所以如果用户使用 <code>kill -9 PID</code> 等强制关闭指令，是不会执行优雅停机的，只有通过 <code>kill PID</code> 时，才会执行。</p><p>Dubbo收到停机的指令后，会进行如下操作：</p><blockquote><ol><li>dubbo收到退出指令</li><li>provider端取消注册中心的元数据</li><li>注册中心将元数据的变更推送给consumer端</li><li>consumer端更新元数据（会移除准备停机的provider元数据）</li><li>providre端发送readonly报文通知consumer端服务不可用</li><li>providre端拒绝新的任务，等待正在执行的任务完成后断开连接</li></ol></blockquote><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3qf3zjlwjj21620igmz4.jpg" alt="image-20220630174211346" style="zoom:40%;"><p>第4步provider端主动发送报文同志consumer端服务下线，是为了避免第3步注册中心通知consumer端导致网络延迟。</p><p><code>DubboShutdownHook</code>在启动dubbo的时候注册到RunTime的hooks中去，源码位于<code>org.apache.dubbo.config.deploy.DefaultApplicationDeployer#registerShutdownHook</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">registerShutdownHook</span><span class="params">()</span> &#123;</span><br><span class="line">dubboShutdownHook.register();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//往下跟dubboShutdownHook.register()</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">register</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (registered.compareAndSet(<span class="literal">false</span>, <span class="literal">true</span>) &amp;&amp; !ignoreListenShutdownHook) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      Runtime.getRuntime().addShutdownHook(<span class="built_in">this</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IllegalStateException e) &#123;</span><br><span class="line">      logger.warn(<span class="string">&quot;register shutdown hook failed: &quot;</span> + e.getMessage());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      logger.warn(<span class="string">&quot;register shutdown hook failed: &quot;</span> + e.getMessage(), e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//继续跟 Runtime.getRuntime().addShutdownHook</span></span><br><span class="line"><span class="comment">//这就到了java层了</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addShutdownHook</span><span class="params">(Thread hook)</span> &#123;</span><br><span class="line">  <span class="type">SecurityManager</span> <span class="variable">sm</span> <span class="operator">=</span> System.getSecurityManager();</span><br><span class="line">  <span class="keyword">if</span> (sm != <span class="literal">null</span>) &#123;</span><br><span class="line">    sm.checkPermission(<span class="keyword">new</span> <span class="title class_">RuntimePermission</span>(<span class="string">&quot;shutdownHooks&quot;</span>));</span><br><span class="line">  &#125;</span><br><span class="line">  ApplicationShutdownHooks.add(hook);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//继续跟 ApplicationShutdownHooks.add</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(Thread hook)</span> &#123;</span><br><span class="line">  <span class="keyword">if</span>(hooks == <span class="literal">null</span>)</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;Shutdown in progress&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (hook.isAlive())</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;Hook already running&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (hooks.containsKey(hook))</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;Hook previously registered&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//塞到了hooks这个map中</span></span><br><span class="line">  hooks.put(hook, hook);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//调用钩子：java.lang.ApplicationShutdownHooks#runHooks</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">runHooks</span><span class="params">()</span> &#123;</span><br><span class="line">  Collection&lt;Thread&gt; threads;</span><br><span class="line">  <span class="keyword">synchronized</span>(ApplicationShutdownHooks.class) &#123;</span><br><span class="line">    threads = hooks.keySet();</span><br><span class="line">    hooks = <span class="literal">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (Thread hook : threads) &#123;</span><br><span class="line">    hook.start();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (Thread hook : threads) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      hook.join();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException x) &#123; &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//最后调用钩子的入口是：java.lang.Runtime#exit</span></span><br></pre></td></tr></table></figure><p><code>DubboShutdownHook</code>都干了些啥呢？核心方法就一个<code>destroy()</code>，其中最重要的是<code>onDestroy()</code>，后续的大致就是移除了一些类加载器、spring容器、扩展类加载器。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">destroy</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (destroyed.compareAndSet(<span class="literal">false</span>, <span class="literal">true</span>)) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line"><span class="comment">//销毁前的操作，非常核心！</span></span><br><span class="line">      onDestroy();</span><br><span class="line">      </span><br><span class="line">      <span class="comment">//后面都是一些销毁容器的操作</span></span><br><span class="line">      HashSet&lt;ClassLoader&gt; copyOfClassLoaders = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;(classLoaders);</span><br><span class="line">      <span class="keyword">for</span> (ClassLoader classLoader : copyOfClassLoaders) &#123;</span><br><span class="line">        removeClassLoader(classLoader);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (beanFactory != <span class="literal">null</span>) &#123;</span><br><span class="line">        beanFactory.destroy();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (extensionDirector != <span class="literal">null</span>) &#123;</span><br><span class="line">        extensionDirector.destroy();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">      LOGGER.error(<span class="string">&quot;Error happened when destroying ScopeModel.&quot;</span>, t);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重点看下<code>org.apache.dubbo.rpc.model.ApplicationModel#onDestroy</code>方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onDestroy</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="comment">// 1. remove from frameworkModel</span></span><br><span class="line">  frameworkModel.removeApplication(<span class="built_in">this</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2. pre-destroy, set stopping</span></span><br><span class="line">  <span class="keyword">if</span> (deployer != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="comment">// destroy registries and unregister services from registries first to notify consumers to stop consuming this instance.</span></span><br><span class="line">    <span class="comment">// 移除注册中心的元数据，以通过注册中心通知consumer停止调用服务，包括销毁服务发现、元数据等</span></span><br><span class="line">    deployer.preDestroy();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 3. Try to destroy protocols to stop this instance from receiving new requests from connections</span></span><br><span class="line">  <span class="comment">// 销毁协议，从而停止接收新的请求</span></span><br><span class="line">  frameworkModel.tryDestroyProtocols();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 4. destroy application resources</span></span><br><span class="line">  <span class="keyword">for</span> (ModuleModel moduleModel : <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(moduleModels)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (moduleModel != internalModule) &#123;</span><br><span class="line">      moduleModel.destroy();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 5. destroy internal module later</span></span><br><span class="line">  internalModule.destroy();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 6. post-destroy, release registry resources</span></span><br><span class="line">  <span class="keyword">if</span> (deployer != <span class="literal">null</span>) &#123;</span><br><span class="line">    deployer.postDestroy();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 7. destroy other resources (e.g. ZookeeperTransporter )</span></span><br><span class="line">  notifyDestroy();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (environment != <span class="literal">null</span>) &#123;</span><br><span class="line">    environment.destroy();</span><br><span class="line">    environment = <span class="literal">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (configManager != <span class="literal">null</span>) &#123;</span><br><span class="line">    configManager.destroy();</span><br><span class="line">    configManager = <span class="literal">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (serviceRepository != <span class="literal">null</span>) &#123;</span><br><span class="line">    serviceRepository.destroy();</span><br><span class="line">    serviceRepository = <span class="literal">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 8. destroy framework if none application</span></span><br><span class="line">  frameworkModel.tryDestroy();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;优雅停机是Dubbo的重要特性之一，因为核心业务运行时突然中断可能带来严重的后果。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="dubbo" scheme="https://eoccc.gitee.io/tags/dubbo/"/>
    
  </entry>
  
  <entry>
    <title>深入浅出对比数组和链表</title>
    <link href="https://eoccc.gitee.io/2022/05/07/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AF%B9%E6%AF%94%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8/"/>
    <id>https://eoccc.gitee.io/2022/05/07/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AF%B9%E6%AF%94%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8/</id>
    <published>2022-05-07T08:25:19.000Z</published>
    <updated>2022-08-01T04:58:42.278Z</updated>
    
    <content type="html"><![CDATA[<p>数组和链表是我们日常编程中非常常用的两种数据结构，那么它们的性能表现如何，本文由浅入深对此进行一些分析。</p><span id="more"></span><h2 id="内存分配"><a class="markdownIt-Anchor" href="#内存分配"></a> 内存分配</h2><p>在开始分析之前，我们先来了解一下数组和链表在内存中的存储方式。</p><p>数组在内存中是存储在一个连续的空间。对于基础数据类型，数组的元素存储的是数据本身，对于引用类型，元素存储的是引用地址（一个Integer值）。在为数组由两部分组成：数组的元数据（16字节）、数组的元素（基本数据类型为元素本身大小，引用类型为引用地址–8个字节）。</p><p>链表在内存中是分布在非连续的空间中的，通过地址指针指向下一个或上一个节点。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h35mtu68wqj20qy0hi403.jpg" alt="image-20220610090434150" style="zoom:50%;"><p>在64位jvm中，内存页为内存分配的最小单位，每个内存页的大小为8个字节。因此，在为对象分配内存的时候，必须为8的倍数，如果元素占用的内存小于8个字节，也会分配8个字节。如：</p><blockquote><ol><li><code>new int[1]</code>的大小为24个字节，即元素int的4个字节 + 4个空白字节（因为一个内存页为8个字节，） + 数组内部属性16个字节；</li><li><code>new long[1]</code>的大小为24个字节，即元素long的8个字节 + 数组内部属性16个字节；</li><li><code>new Node[1]</code>将会分配24个字节，即引用地址Integer的4个字节 + 4个空白字节 + 数组内部属性16个字节</li></ol></blockquote><p>接下来我们进行测试：我们分别对boolean、int、long、Node对象新建容量从1～10的数组，然后分别统计每个数组占用内存的大小。</p><p>这里我使用jol的ClassLayout工具获取对象占用的内存大小，引入依赖即可使用：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.openjdk.jol<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jol-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>测试代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> <span class="keyword">throws</span> ParseException &#123;</span><br><span class="line">  System.out.println(<span class="string">&quot;capacity booleanArraySize intArraySize longArraySize nodeArraySize&quot;</span>);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= <span class="number">10</span>; i++) &#123;</span><br><span class="line">    <span class="type">boolean</span>[] booleanArray = <span class="keyword">new</span> <span class="title class_">boolean</span>[i];</span><br><span class="line">    <span class="type">int</span>[] intArray = <span class="keyword">new</span> <span class="title class_">int</span>[i];</span><br><span class="line">    <span class="type">long</span>[] longArray = <span class="keyword">new</span> <span class="title class_">long</span>[i];</span><br><span class="line">    Node[] nodeArray = <span class="keyword">new</span> <span class="title class_">Node</span>[i];</span><br><span class="line">    <span class="type">long</span> <span class="variable">booleanArraySize</span> <span class="operator">=</span> ClassLayout.parseInstance(booleanArray).instanceSize();</span><br><span class="line">    <span class="type">long</span> <span class="variable">intArraySize</span> <span class="operator">=</span> ClassLayout.parseInstance(intArray).instanceSize();</span><br><span class="line">    <span class="type">long</span> <span class="variable">longArraySize</span> <span class="operator">=</span> ClassLayout.parseInstance(longArray).instanceSize();</span><br><span class="line">    <span class="type">long</span> <span class="variable">nodeArraySize</span> <span class="operator">=</span> ClassLayout.parseInstance(nodeArray).instanceSize();</span><br><span class="line">    System.out.printf(<span class="string">&quot;%d %d %d %d %d%n&quot;</span>, i, booleanArraySize, intArraySize, longArraySize, nodeArraySize);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> Node pre;</span><br><span class="line">  <span class="keyword">private</span> Node next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>统计的结果如下表所示。如boolean数组，初始大小为24字节，除去数组自身的16字节以外，还有8个字节可以用来保存元素，boolean占用1个字节，也就是说还可以存8个boolean元素，正如实验结果一样，数组容量为1～8的时候，占用内存为24字节，当数组容量为9的时候变成32字节（24+8，即增加了一个内存页）。</p><table><thead><tr><th>capacity</th><th>booleanArraySize</th><th>intArraySize</th><th>longArraySize</th><th>nodeArraySize</th></tr></thead><tbody><tr><td>1</td><td>24</td><td>24</td><td>24</td><td>24</td></tr><tr><td>2</td><td>24</td><td>24</td><td>32</td><td>24</td></tr><tr><td>3</td><td>24</td><td>32</td><td>40</td><td>32</td></tr><tr><td>4</td><td>24</td><td>32</td><td>48</td><td>32</td></tr><tr><td>5</td><td>24</td><td>40</td><td>56</td><td>40</td></tr><tr><td>6</td><td>24</td><td>40</td><td>64</td><td>40</td></tr><tr><td>7</td><td>24</td><td>48</td><td>72</td><td>48</td></tr><tr><td>8</td><td>24</td><td>48</td><td>80</td><td>48</td></tr><tr><td>9</td><td>32</td><td>56</td><td>88</td><td>56</td></tr><tr><td>10</td><td>32</td><td>56</td><td>96</td><td>56</td></tr></tbody></table><h2 id="添加"><a class="markdownIt-Anchor" href="#添加"></a> 添加</h2><p><strong>数组插入</strong></p><p>对于数组来说，在末尾添加一个元素的流程大致是这样的：</p><blockquote><ol><li>找到数组在内存中的起始地址；</li><li>根据下标计算出需要插入元素的位置的地址；</li><li>如果是基本数据类型，直接将元素写入到内存中；</li><li>如果是引用类型，将元素的地址写入到需要添加元素的内存地址</li></ol></blockquote><p>如下图是一个容量为3的int数组的示例，数组中已经保存了两个元素，由于是基本类型，没有赋值的元素（即第三个元素）会初始化为0。数组在内存中的起始地址为1000，metadate占16字节，因此第一个元素的起始位置是1016，由于内存页为8个字节，保存3个元素需要两个内存页，因此数组的结束位置为1032。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h35mtp6f6ej20iy066q32.jpg" alt="image-20220609103236268" style="zoom:67%;"><p>如果要在第三个位置添加一个元素，即如下操作：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array[<span class="number">2</span>] = <span class="number">3</span>;</span><br></pre></td></tr></table></figure><p>那么会进行如下操作：</p><blockquote><ol><li>找到数组在内存中的位置1000</li><li>计算出需要插入的元素的位置：1000 + 16 + 4 * 2 = 1024</li><li>判断地址是否超出数组分配的内存地址范围，超出则说明数组越界，抛出<em>IndexOutOfBoundsException</em></li><li>将需要插入的值写入到指定的内存位置</li></ol></blockquote><p><strong>链表添加元素</strong></p><p>链表添加元素就比较简单，直接把Node的引用地址赋值给末尾Node的next即可：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail.next = <span class="keyword">new</span> <span class="title class_">Node</span>();</span><br></pre></td></tr></table></figure><p><strong>性能分析</strong></p><p>数组追加元素比链表追加元素要多两个操作：计算元素的位置、判断是否越界。因此我猜测链表添加元素的速度要快一些。测试一下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testAdd</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line">    <span class="type">int</span> <span class="variable">maxCount</span> <span class="operator">=</span> <span class="number">1000000</span>;</span><br><span class="line">    System.out.println(<span class="string">&quot;count    array add cost&quot;</span>);</span><br><span class="line">    <span class="keyword">while</span> (count &lt; maxCount) &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">        arrayAdd(count);</span><br><span class="line">        System.out.println(count + <span class="string">&quot;    &quot;</span> + (System.nanoTime() - start));</span><br><span class="line">        count = count &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;count    link add cost&quot;</span>);</span><br><span class="line">    count = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">while</span> (count &lt; maxCount) &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">        linkAdd(count);</span><br><span class="line">        System.out.println(count + <span class="string">&quot;    &quot;</span> + (System.nanoTime() - start));</span><br><span class="line">        count = count &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> Node[] arrayAdd(<span class="type">int</span> count) &#123;</span><br><span class="line">    Node[] nodes = <span class="keyword">new</span> <span class="title class_">Node</span>[count];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; count - <span class="number">1</span>; i++) &#123;</span><br><span class="line">        nodes[i] = <span class="keyword">new</span> <span class="title class_">Node</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nodes;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> Node <span class="title function_">linkAdd</span><span class="params">(<span class="type">int</span> count)</span> &#123;</span><br><span class="line">    <span class="type">Node</span> <span class="variable">head</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Node</span>();</span><br><span class="line">    <span class="type">Node</span> <span class="variable">tmp</span> <span class="operator">=</span> head;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; count - <span class="number">1</span>; i++) &#123;</span><br><span class="line">        tmp.next = <span class="keyword">new</span> <span class="title class_">Node</span>();</span><br><span class="line">        tmp = tmp.next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> head;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>分析一下数据，如下图，横坐标是元素的数量，纵坐标是耗时（纳秒）。可以看到，在一定数量范围内，数组追加元素的速度比链表要快一些，但是超过一定的数据量后，链表要快一些。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h35mtm8h8qj20qq0g2jss.jpg" alt="image-20220610092601983" style="zoom:50%;"><p>图中add的耗时存在一个先增后降的过程，这里可能涉及到jvm和操作系统更底层的实现逻辑了，暂时没有分析出原因。</p><h2 id="插入"><a class="markdownIt-Anchor" href="#插入"></a> 插入</h2><p><strong>数组插入</strong></p><p>数组的插入是一个比较重的操作，大致流程如下：</p><blockquote><ol><li>根据下标定位到需要插入的内存地址（通过偏移量计算）</li><li>将后面的元素往后移动一个位置（涉及到大块的内存移动）</li><li>将新的元素写到指定的位置</li></ol></blockquote><p>数组插入代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="title function_">arrayInsert</span><span class="params">(<span class="type">int</span> index, <span class="type">int</span> currSize, Node[] nodes, Node node)</span> &#123;</span><br><span class="line">    <span class="comment">//先把后面的元素后移一位</span></span><br><span class="line">    <span class="keyword">while</span> (currSize &gt; index) &#123;</span><br><span class="line">        nodes[currSize] = nodes[currSize - <span class="number">1</span>];</span><br><span class="line">        currSize--;</span><br><span class="line">    &#125;</span><br><span class="line">    nodes[index] = node;</span><br><span class="line">    <span class="keyword">return</span> currSize+<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>链表插入</strong></p><p>链表的插入比较简单，只需要修改链表的指针即可，而且只需要修改2个节点的指针（双向链表需要修改3个节点的指针）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//单向链表插入</span></span><br><span class="line"><span class="type">Node</span> <span class="variable">next</span> <span class="operator">=</span> pre.next;</span><br><span class="line">pre.next = node;</span><br><span class="line">node.next = next;</span><br></pre></td></tr></table></figure><p>但是如果我们只知道要插入到第几个，还得先通过遍历定位出插入节点的位置：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">linkInsert</span><span class="params">(<span class="type">int</span> index, Node head, Node node)</span> &#123;</span><br><span class="line">    <span class="type">Node</span> <span class="variable">tmp</span> <span class="operator">=</span> head;</span><br><span class="line">    <span class="comment">//先找到插入的位置</span></span><br><span class="line">    <span class="keyword">while</span> (index &gt; <span class="number">0</span> &amp;&amp; tmp != <span class="literal">null</span>) &#123;</span><br><span class="line">        tmp = tmp.next;</span><br><span class="line">        index--;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//越界了</span></span><br><span class="line">    <span class="keyword">if</span> (index &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">Node</span> <span class="variable">next</span> <span class="operator">=</span> tmp.next;</span><br><span class="line">    tmp.next = node;</span><br><span class="line">    node.next = next;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>性能对比</strong></p><p>链表不涉及内存的移动，只需要定位到插入的位置即可，复杂度为O(index)，因此我猜测链表的插入速度要快一些。我们测试在size/2的位置插入元素：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testInsert</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">size</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line">    <span class="type">int</span> <span class="variable">maxSize</span> <span class="operator">=</span> <span class="number">1000000</span>;</span><br><span class="line">    <span class="type">int</span> <span class="variable">currSize</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">Node</span> <span class="variable">head</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Node</span>();</span><br><span class="line">    Node[] nodes = <span class="keyword">new</span> <span class="title class_">Node</span>[maxSize];</span><br><span class="line">    nodes[<span class="number">0</span>] = head;</span><br><span class="line">    <span class="type">Node</span> <span class="variable">tail</span> <span class="operator">=</span> head;</span><br><span class="line">    tail = addElement(nodes, tail, <span class="number">0</span>, size);</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;count    array insert cost    link insert cost&quot;</span>);</span><br><span class="line">    <span class="keyword">while</span> (size &lt; maxSize) &#123;</span><br><span class="line">        <span class="type">Node</span> <span class="variable">node</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Node</span>();</span><br><span class="line">        <span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> size &gt;&gt; <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">        currSize = arrayInsert(index, currSize, nodes, node);</span><br><span class="line">        System.out.print(size + <span class="string">&quot;    &quot;</span> + (System.nanoTime() - start));</span><br><span class="line"></span><br><span class="line">        start = System.nanoTime();</span><br><span class="line">        linkInsert(index, head, node);</span><br><span class="line">        System.out.println(<span class="string">&quot;    &quot;</span> + (System.nanoTime() - start));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//添加元素</span></span><br><span class="line">        size = size &lt;&lt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (size &lt; maxSize) &#123;</span><br><span class="line">            tail = addElement(nodes, tail, currSize, size);</span><br><span class="line">            currSize++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试结果：</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h35mu1a41yj20qr0g2759.jpg" alt="image-20220611150741041" style="zoom:50%;"><h2 id="删除"><a class="markdownIt-Anchor" href="#删除"></a> 删除</h2><p>删除和插入类似，数组会导致内存块的移动，链表只需要修改节点的指针即可，这里不再赘述。</p><h2 id="遍历"><a class="markdownIt-Anchor" href="#遍历"></a> 遍历</h2><p>数组的遍历需要根据下标，计算出元素的地址，然后取出元素。链表的遍历依次获取元素的地址指针即可。但是由于数组在内存中是顺序保存的，操作系统加载数据的时候，会把缓存页中的数据全都加载到高速缓存，因此数据的遍历速度会比链表快。</p><p>上代码测试分析：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testFor</span><span class="params">()</span> &#123;</span><br><span class="line">    Map&lt;Integer, List&lt;Long&gt;&gt; arrayCostMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">    Map&lt;Integer, List&lt;Long&gt;&gt; linkCostMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">    <span class="type">int</span> <span class="variable">maxSize</span> <span class="operator">=</span> <span class="number">100000</span>;</span><br><span class="line">    <span class="type">int</span> <span class="variable">currSize</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line">    <span class="comment">//为了削弱机器获胜虚拟机导致的误差，跑了10次取平均值</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; <span class="number">10</span>; j++) &#123;</span><br><span class="line">        <span class="keyword">while</span> (currSize &lt; maxSize) &#123;</span><br><span class="line">            Node[] nodeArray = createArray(currSize);</span><br><span class="line">            <span class="type">Node</span> <span class="variable">head</span> <span class="operator">=</span> createLink(nodeArray);</span><br><span class="line"></span><br><span class="line">            <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; currSize; i++) &#123;</span><br><span class="line">                <span class="type">Node</span> <span class="variable">node</span> <span class="operator">=</span> nodeArray[i];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">long</span> <span class="variable">arrayCost</span> <span class="operator">=</span> System.nanoTime() - start;</span><br><span class="line">            List&lt;Long&gt; arrayCostList = arrayCostMap.computeIfAbsent(currSize, k -&gt; <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;());</span><br><span class="line">            arrayCostList.add(arrayCost);</span><br><span class="line"></span><br><span class="line">            start = System.nanoTime();</span><br><span class="line">            <span class="type">Node</span> <span class="variable">tmp</span> <span class="operator">=</span> head;</span><br><span class="line">            <span class="keyword">while</span> (tmp != <span class="literal">null</span>) &#123;</span><br><span class="line">                tmp = tmp.next;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">long</span> <span class="variable">linkCost</span> <span class="operator">=</span> System.nanoTime() - start;</span><br><span class="line">            List&lt;Long&gt; linkCostList = linkCostMap.computeIfAbsent(currSize, k -&gt; <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;());</span><br><span class="line">            linkCostList.add(linkCost);</span><br><span class="line">            currSize = currSize &lt;&lt; <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    currSize = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">while</span> (currSize &lt; maxSize) &#123;</span><br><span class="line">        <span class="type">Double</span> <span class="variable">arrayCost</span> <span class="operator">=</span> arrayCostMap.get(currSize).stream().collect(Collectors.averagingLong(Long::<span class="keyword">new</span>));</span><br><span class="line">        <span class="type">Double</span> <span class="variable">linkCost</span> <span class="operator">=</span> linkCostMap.get(currSize).stream().collect(Collectors.averagingLong(Long::<span class="keyword">new</span>));</span><br><span class="line">        System.out.printf(<span class="string">&quot;%d %s %s%n&quot;</span>, currSize, arrayCost, linkCost);</span><br><span class="line">        currSize = currSize &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> Node[] createArray(<span class="type">int</span> size) &#123;</span><br><span class="line">    Node[] nodeArray = <span class="keyword">new</span> <span class="title class_">Node</span>[size];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">        nodeArray[i] = <span class="keyword">new</span> <span class="title class_">Node</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nodeArray;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> Node <span class="title function_">createLink</span><span class="params">(Node[] nodeArray)</span> &#123;</span><br><span class="line">    <span class="type">Node</span> <span class="variable">head</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Node</span>();</span><br><span class="line">    <span class="type">Node</span> <span class="variable">tmp</span> <span class="operator">=</span> head;</span><br><span class="line">    <span class="keyword">for</span> (Node node : nodeArray) &#123;</span><br><span class="line">        tmp.next = node;</span><br><span class="line">        tmp = tmp.next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> head;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果分析如下图。整体来说，数组的遍历速度比链表快，尤其是在数据量比较大的时候，二者的差距越来越大。不过在前面数组和链表的遍历数组都有波动，猜测跟jvm、操作系统、硬件都有关系，感兴趣的可以和我一起研究。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h35mrm2w95j20k20c2t9b.jpg" alt="image-20220612181316593" style="zoom:50%;">]]></content>
    
    
    <summary type="html">&lt;p&gt;数组和链表是我们日常编程中非常常用的两种数据结构，那么它们的性能表现如何，本文由浅入深对此进行一些分析。&lt;/p&gt;</summary>
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>dubbo服务暴露</title>
    <link href="https://eoccc.gitee.io/2022/05/04/dubbo%E6%9C%8D%E5%8A%A1%E6%9A%B4%E9%9C%B2/"/>
    <id>https://eoccc.gitee.io/2022/05/04/dubbo%E6%9C%8D%E5%8A%A1%E6%9A%B4%E9%9C%B2/</id>
    <published>2022-05-03T16:00:00.000Z</published>
    <updated>2022-08-01T04:58:42.247Z</updated>
    
    <content type="html"><![CDATA[<p>Dubbo的服务暴露主要分为两个部分：第一步，将服务实例通过代理转换成Invoker；第二步，将Invoker通过具体协议转换成Exporter，实现服务暴露。</p><span id="more"></span><p>Dubbo框架进行服务暴露的入口是ServiceConfig#export，暴露服务的流程大致分为以下几步：</p><blockquote><ol><li>读取配置。AbstractConfig#refresh</li><li>通过代理将服务实例转成invoker。默认是Javassist，也支持JDK动态代理。ServiceConfig#doExportUrl</li><li>通过具体的协议，将Invoker转成expoter</li><li>将服务的元数据注册到注册中心。ServiceConfig#exported</li></ol></blockquote><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3wc0ircowj20xo0rqwhl.jpg" style="zoom:33%;"><p>注意：</p><ol><li>在将服务的元数据推送到注册中心的时候，如果失败了会进行重试，默认重试次数为6次。</li><li>支持多注册中心。MetadataServiceNameMapping#map</li></ol><p><strong>配置文件优先级：</strong></p><blockquote><ol><li>-D 传递给 JVM 参数优先级最高，比如-Ddubbo. protocol.port=20880</li><li>代码或XML配置优先级次高，比如Spring中XML文件指定&lt;dubbo:protocol port=H20880’/&gt;</li><li>置文件优先级最低，比如 dubbo.properties 文件指定 dubbo.protocol.port=20880</li></ol></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;Dubbo的服务暴露主要分为两个部分：第一步，将服务实例通过代理转换成Invoker；第二步，将Invoker通过具体协议转换成Exporter，实现服务暴露。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="dubbo" scheme="https://eoccc.gitee.io/tags/dubbo/"/>
    
  </entry>
  
  <entry>
    <title>dubbo服务消费</title>
    <link href="https://eoccc.gitee.io/2022/05/04/dubbo%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9/"/>
    <id>https://eoccc.gitee.io/2022/05/04/dubbo%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9/</id>
    <published>2022-05-03T16:00:00.000Z</published>
    <updated>2022-08-01T04:58:42.247Z</updated>
    
    <content type="html"><![CDATA[<p>在整体上看，Dubbo框架做服务消费也分为两大部分，第一步通过持有远程服务实例生成 Invoker，这个Invoker在客户端是核心的远程代理对象。第二步会把Invoker通过动态代理转换成实现用户接口的动态代理引用。这里的Invoker承载了网络连接、服务调用和重试等功能。</p><span id="more"></span><p>服务消费大致分为以下几步：</p><blockquote><ol><li><p>读取配置，转成ReferenceBean</p></li><li><p>获取元数据</p></li><li><p>创建invoker（incoker就是协议层包装了一个客户端）</p></li><li><p>代理invoker</p><p>支持cglib代理和jdk动态代理：CglibAopProxy、JdkDynamicAopProxy</p></li></ol></blockquote><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h3yxnh5zhjj20rm0n441i.jpg" alt="image-20220707101619358" style="zoom:45%;"><p>Dubbo的消费者配置会被转换成ReferenceBean，获取dubbo代理的入口是ReferenceBean#getObject，如果没有初始化，会调用createLazyProxy()方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> T <span class="title function_">getObject</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (lazyProxy == <span class="literal">null</span>) &#123;</span><br><span class="line">    createLazyProxy();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> (T) lazyProxy;</span><br><span class="line">&#125;    </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">createLazyProxy</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="comment">//创建代理工厂</span></span><br><span class="line">  <span class="type">ProxyFactory</span> <span class="variable">proxyFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ProxyFactory</span>();</span><br><span class="line">  <span class="comment">//初始化代理的核心逻辑</span></span><br><span class="line">  proxyFactory.setTargetSource(<span class="keyword">new</span> <span class="title class_">DubboReferenceLazyInitTargetSource</span>());</span><br><span class="line">  ...</span><br><span class="line">  <span class="built_in">this</span>.lazyProxy = proxyFactory.getProxy(<span class="built_in">this</span>.beanClassLoader);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>DubboReferenceLazyInitTargetSource中的核心逻辑是调用了ReferenceConfig#get方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//ReferenceBean#getCallProxy</span></span><br><span class="line"><span class="keyword">private</span> Object <span class="title function_">getCallProxy</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">  <span class="keyword">if</span> (referenceConfig == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;ReferenceBean is not ready yet, please make sure to call reference interface method after dubbo is started.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//get reference proxy 核心！</span></span><br><span class="line">  <span class="keyword">return</span> referenceConfig.get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在中，如果引用没有初始化，会先进行初始化，然后放到ReferenceCache中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> T <span class="title function_">get</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (destroyed) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;The invoker of ReferenceConfig(&quot;</span> + url + <span class="string">&quot;) has already destroyed!&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (ref == <span class="literal">null</span>) &#123;</span><br><span class="line">    getScopeModel().getDeployer().start();</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="built_in">this</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (ref == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">//开始初始化</span></span><br><span class="line">        init();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> ref;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ReferenceConfig#init开始初始化引用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 先初始化service的元数据</span></span><br><span class="line">  initServiceMetadata(consumer);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 获取注册中心</span></span><br><span class="line">  <span class="type">ModuleServiceRepository</span> <span class="variable">repository</span> <span class="operator">=</span> getScopeModel().getServiceRepository();</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 将consumer注册到注册中心</span></span><br><span class="line">  repository.registerConsumer(consumerModel);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 创建代理  重点！</span></span><br><span class="line">  ref = createProxy(referenceParameters);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>createProxy方法中的重点是createInvokerForRemote，创建远程代理，实现了单注册中心和多注册中心的逻辑，另外createProxy也实现了本地代理和远程代理的逻辑：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> T <span class="title function_">createProxy</span><span class="params">(Map&lt;String, String&gt; referenceParameters)</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (shouldJvmRefer(referenceParameters)) &#123;</span><br><span class="line">    <span class="comment">//创建本地代理</span></span><br><span class="line">    createInvokerForLocal(referenceParameters);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">//创建远程代理</span></span><br><span class="line">    createInvokerForRemote();</span><br><span class="line">  &#125;</span><br><span class="line">...</span><br><span class="line">  <span class="comment">// create service proxy</span></span><br><span class="line">  <span class="keyword">return</span> (T) proxyFactory.getProxy(invoker, ProtocolUtils.isGeneric(generic));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">createInvokerForRemote</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="comment">// 单注册中心</span></span><br><span class="line">  <span class="keyword">if</span> (urls.size() == <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="type">URL</span> <span class="variable">curUrl</span> <span class="operator">=</span> urls.get(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 核心 通过协议创建代理</span></span><br><span class="line">    invoker = protocolSPI.refer(interfaceClass, curUrl);</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    List&lt;Invoker&lt;?&gt;&gt; invokers = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    <span class="type">URL</span> <span class="variable">registryUrl</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="comment">// 多注册中心</span></span><br><span class="line">    <span class="keyword">for</span> (URL url : urls) &#123;</span><br><span class="line">      <span class="comment">// 和单注册中心一样  创建代理</span></span><br><span class="line">      invokers.add(protocolSPI.refer(interfaceClass, url));</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>后续就是协议层的具体实现了。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在整体上看，Dubbo框架做服务消费也分为两大部分，第一步通过持有远程服务实例生成 Invoker，这个Invoker在客户端是核心的远程代理对象。第二步会把Invoker通过动态代理转换成实现用户接口的动态代理引用。这里的Invoker承载了网络连接、服务调用和重试等功能。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="dubbo" scheme="https://eoccc.gitee.io/tags/dubbo/"/>
    
  </entry>
  
  <entry>
    <title>kafka副本管理</title>
    <link href="https://eoccc.gitee.io/2022/04/25/kafka%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86/"/>
    <id>https://eoccc.gitee.io/2022/04/25/kafka%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86/</id>
    <published>2022-04-25T14:52:41.000Z</published>
    <updated>2022-08-12T01:29:23.635Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka分区使用多副本机制来提升可靠性，只有leader副本能对外提供读写服务，follower副本只负责在内部进行消息同步，当leader副本不可用时，从follower副本中选择一个成为新的leader副本。</p><span id="more"></span><h1 id="优先副本"><a class="markdownIt-Anchor" href="#优先副本"></a> 优先副本</h1><p>在创建主题的时候，kafka会尽可能均匀地将分区和副本分布到各个broker节点上，leader副本的分布也比较均匀。</p><p>对于leader副本的选择，kafka会优先选择AR集合中的第一个副本。比如，分区0的AR集合为[1,2,0]，则kafka会优先将副本1作为这个分区的leader副本。</p><p>kafka提供了分区自动平衡的功能，通过参数<code>auto.leader.rebalance.enable</code>控制，默认为true。通过一个定时任务轮询所有的broker节点，计算每个broker的不平衡率（非优先副本的leader个数/分区总数），如果不平衡率超过<code>leader.imbalance.per.broker.percentage</code>配置的比例，就会触发优先副本的选举。执行的周期通过<code>leader.imbalance.check.interval.seconds </code>配置，默认为300秒。</p><p>需要注意的是，优先副本的选举会造成kafka不可用，生产环境不建议打开自动平衡副本。可以通过<code>kafka-perferr.replica.election.sh</code>脚本手动执行平衡动作。</p><h1 id="分区重分配"><a class="markdownIt-Anchor" href="#分区重分配"></a> 分区重分配</h1><p>当集群新增broker节点时，只有新创建的主题分区才会分配到这个节点上。因此集群扩容、或节点失效的时候，需要手动进行分区重分配，以保证分区的平衡。</p><p>Kafka 提供了 <a href="http://kafka-reassign-partitions.sh">kafka-reassign-partitions.sh</a> 脚本来执行分区重分配的工作。</p><p>分区重分配的本质在于数据复制，先增加新的副本，然后进行数据同步，最后删除旧的副本。复制会占用大量资源，如果分配的量太大，会影响性能，可以减小重分配的粒度，以小批次进行重分配。但是如果集群中某个主题或分区的流量特别大，仅靠减小粒度是不足够的，这时可以通过限流来实现。</p><p>副本间的复制限流有两种实现方式: <a href="http://kafka-config.sh">kafka-config.sh</a> 脚本和 <a href="http://kafka-reassign-partitions.sh">kafka-reassign-partitions.sh</a> 脚本。</p><h1 id="修改副本因子"><a class="markdownIt-Anchor" href="#修改副本因子"></a> 修改副本因子</h1><p>创建主题之后，如果我们想修改分区的个数，或者修改副本的个数，可以通过重分配的脚本 <a href="http://kafka-reassign-partition.sh">kafka-reassign-partition.sh</a> 来实现。</p><p>适当的增加分区数，会提高并发度，从而提高吞吐量，但是并不是分区数越多，吞吐量就会一直增长。</p>]]></content>
    
    
    <summary type="html">leader副本选举，副本同步</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka leader选举</title>
    <link href="https://eoccc.gitee.io/2022/04/25/kafka-leader%E9%80%89%E4%B8%BE/"/>
    <id>https://eoccc.gitee.io/2022/04/25/kafka-leader%E9%80%89%E4%B8%BE/</id>
    <published>2022-04-25T14:52:41.000Z</published>
    <updated>2022-08-01T04:58:42.277Z</updated>
    
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>反射异常？类型转换的锅</title>
    <link href="https://eoccc.gitee.io/2022/04/23/%E5%8F%8D%E5%B0%84%E5%BC%82%E5%B8%B8%EF%BC%9F%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E7%9A%84%E9%94%85/"/>
    <id>https://eoccc.gitee.io/2022/04/23/%E5%8F%8D%E5%B0%84%E5%BC%82%E5%B8%B8%EF%BC%9F%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E7%9A%84%E9%94%85/</id>
    <published>2022-04-23T06:10:32.000Z</published>
    <updated>2022-08-01T04:58:42.278Z</updated>
    
    <content type="html"><![CDATA[<p>前两天一个同事上线了代码，然后就飙了一阵<code>java.lang.NoSuchMethodException</code>，一时还不知所以，看不出代码存在什么问题，拉了好几个人在看，最后查到时反射的获取方法的时候，对象的类型不匹配，导致异常。</p><span id="more"></span><p>代码类似如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Demo</span> <span class="variable">demo</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Demo</span>();</span><br><span class="line">        List&lt;String&gt; list = Lists.newArrayList(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>);</span><br><span class="line">        <span class="type">Method</span> <span class="variable">printElement</span> <span class="operator">=</span> Demo.class.getDeclaredMethod(<span class="string">&quot;printElement&quot;</span>, list.getClass());</span><br><span class="line">        printElement.invoke(demo, list);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">printElement</span><span class="params">(List&lt;String&gt; list)</span> &#123;</span><br><span class="line">        Assert.isTrue(list != <span class="literal">null</span>, <span class="string">&quot;list can not be null&quot;</span>);</span><br><span class="line">        list.forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>乍一看不存在什么问题，日常写代码也是这么写的。但是运行的时候就是报了如下的错误：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread <span class="string">&quot;main&quot;</span> java.lang.NoSuchMethodException: com.my.Demo.printElement(java.util.ArrayList)</span><br></pre></td></tr></table></figure><p>问题就出在了通过反射获取class的方法这里：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Demo.class.getDeclaredMethod(<span class="string">&quot;printElement&quot;</span>, list.getClass());</span><br></pre></td></tr></table></figure><p>异常栈里面已经写的很清楚了，查找的是<code>printElement(java.util.ArrayList)</code>方法。随后我们对这段代码进行了分析。</p><p>以下是反射查找方法的核心方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Method <span class="title function_">searchMethods</span><span class="params">(Method[] methods,</span></span><br><span class="line"><span class="params">                                    String name,</span></span><br><span class="line"><span class="params">                                    Class&lt;?&gt;[] parameterTypes)</span>&#123;</span><br><span class="line">  <span class="type">ReflectionFactory</span> <span class="variable">fact</span> <span class="operator">=</span> getReflectionFactory();</span><br><span class="line">  <span class="type">Method</span> <span class="variable">res</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">  <span class="keyword">for</span> (Method m : methods) &#123;</span><br><span class="line">    <span class="keyword">if</span> (m.getName().equals(name)</span><br><span class="line">        &amp;&amp; arrayContentsEq(parameterTypes,</span><br><span class="line">                           fact.getExecutableSharedParameterTypes(m))</span><br><span class="line">        &amp;&amp; (res == <span class="literal">null</span></span><br><span class="line">            || (res.getReturnType() != m.getReturnType()</span><br><span class="line">                &amp;&amp; res.getReturnType().isAssignableFrom(m.getReturnType()))))</span><br><span class="line">      res = m;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而对参数进行匹配的方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">arrayContentsEq</span><span class="params">(Object[] a1, Object[] a2)</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (a1 == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="type">return</span> <span class="variable">a2</span> <span class="operator">=</span>= <span class="literal">null</span> || a2.length == <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (a2 == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> a1.length == <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (a1.length != a2.length) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; a1.length; i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (a1[i] != a2[i]) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>跟进去后发现a1（需要查找的参数）种存的类型为<code>class java.util.ArrayList</code>，而a2（class中的参数）存的类型为<code>interface java.util.List</code>，自然匹配不上。而且一个是<strong>class</strong>，一个是<strong>interface</strong> ！</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1r49pcgrlj20py06e3za.jpg" alt="image-20220430014244128" style="zoom:50%;"><p>那么如何解决？我们都知道原因了，解决起来就很简单——只要保证查找的方法的参数类型和实际方法的参数类型一致就可以了，自然就有两个方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//方法一</span></span><br><span class="line"><span class="comment">//查找类型设置为List.class</span></span><br><span class="line">Demo.class.getDeclaredMethod(<span class="string">&quot;printElement&quot;</span>, List.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//方法二</span></span><br><span class="line"><span class="comment">//将类中的方法定义为ArrayList</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">printElement</span><span class="params">(ArrayList&lt;String&gt; list)</span> &#123;</span><br><span class="line">  Assert.isTrue(list != <span class="literal">null</span>, <span class="string">&quot;list can not be null&quot;</span>);</span><br><span class="line">  list.forEach(System.out::println);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还有一个问题：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; list = Lists.newArrayList(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>);</span><br></pre></td></tr></table></figure><p>这一行代码我明明讲list定义为List类型了，为什么<code>list.getClass()</code>拿到的是<code>class java.util.ArrayList</code>?其原因是进行了<strong>向下转型</strong>。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前两天一个同事上线了代码，然后就飙了一阵&lt;code&gt;java.lang.NoSuchMethodException&lt;/code&gt;，一时还不知所以，看不出代码存在什么问题，拉了好几个人在看，最后查到时反射的获取方法的时候，对象的类型不匹配，导致异常。&lt;/p&gt;</summary>
    
    
    
    
    <category term="随笔" scheme="https://eoccc.gitee.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
    <category term="踩坑" scheme="https://eoccc.gitee.io/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>kafka小知识</title>
    <link href="https://eoccc.gitee.io/2022/04/19/kafka%E5%B0%8F%E7%9F%A5%E8%AF%86/"/>
    <id>https://eoccc.gitee.io/2022/04/19/kafka%E5%B0%8F%E7%9F%A5%E8%AF%86/</id>
    <published>2022-04-19T14:52:41.000Z</published>
    <updated>2022-08-01T04:58:42.277Z</updated>
    
    <content type="html"><![CDATA[<p>多生产者、多消费者、高性能、可伸缩、有消息堆积能力的 <strong>消息队列</strong> 。</p><span id="more"></span><p><a href="https://aidodoo.com/post/kafka/kafka%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/">很好的Kafka学习网站</a></p><h2 id="kafka的常见名词概念"><a class="markdownIt-Anchor" href="#kafka的常见名词概念"></a> Kafka的常见名词概念</h2><ol><li><p><strong>Broker</strong><br>存储消息的服务器，一个Kafka集群由多个Broker组成</p></li><li><p><strong>Topic（主题）</strong><br>每条消息发到Broker上都有一个类别，即Topic。Topic是消息逻辑上的分类概念。</p></li><li><p><strong>Partition（分区）</strong><br>Partition是一个物理上的概念，每个Topic包含一个或多个Partition，每个Partition是一个文件夹。Partition的特点是 <strong>ordered &amp; immutable</strong>。每个partition都有一个broker为“leader”，其余都为“follower”。</p><blockquote><p>Topic、Partition与Replica</p><ol><li>Kafka使用 <strong>Topic</strong> 组织数据，每个主题有若干个 <strong>Partition</strong> ，每个 <strong>Partition</strong> 有多个 <strong>副本（Replica）</strong>；每个 <strong>Broker</strong> 可以保存成百上千个属于不同 <strong>Topic</strong> 的 <strong>副本（Replica）</strong>；</li><li>同一个Topic不保证消息有序性，同一个Partition保证消息有序性；</li><li><strong>Topic</strong> 是用户订阅时关注的逻辑概念，而 <strong>分区（Partition）</strong> 是具体存储的物理逻辑，当我们对消息有序有要求时，我们需要使用 <strong>分区器</strong> ，对消息的分区行为进行定义以满足要求；至于 <strong>副本</strong> ，这是Kafka对数据可用性、持久性做的机制，使用者不需关注。</li><li>Partition的 “伸缩” 支持了 <strong>海量数据的存储</strong>、<strong>数据的高并发读取</strong>、<strong>极高的吞吐量</strong> 。</li></ol></blockquote></li><li><p><strong>Replica（副本）</strong><br>保证系统、数据的可用性、可靠性。<br>4.1 “首领副本&quot;和&quot;跟随副本”<br>​<strong>首领副本</strong> ：每个Partition都有一个首领副本，读写都会经过此副本；<br>​<strong>跟随副本</strong> ：从 <strong>首领</strong> 那里复制消息，不处理客户端请求，<strong>首领</strong> 崩溃时，升级为新首领（控制器选取）。<br>4.2 “同步副本&quot;和&quot;不同步副本”<br>​同步副本列表（In-Sync Replica，ISR）<br>​    不同步副本列表（Outof-Sync Replicas，OSR）</p><p>4.3 副本存活的条件：</p><ol><li>副本节点必须能与zookeeper保持会话（心跳机制）</li><li>副本能复制leader上的所有写操作，并且不能落后太多</li></ol><p>4.4 一条消息只有被ISR中所有的节点同步完成，才算提交成功</p><p>4.5 只有已提交的消息才能被消费</p></li><li><p><strong>Message (消息)</strong></p><p>传递的数据对象，主要由四部分构成，其中 <strong>offset</strong> 和 <strong>timestamp</strong> 在kafka集群中产生，key/value在producer发送数据的时候产生：</p><pre><code>1. offset(偏移量)（消费者自己保存消费进度）  是一个long型整数，代表了这条消息在Partition文件中的偏移量，它是一条消息在文件中的唯一标识。2. key，按照key进行哈希来选择partition(默认)；key没有填的时候使用round-robin来选partition。3. value4. timestamp(插入时间)；</code></pre></li><li><p><strong>生产者</strong><br>负责发布消息到Kafka broker。</p></li><li><p><strong>消费者</strong><br>消息消费者，从Kafka broker读取消息的客户端。</p></li><li><p><strong>消费者组</strong><br>消费者组（Consumer Group），多个消费者组成一个消费者组，共同消费一个Topic，每个消费者消费一部分分区；</p><blockquote><ol><li>一个Partition分区只能被组中的一个消费者消费；</li><li>若消费者数目大于partition数目，则会有消费者空置；</li><li>每个Consumer属于一个特定的Consumer Group；</li><li>可为每个Consumer指定group name，若不指定group name则属于默认的group；</li><li>一个Topic可以被多个消费者或消费者群组共同并行读取。</li></ol></blockquote></li></ol><p>​8.1 消费者群组和分区再均衡<br>​         群组加入新的消费者，它会读取原本由其他消费者读取的分区；群组删除消费者，该消费者读取的分区会由其他消费者读取；这就是 <strong>分区再均衡</strong> 。再均衡为消费者群组带来了高可用性和伸缩性（放心增加、删除消费者）。</p><ol start="9"><li><p><strong>控制器</strong></p><p><strong>控制器</strong> 就是一个Broker，集群中有且仅有一个控制器。所有Broker通过向zookeeper注册临时节点竞争获得。这个Broker的意义是防止 <strong>羊群效应</strong>（Zookeeper通知的客户端过多，造成zookeeper性能突然下降，影响使用），负责管理整个集群中所有分区和副本的状态，如:</p><ol><li>负责头领副本的选举</li><li>某个Partition的ISR集合发生变化时，控制器负责通知所有Broker更新其元数据信息</li></ol></li><li><p><strong>ISR(In-Sync Replicas)</strong></p><p>leader会追踪和维护ISR中所有follower的滞后状态。如果滞后太多（时间滞后<code>replica.lag.time.max.ms</code>，消息滞后<code>replica.lag.max.messages</code>），leader会把该replica从ISR中移除。被移除ISR的replica一直在追赶leader。</p><p>leader写入数据后并不会commit，只有ISR列表中的所有folower同步之后才会commit，把滞后的follower移除ISR主要是避免写消息延迟。设置ISR主要是为了broker宕掉之后，重新选举partition的leader从ISR列表中选择。</p><p><code>min.insync.replicas</code>: 最小的ISR个数，当ISR个数小于配置的个数，leader将变成只读，直到replica同步消息追赶上leader。</p></li><li><p><strong>Zookeeper在kafka中的作用</strong><br>在Kafka集群中，Zookeeper负责 <strong>管理协调</strong> 、<strong>元数据</strong> 保存等工作。Broker、消费者和Zookeeper相连，而生产者只和Broker相连。</p></li><li><p>Kafka使用ZooKeeper用于管理、协调；Kafka控制器的选举由Zookeeper负责；启动时，第一个在Zookeeper创建一个临时节点/controller的会成为控制器；为了防止脑裂，每个控制器都有一个epoch字段，并且是递增的，<strong>收到消息的epoch小于当前控制器epoch则忽略</strong> 。</p></li></ol><blockquote><p>脑裂：失效的HA节点认为自己仍然有效，和当前的HA节点争抢&quot;共享服务&quot;或&quot;资源&quot;，造成数据损坏，服务失败等问题。</p><p>如果没有epoch，Kafka脑裂发生的情况：旧的Controller失去与Zookeeper的关联后，但这个Controller并没有意识到自己已经失效而且还保持着和其他Broker的连接，其他Broker尝试成为Controller；这时新旧Controller同时给Broker发送命令消息，造成脑裂。</p></blockquote><ol start="2"><li>Kafka将元数据信息保存在Zookeeper中，这包括<br>broker信息、topic信息、分区与消费者的关系、消费者消费进度(offset)等信息。<br>[Zookeeper在Kafka中作用](<a href="https://www.jianshu.com/p/a036405f989c">https://www.jianshu.com/p/a036405f989c</a>   zookeeper在kafka中作用)</li></ol><p><strong>一段话概括Kafka架构：</strong></p><p>Kafka由一个或多个Broker组成，消息以Partition为单位的log文件的形式存储于Broker中，每个Topic可以对应一个或多个Partition，这为消息提供了容量上的扩展性和消费上的并发度；为了保证消息的可靠性以及可用性，每个Partition都会有多个Replica。</p><h2 id="kafka文件存储机制"><a class="markdownIt-Anchor" href="#kafka文件存储机制"></a> Kafka文件存储机制</h2><h3 id="存储格式"><a class="markdownIt-Anchor" href="#存储格式"></a> 存储格式</h3><p>Topic是一个逻辑概念，Partition才是一个物理概念。</p><ul><li><p>一个Partition是一个目录，topic名+id（id从0开始）</p></li><li><p>Partition目录下包含多个大小相等 <strong>segment(段)数据文件</strong> ，这样做是为了方便删除</p></li><li><p>segment文件由两部分组成，分别为“.index”文件和“.log”文件</p><ul><li><p>文件名从0开始，后续的文件名是 <strong>上一个segment文件最后一条消息的offset值</strong></p></li><li><p>数据文件存储消息实体</p></li><li><p>索引文件存储对应数据文件部分消息的元数据（稀疏索引）</p><p>（索引文件中元数据指向对应数据文件中message的物理偏移地址）</p></li></ul></li></ul><p><img src="https:////upload-images.jianshu.io/upload_images/2835676-f378607bc841309a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000" alt="img"></p><h3 id="删除策略"><a class="markdownIt-Anchor" href="#删除策略"></a> 删除策略</h3><p>Kafka具备消息堆积能力，但消息不能无限增长。</p><p>默认规定：保留7天，或超过指定大小，如1G；达到上限时，数据会被删除。</p><h2 id="kafka副本同步机制"><a class="markdownIt-Anchor" href="#kafka副本同步机制"></a> Kafka副本同步机制</h2><p>Kafka同一个Partition下有多个Replica，并且分为Leader Replica和follower Replica。消息的读写都由Leader Replica完成。</p><p>Leader Replica还维护<strong>ISR列表</strong>，消费者只能消费到ISR中offset最小值（高水位HW）之前的消息（不是完全的同步，又不是完全的异步，在吞吐率和可靠性之间做了均衡）。</p><p>副本不同步的原因：</p><ul><li>慢副本：在一定周期时间内follower不能追赶上leader。最常见的原因之一是I / O瓶颈导致follower追加复制消息速度慢于从leader拉取速度。</li><li>卡住副本：在一定周期时间内follower停止从leader拉取请求。follower replica卡住了是由于GC暂停或follower失效或死亡。</li><li>新启动副本：当用户给主题增加副本因子时，新的follower不在同步副本列表中，直到他们完全赶上了leader日志。</li></ul><p><a href="https://aidodoo.com/post/kafka/kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/">副本同步机制参考</a></p><h2 id="kafka数据一致性和可靠性保证"><a class="markdownIt-Anchor" href="#kafka数据一致性和可靠性保证"></a> Kafka数据一致性和可靠性保证</h2><p>当producer向leader发送数据时，可以通过<code>request.required.acks</code>参数来设置数据可靠性的级别</p><ul><li>1（默认）：这意味着producer在ISR中的leader已成功收到的数据并得到确认后发送下一条message。如果leader宕机了，则会丢失数据。</li><li>0：这意味着producer无需等待来自broker的确认而继续发送下一批消息。这种情况下数据传输效率最高，但是数据可靠性确是最低的。</li><li>-1：producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。但是这样也不能保证数据不丢失，比如当ISR中只有leader时（前面ISR那一节讲到，ISR中的成员由于某些情况会增加也会减少，最少就只剩一个leader），这样就变成了acks=1的情况。</li><li>min.insync.replicas=2：ISR集合中最少有2个replica，否则写入失败。如果ISR成员数目小于2，该Partition的Leader Replica会变得可读，但不可写。只有被ISR中所有Replica同步的消息才被Commit，才能被消费者消费。</li></ul><h2 id="kafka-partition-leader选举"><a class="markdownIt-Anchor" href="#kafka-partition-leader选举"></a> Kafka Partition leader选举</h2><p>Kafka在Zookeeper中为每一个partition动态的维护了一个ISR，这个ISR里的所有replica都跟上了leader，只有ISR里的成员才能有被选为leader的可能。</p><p>（默认 unclean.leader.election.enable=false，非ISR中的副本不能够参与选举）</p><p>如果Leader Replica宕机，而ISR全部不可用，为了恢复业务，我们需要重启Leader和ISR，如果失败，则需要修改配置，unclean.leader.election.enable=true。</p><p>如果min.insync.replicas数目达不到，造成系统不可写，而又重启有失败，就要修改min.insync.replicas使系统可写。</p><h2 id="kafka消息幂等性"><a class="markdownIt-Anchor" href="#kafka消息幂等性"></a> Kafka消息幂等性</h2><p>主要考虑三种消息可靠性：</p><ul><li>At most once: 消息可能会丢，但绝不会重复传输</li><li>At least once：消息绝不会丢，但可能会重复传输</li><li>Exactly once：每条消息肯定会被传输一次且仅传输一次</li></ul><p>我们想要的是 <strong>Exactly once</strong> ，但在实际场景中，常常是 <strong>At least once</strong> 或者 <strong>At most once</strong> ，</p><ul><li>At least once：<ul><li>producer无法判断消息是否真正提交时，会多次retry，重复发送该消息；</li><li>consumer先消费消息，再commit，消费成功，但commit前crash了，下次还会接收到该消息；</li></ul></li><li>At most once：<ul><li>Producer的消息没发到Broker（request.required.acks=0）</li><li>consumer先commit，再消费消息，消费成功，但commit前crash了，下次还会接收到该消息；</li></ul></li></ul><p>所以，一般在使用中，我们会让消息处于At least once状态，然后在consumer处理时，根据业务的特性，进行幂等处理。</p><h2 id="kafka消息的有序性"><a class="markdownIt-Anchor" href="#kafka消息的有序性"></a> Kafka消息的有序性</h2><p>Kafka消息同一个Topic下的消息是无序的，同一Partition下的消息是有序的。</p><p>我们可以自定义分区器，使消息根据业务的具体特性进行分区。</p><h2 id="kafka运维"><a class="markdownIt-Anchor" href="#kafka运维"></a> Kafka运维</h2><p>硬件配置：</p><ul><li>磁盘吞吐量、磁盘容量、内存、网络、CPU、Broker数目等等</li></ul><h2 id="相关问题"><a class="markdownIt-Anchor" href="#相关问题"></a> 相关问题</h2><ul><li><p>kafka节点之间如何复制备份的？</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.将所有Broker（假设共n个Broker）和待分配的Partition排序</span><br><span class="line">2.将第i个Partition分配到第（i mod n）个Broker上 （这个就是leader）</span><br><span class="line">3.将第i个Partition的第j个Replica分配到第（(i + j) mode n）个Broker</span><br></pre></td></tr></table></figure></li><li><p>kafka消息是否会丢失？为什么？</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="strong">**网络异常：**</span> <span class="code">`request.required.acks`</span>设置为0时，不和Kafka集群进行消息接受确认，当网络发生异常等情况时，存在消息丢失的可能；</span><br><span class="line"><span class="strong">**客户端异常：**</span> 异步发送时，消息并没有直接发送至Kafka集群，而是在Client端按一定规则缓存并批量发送。在这期间，如果客户端发生死机等情况，都会导致消息的丢失；</span><br><span class="line"><span class="strong">**缓冲区满了：**</span> 异步发送时，Client端缓存的消息超出了缓冲池的大小，也存在消息丢失的可能；</span><br><span class="line"><span class="strong">**Leader副本异常：**</span> acks设置为1时，Leader副本接收成功，Kafka集群就返回成功确认信息，而Follower副本可能还在同步。这时Leader副本突然出现异常，新Leader副本(原Follower副本)未能和其保持一致，就会出现消息丢失的情况；</span><br></pre></td></tr></table></figure></li><li><p>kafka最合理的配置是什么？</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="strong">**高可用配置:**</span> </span><br><span class="line">  topic配置：</span><br><span class="line"><span class="code">    replication.factor&gt;=3，即副本数至少是3个；</span></span><br><span class="line"><span class="code">    2 &lt;= min.insync.replicas &lt;= replication.factor，最小同步副本数码至少为2</span></span><br><span class="line"><span class="code">  broker的配置：</span></span><br><span class="line"><span class="code">    leader的选举条件unclean.leader.election.enable=false，非ISR中的副本不能够参与选举</span></span><br><span class="line"><span class="code">  producer的配置：</span></span><br><span class="line"><span class="code">    request.required.acks=-1(all)</span></span><br><span class="line"><span class="code">    producer.type=sync（指定消息发送是同步的）</span></span><br></pre></td></tr></table></figure></li><li><p>kafka的leader选举机制是什么？</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">所有Partition的Leader选举都由<span class="code">`controller`</span>决定。Kafka会在Zookeeper上针对每个Topic维护一个称为ISR（in-sync replica，已同步的partition副本）的集合。只有当这些副本都跟Leader中的副本同步了之后，kafka才会认为消息已提交，并反馈给消息的生产者。如果这个集合有增减，kafka会更新zookeeper上的记录。如果某个分区的Leader不可用，Kafka就会从ISR集合中选择一个副本作为新的Leader。</span><br><span class="line">如果Leader Replica宕机，而ISR全部不可用，为了恢复业务，我们需要重启Leader和ISR，如果失败，则需要修改配置，unclean.leader.election.enable=true，允许非同步的partition成为leader。</span><br><span class="line">如果min.insync.replicas数目达不到，造成系统不可写，而又重启有失败，就要修改min.insync.replicas使系统可写。</span><br></pre></td></tr></table></figure></li><li><p>kafka的消息保证有几种方式？</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="code">`request.required.acks`</span></span><br><span class="line"><span class="strong">**1(默认):**</span> leader收到消息就向producer确认</span><br><span class="line"><span class="strong">**0:**</span> producer不关心leader有没有收到消息</span><br><span class="line"><span class="strong">**-1:**</span> leader收到消息，并且同步partition同步完成后才向producer确认</span><br><span class="line"><span class="code">`min.insync.replicas`</span></span><br><span class="line">设置ISR集合中最少的replica个数。</span><br></pre></td></tr></table></figure></li><li><p>Kafka如何实现高伸缩性？</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="strong">**分区再均衡**</span>  群组加入新的消费者，它会读取原本由其他消费者读取的分区；群组删除消费者，该消费者读取的分区会由其他消费者读取</span><br></pre></td></tr></table></figure></li><li><p>Kafka消息的有序性如何？</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在Kafka中，消息是以消息队列的方式存在，存储在Topic中，Topic有多个partition。而每一条消息根据 Key 值来分配到不同的 partition 中。在一个 Partition 中，消息是以追加的形式写入的。如果一个 Consumer 读取一个 Partition，那么数据可以被有序的消费掉。</span><br><span class="line">方案一，kafka topic 只设置一个partition分区。kafka默认保证同一个partition分区内的消息是有序的，则可以设置topic只使用一个分区，这样消息就是全局有序，缺点是只能被consumer group里的一个消费者消费，降低了性能，不适用高并发的情况。</span><br><span class="line">方案二，producer将消息发送到指定partition分区。producer可以在发送消息时可以指定需要保证顺序的几条消息发送到同一个分区，这样消费者消费时，消息就是有序。</span><br></pre></td></tr></table></figure></li><li><p>producer 的写入流程</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">1.</span> producer 先从 zookeeper 的 &quot;/brokers/.../state&quot; 节点找到该 partition 的 leader </span><br><span class="line"><span class="bullet">2.</span> producer 将消息发送给该 leader </span><br><span class="line"><span class="bullet">3.</span> leader 将消息写入本地 log </span><br><span class="line"><span class="bullet">4.</span> followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK </span><br><span class="line"><span class="bullet">5.</span> leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK</span><br></pre></td></tr></table></figure></li><li><p>如何防止脑裂</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafka中只有一个控制器controller负责分区的leader选举，同步broker的新增或删除消息，但有时由于网络问题，可能同时有两个broker认为自己是controller，这时候其他的broker就会发生脑裂。</span><br><span class="line">解决：每当新的controller产生的时候就会在zk中生成一个全新的、数值更大的controller epoch的标识，并同步给其他的broker进行保存，这样当第二个controller发送指令时，其他的broker就会自动忽略。</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <summary type="html">多生产者、多消费者、高性能、可伸缩、有消息堆积能力的 **消息队列**</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka文件存储机制</title>
    <link href="https://eoccc.gitee.io/2022/04/15/kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6/"/>
    <id>https://eoccc.gitee.io/2022/04/15/kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6/</id>
    <published>2022-04-15T14:52:41.000Z</published>
    <updated>2022-08-01T04:58:42.277Z</updated>
    
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="kafka" scheme="https://eoccc.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>redis学习10-集群</title>
    <link href="https://eoccc.gitee.io/2022/04/02/redis%E5%AD%A6%E4%B9%A010-%E9%9B%86%E7%BE%A4/"/>
    <id>https://eoccc.gitee.io/2022/04/02/redis%E5%AD%A6%E4%B9%A010-%E9%9B%86%E7%BE%A4/</id>
    <published>2022-04-02T07:10:35.000Z</published>
    <updated>2022-08-01T04:58:42.277Z</updated>
    
    <content type="html"><![CDATA[<p>Redis集群会将数据库分为16384个槽（slot），集群中的每个节点可以处理0～16384个槽，redis的每个键只会落在其中的一个槽中。当数据库中的每个槽都有redis节点处理的时候，集群才会处于可用状态。</p><span id="more"></span><p>Reids可以用以下命令让一个节点负责处理第0～5000个槽：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLUSTER ADDSLOT 0 1 2 3 ... 5000</span><br></pre></td></tr></table></figure><p>同时，节点会将自己负责处理的槽的信息发送给集群中的其他服务器，集群中的每个节点都知道每个槽是由哪个节点负责。</p><h2 id="执行命令"><a class="markdownIt-Anchor" href="#执行命令"></a> 执行命令</h2><p>Redis中的16384个槽都分配到redis节点处理后，集群就会进入上线状态，开始接收客户端的命令。当集群服务器收到有关数据库的命令后，不会立即开始处理，而是会先计算出命令中的键是处于哪个槽，然后进行分派：</p><blockquote><ul><li><p>如果键所在的槽由自己负责，则开始处理命令</p></li><li><p>如果键所在的槽不是由自己负责，则会向客户端发挥一个<code>MOVED</code>命令，指引客户端转向正确的节点，并重新发送命令。（集群模式的客户端收到<code>MOVED</code>命令不会打印错误，只会转向正确的节点，然后打印转向信息）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MOVED &lt;slot&gt; &lt;ip&gt;:&lt;port&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1t25ak149j20r20f4jsm.jpg" alt="image-20220501180000995" style="zoom:45%;"><p>Redis使用<code>CRC-16</code>算法对key进行散列：</p><blockquote><p>crc16(key) % 16384</p></blockquote><p>使用以下命令，可以计算cluster会将key散列到哪个slot中去：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLUSTER KEYSLOT myKey</span><br></pre></td></tr></table></figure><h2 id="重新分片"><a class="markdownIt-Anchor" href="#重新分片"></a> 重新分片</h2><p>Redis集群可以把任意数量已已指派给某一节点的槽指派给另一个节点，并且这些槽相关的键也会移到新的节点上。这个操作可以在线进行，并且在重新分片过程中，源节点和目标节点都可以执行命令。</p><h3 id="迁移过程"><a class="markdownIt-Anchor" href="#迁移过程"></a> 迁移过程</h3><p>重新分片由redis集群管理软件<strong>redis-trib</strong>负责操作，单个slot的迁移分为几个步骤：</p><blockquote><ol><li>向目标节点发送<code>CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_id&gt;</code>命令，让目标节点准备好导入新的槽</li><li>向源节点发送<code>CLUSTER SETSLOT &lt;slot&gt; MAGRATING &lt;target_id&gt;</code>命令，让源节点准备好迁移槽</li><li>向源节点发送<code>CLUSTER  GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;</code>命令，获得最多count个属于slot的键</li><li>根据3步骤中获得的键，向源节点发送<code>MIGRATE &lt;target_ip&gt; &lt;target_port&gt; &lt;key_name&gt; 0 &lt;timeout&gt;</code>命令，将键key_name迁移到目标节点</li><li>重复3、4步骤，将属于slot槽的所有键迁移到新节点</li><li>向集群中的任一节点发送<code>CLUSTER SETSLOT &lt;slot&gt; NODE &lt;target_id&gt;</code>命令，将slot槽指派给目标节点，这一指派信息会通过消息发送至集群中的每一个节点</li><li>集群中的节点收到新的指派消息后，更新分片信息</li></ol></blockquote><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1t4lrrchyj20wq08q0tp.jpg" alt="image-20220501192528800" style="zoom:50%;"><h3 id="迁移过程中访问键ask"><a class="markdownIt-Anchor" href="#迁移过程中访问键ask"></a> 迁移过程中访问键（ASK）</h3><p>在迁移过程中，如果客户端向源节点发送一个与数据库有关的命令，而且命令中的键正好在迁移的slot中时：</p><blockquote><ol><li>源节点会在自己的数据库中查找命令中的键，如果找到，执行命令</li><li>如果在源节点的数据库中没有找到命令中的键，说明这个键已经迁移到目标节点，这时源节点会回复一个<code>ASK</code>错误，指引客户端将命令发送给目标节点（客户端会忽略异常信息，只执行转向操作）</li></ol></blockquote><img src="/.io//image-20220501193151480.png" alt="image-20220501193151480" style="zoom:45%;"><p>客户端收到<code>ASK</code>错误后，会执行<code>ASKING</code>命令，打开客户端中的<code>REDIS_ASKING</code>标识，然后将新的命令发送给<code>ASK</code>错误信息中的目标节点。如果<code>REDIS_ASKING</code>标识没有打开，目标节点会拒绝执行命令，并且返回一个<code>MOVED</code>错误。</p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1t4z8t1vpj20n60dkq46.jpg" alt="image-20220501193815198" style="zoom:45%;"><h2 id="复制与故障转移"><a class="markdownIt-Anchor" href="#复制与故障转移"></a> 复制与故障转移</h2><p>集群中的主节点负责处理槽，从节点复制主节点。当某个主节点下线时，从其从节点中选择一个成为新的主节点，代替主节点接收并处理客户端命令。</p><p>通过以下命令，让一个节点成为主节点的从节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLUSTER REPLICATE &lt;node_id&gt;</span><br></pre></td></tr></table></figure><h3 id="故障检测"><a class="markdownIt-Anchor" href="#故障检测"></a> 故障检测</h3><p>集群中的每个节点都会定期地向其他节点发送<code>PING</code>命令，检测其他节点是否存活。如果某个节点在指定的时间没没有返回<code>PONG</code>消息，则会认为这个服务器<strong>疑似下线</strong>，然后这个服务器会询问其他<font color="red">主节点</font>是否支持目标服务器下线，当收到半数以上的赞成票时，就会将目标服务器标记为<strong>已下线</strong>，然后会向集群广播一条这个主节点下线的消息。</p><h3 id="故障转移"><a class="markdownIt-Anchor" href="#故障转移"></a> 故障转移</h3><p>当一个<font color="red">从节点</font>发现自己的主节点下线时，将开始故障转移，从从节点中选择一个节点成为新的主节点：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">1.</span> 在从节点中选择一个节点成为主节点</span><br><span class="line"><span class="bullet">2.</span> 被选中的节点执行<span class="code">`SLAVEOF no one`</span>命令，成为主节点</span><br><span class="line"><span class="bullet">3.</span> 新的主节点撤销旧的主节点的所有槽指派，并将这些槽指派给自己</span><br><span class="line"><span class="bullet">4.</span> 新主节点在集群中广播一条<span class="code">`PONE`</span>消息，让集群中的其他节点知道自己成为了新的主节点，并已接管了下线节点的槽</span><br><span class="line"><span class="bullet">5.</span> 新主节点开始接收和处理请求</span><br></pre></td></tr></table></figure><h3 id="选举新的主节点"><a class="markdownIt-Anchor" href="#选举新的主节点"></a> 选举新的主节点</h3><p>当发现某个服务器客观下线，就会开始故障转移，故障转移时要先选择一个新的主节点。选举的方式和Sentinel相似：</p><blockquote><ol><li>集群的纪元自增1</li><li>在一个纪元中，集群中的每个<font color="red">主节点</font>有一次投票机会</li><li>当从节点发现自己的主节点下线时，会向集群广播一条消息，并要求有投票权的主节点给自己投票</li><li>如果一个主节点有投票权，且在这个纪元中没有将票投给其他节点，会将票投给第一个请求投票的从节点（先到先得）</li><li>当一个从节点获得的票数过半时，当选成新的主节点</li><li>如果在一个纪元里，没有选举出新的主节点，会进入一个新的纪元（纪元加1），重新开始投票，直到选出新主节点</li></ol></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;Redis集群会将数据库分为16384个槽（slot），集群中的每个节点可以处理0～16384个槽，redis的每个键只会落在其中的一个槽中。当数据库中的每个槽都有redis节点处理的时候，集群才会处于可用状态。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习9-哨兵Sentinel</title>
    <link href="https://eoccc.gitee.io/2022/04/01/redis%E5%AD%A6%E4%B9%A09-%E5%93%A8%E5%85%B5Sentinel/"/>
    <id>https://eoccc.gitee.io/2022/04/01/redis%E5%AD%A6%E4%B9%A09-%E5%93%A8%E5%85%B5Sentinel/</id>
    <published>2022-04-01T05:10:32.000Z</published>
    <updated>2022-08-01T04:58:42.278Z</updated>
    
    <content type="html"><![CDATA[<p>哨兵Sentinel是redis集群高可用的解决方案：由一个或多个Sentinel节点组成，监视任意多个主服务器及主服务器下的所有从服务器，当主服务器下线的时候，从其从服务器中选择一个升级成主服务器。</p><span id="more"></span><h2 id="获取服务器信息"><a class="markdownIt-Anchor" href="#获取服务器信息"></a> 获取服务器信息</h2><p>Sentinel会以10秒每次的频率向主服务器发送<code>INFO</code>命令，通过主服务器返回的信息，可以获得两类信息：</p><blockquote><ol><li>主服务器本身的信息</li><li>主服务器的所有从服务器的信息</li></ol></blockquote><p>同时Sentinel会以10秒每次的频率向从服务器发送<code>INFO</code>命令，获得以下信息：</p><blockquote><ol><li>从服务器的运行ID <code>run_id</code></li><li>从服务器的角色<code>role</code></li><li>主服务器的ip地址<code>master_host</code>，主服务器的端口号<code>master_port</code></li><li>主从服务器的连接状态<code>master_link_status</code></li><li>从服务器的优先级<code>slave_priority</code></li><li>从服务器的复制偏移量<code>slave_repl_offset</code></li></ol></blockquote><p>Sentinel会以2秒每次的频率向主从服务器的<code>__sentinel__:hello</code>频道发送以下信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUBLISH __sentinel__:hello <span class="string">&quot;&lt;s_ip&gt;,&lt;s_port&gt;,&lt;s_runid&gt;,&lt;s_epoch&gt;,&lt;m_name&gt;,&lt;m_ip&gt;,&lt;m_port&gt;,&lt;m_epoch&gt;&quot;</span> </span><br></pre></td></tr></table></figure><table><thead><tr><th>参数</th><th>意义</th></tr></thead><tbody><tr><td>s_ip</td><td>Sentiel 的IP</td></tr><tr><td>s_port</td><td>Sentiel 的端口号</td></tr><tr><td>s_runid</td><td>Sentiel 的运行id</td></tr><tr><td>s_epoch</td><td>Sentiel 的纪元</td></tr><tr><td>m_name</td><td>主服务器的名字</td></tr><tr><td>m_ip</td><td>主服务器的ip</td></tr><tr><td>m_port</td><td>主服务器的端口号</td></tr><tr><td>m_epoch</td><td>主服务器的纪元</td></tr></tbody></table><p>Sentinel与主服务器和从服务器建立连接后，会执行一下命令，订阅<code>__sentiel__:hello</code>频道的信息，解析收到的小心，并更新自己的数据。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SUBSCRIBE __sentiel__:hello</span><br></pre></td></tr></table></figure><p>另外，Sentinel可以通过主服务器或从服务器发送的频道信息，感知到新加入的Sentinel服务器。</p><h2 id="主观下线检测"><a class="markdownIt-Anchor" href="#主观下线检测"></a> 主观下线检测</h2><p>Sentinel会以每秒一次的频率向所有的主服务器、从服务器、其他Sentiel服务器发送<code>PING</code>命令，从而判断其他服务器是否在线。如果一个实例在<code>down_after_milliseconds</code>毫秒内没有回复，sentiel就会将这个实例标记为主管下线状态。</p><p>如果对一个sentinel进行了如下配置，那么master在50秒内没有回复<code>PING</code>命令，sentinel就会认为master主观下线。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sentinel monitor master 127.0.0.1 6379 2</span><br><span class="line">sentinel down_after_milliseconds master 50000</span><br></pre></td></tr></table></figure><p><strong>需要注意的是</strong>：每个sentinel实例可以有不同的配置，一个sentinel认为master主管下线，另一个sentinel不一定认为master主观下线。</p><h2 id="客观下线检测"><a class="markdownIt-Anchor" href="#客观下线检测"></a> 客观下线检测</h2><p>当一个sentinel（记为sentinelA）发现某个节点主观下线后，会向其他sentine发送一下命令，询问这个节点是否下线：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SENTINEL is-master-down-by-addr &lt;ip&gt; &lt;port&gt; &lt;current_epoch&gt; &lt;runid&gt;</span><br></pre></td></tr></table></figure><p>当一个sentinel（记为sentinelB）收到这个命令的时候，会检查命令中的服务器是否下线，并回复是否赞成这个服务器已经下线。</p><p>sentinelA收到其他sentinel的回复以后，会判断其他sentinel是否赞成这个服务器已经下线，如果赞成票达到配置的数量以后，就会将这个服务器标记成客观下线。</p><p>如一下配置表示支持master主观下线的票数达到3票，就会将master标记为客观下线：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentinel monitor master 127.0.0.1 6379 5</span><br></pre></td></tr></table></figure><p>**需要注意的是：**不同的sentinel判断客观下线的条件不同，根据sentinel的配置决定。</p><h2 id="选举领头sentinel"><a class="markdownIt-Anchor" href="#选举领头sentinel"></a> 选举领头Sentinel</h2><p>当一个主服务器下线之后，负责监视的sentinel会进行协商，选举出一个领头的sentinel，由领头的sentinel主持故障转移。选举领头sentinel的规则如下：</p><blockquote><ol><li>每次选举，不论选举是否成功，所有sentinel的纪元都会加1</li><li>在一个纪元里，一个sentinel有一次将某个sentinel设置为leader的机会，而且一旦设置，在这个纪元里就不会再更改</li><li>每个发现主服务器客观下线的sentinel都会要求其他sentinel将自己设置为leader（最终只会有一个成功）</li><li>担任leader的规则是先到先得：最先发现主服务器客观下线的sentinel会率先发起选举投票</li><li>如果有某个sentinel收到半数以上的投票，则成为leader</li><li>如果在限定的时间内没有选举成功，那么各个sentinel会隔一段时间之后再次选举，直到选举出leader</li></ol></blockquote><h2 id="故障转移"><a class="markdownIt-Anchor" href="#故障转移"></a> 故障转移</h2><p>选举出sentinel的leader以后，leader就会主持故障转移：</p><blockquote><ol><li>在主服务器的所有从服务器中选出一个，成为主服务器</li><li>让其他从服务器复制这个新的主服务器</li><li>原来的主服务器恢复以后，成为新的主服务器的从服务器</li></ol></blockquote><h3 id="选举主服务器"><a class="markdownIt-Anchor" href="#选举主服务器"></a> 选举主服务器</h3><p>哨兵leader会把所有从服务器保存在一个列表中，从中选择出一个状态良好、数据完整的服务器，成为新的主服务器：</p><blockquote><ol><li>删除列表中所有处于下线状态的服务器</li><li>删除列表中最近5秒内没有回复sentinel的<code>INFO</code>命令的服务器</li><li>删除与主服务器断开连接超过<code>down_after_milliseconds * 10</code>毫秒的服务器</li><li>选择出列表中剩余的服务器中优先级最高的一个</li><li>如果有多个优先级一样的服务器，选择其中偏移量最大的一个</li><li>如果有多个偏移量一样的服务器，选择其中运行ID最小的一个</li></ol></blockquote><p>向选出的服务器发送以下命令，并以每秒一次的频率向其发送<code>INFO</code>命令，当其<code>role</code>属性由&quot;slave&quot;变成&quot;master&quot;，则成功变成主服务器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SLAVEOF no one</span><br></pre></td></tr></table></figure><h3 id="修改从服务器的复制目标"><a class="markdownIt-Anchor" href="#修改从服务器的复制目标"></a> 修改从服务器的复制目标</h3><p>当新的主服务器出现后，leader会向所有的从服务器发送<code>SLAVEOF</code>命令，让它们复制新的主服务器。</p><h3 id="旧主服务器变成从服务器"><a class="markdownIt-Anchor" href="#旧主服务器变成从服务器"></a> 旧主服务器变成从服务器</h3><p>当旧服务器恢复重连的时候，sentinel会向其发送<code>SLAVEOF</code>命令，让其成为新主服务的从服务器。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;哨兵Sentinel是redis集群高可用的解决方案：由一个或多个Sentinel节点组成，监视任意多个主服务器及主服务器下的所有从服务器，当主服务器下线的时候，从其从服务器中选择一个升级成主服务器。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习8-复制（主从架构）</title>
    <link href="https://eoccc.gitee.io/2022/03/30/redis%E5%AD%A6%E4%B9%A08-%E5%A4%8D%E5%88%B6%EF%BC%88%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84%EF%BC%89/"/>
    <id>https://eoccc.gitee.io/2022/03/30/redis%E5%AD%A6%E4%B9%A08-%E5%A4%8D%E5%88%B6%EF%BC%88%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84%EF%BC%89/</id>
    <published>2022-03-30T06:10:32.000Z</published>
    <updated>2022-08-01T04:58:42.278Z</updated>
    
    <content type="html"><![CDATA[<p>在主从架构的redis集群中，为了保证主从服务器数据的一致性，redis通过复制和广播，尽力保证数据的一致性。本节会介绍reids复制的具体实现。</p><span id="more"></span><p>Redis可以通过如下命令复制一个服务器，或者说成为另一个服务器的从服务器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SLAVEOF &lt;ip&gt; &lt;port&gt;</span><br></pre></td></tr></table></figure><h2 id="旧版复制的实现"><a class="markdownIt-Anchor" href="#旧版复制的实现"></a> 旧版复制的实现</h2><p>Redis的复制功能包括同步和广播两个操作：</p><blockquote><ul><li><p>redis从服务器将数据更新到和主服务器一致的状态</p></li><li><p>主服务器的数据库发生变更的时候，会广播数据库的变化，使从服务器的数据库保持一致</p></li></ul></blockquote><h3 id="同步"><a class="markdownIt-Anchor" href="#同步"></a> 同步</h3><p>当服务器发送<code>SLAVEOF</code>命令成为另一个服务器的从服务器的时候，会先执行同步操作，使数据一致。执行同步操作需要从服务器发送<code>SYNC</code>命令给主服务器：</p><blockquote><ol><li>从服务器向主服务器发送<code>SYNC</code>命令</li><li>主服务器收到<code>SYNC</code>命令，先执行<code>BGSAVE</code>命令生成一个RDB文件，并使用一个缓冲区记录此时开始执行的所有命令</li><li>主服务器执行完<code>BGSAVE</code>命令生成了一个新的RDB文件，发送给从服务器，从服务器载入文件，使数据库更新至主服务器开始实行<code>BGSAVE</code>命令时的状态</li><li>主服务器将缓冲区中的内容发送给从服务器，从服务器执行这些命令，使数据库更新到主服务器的当前状态</li></ol></blockquote><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1qwbxlx27j20qw09y750.jpg" alt="image-20220429210758185" style="zoom:45%;"><h3 id="命令广播"><a class="markdownIt-Anchor" href="#命令广播"></a> 命令广播</h3><p>在执行完同步操作后，主从服务器的数据库达到了一致的状态。这时，如果有新的数据写入，为了让主从数据库保持一致，主服务器会将自己执行的写命令广播给从服务器，从服务器执行收到的命令，使数据库保持一致。</p><h3 id="旧版复制的缺陷"><a class="markdownIt-Anchor" href="#旧版复制的缺陷"></a> 旧版复制的缺陷</h3><p>每次复制都会全量的复制主服务器的数据，而对于断线后的重新复制，大多数情况下是不需要进行全量复制的，只需要复制新增的命令即可。<code>SYNC</code>每次都会进行以下的操作：</p><blockquote><ol><li>主服务器执行<code>BGSAVE</code>生成新的RDB文件，耗费cpu、io和内存资源</li><li>主服务器将新的RDB文件传给从服务器，浪费网络资源</li><li>从服务器载入RDB文件，处于阻塞状态，不能处理客户端传的命令</li></ol></blockquote><h2 id="新版复制的实现"><a class="markdownIt-Anchor" href="#新版复制的实现"></a> 新版复制的实现</h2><p>为了解决旧版每次都会进行全量复制，造成资源浪费的问题。新版复制使用<code>PSYNC</code>替代了<code>SYNC</code>命令，能够进行完整复制个部分复制。</p><p>新版复制添加了主从服务器的复制偏移量和服务器运行ID，以实现部分复制的功能。</p><h3 id="复制偏移量"><a class="markdownIt-Anchor" href="#复制偏移量"></a> 复制偏移量</h3><p>主从服务器都维护了自己的复制偏移量：</p><blockquote><p>主服务器每向从服务器发送N个字节的数据，就会将自己的偏移量加N</p><p>从服务器每收到主服务器发送来的N个字节的数据，就会将自己的偏移量加N</p></blockquote><p>从服务器请求同步的时候，会将自己的偏移量传给主服务器，主服务器只会发送未同步的数据。</p><h3 id="复制积压缓冲区"><a class="markdownIt-Anchor" href="#复制积压缓冲区"></a> 复制积压缓冲区</h3><p>主服务器在将命令广播给所有从服务器时，还会将广播的命令写入到复制积压缓冲区，并且记录每个字节的偏移量。</p><p>当从服务器请求同步的时候，主服务器会根据偏移量判断进行何种同步：</p><blockquote><p>如果从服务器偏移量之后的数据仍然存在复制积压缓冲区，主服务器会进行部分同步</p><p>如果从服务器偏移量之后的数据已经不存在复制积压缓冲区，主服务器会进行全量同步</p></blockquote><p>因此，积压缓冲区的大小要进行合理的配置：</p><blockquote><p>积压缓冲区的默认大小为1MB，当写入的频率很高或断线重连的时间较长，这个大小会变得不合理，导致不能进行部分同步。</p><p>为了安全起见，建议将复制积压缓冲区的大小设置成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2 * 断线重连需要的秒数 * 每秒产生的数据平均长度</span><br></pre></td></tr></table></figure></blockquote><h3 id="服务器id"><a class="markdownIt-Anchor" href="#服务器id"></a> 服务器ID</h3><p>Redis的主从服务器都有自己的ID，redis的主服务器会将自己的ID发送给从服务器保存起来，从服务器断线重连时会将之前连接的主服务器的ID发送给主服务器，主服务器据此判断进行何种复制：</p><blockquote><p>如果收到的服务器ID和自己的ID相同，说明从服务器之前就是复制的自己，尝试进行部分复制</p><p>如果收到的服务器ID和自己的ID不同，进行全量复制</p></blockquote><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1qykdxte3j20zy0rqtbc.jpg" alt="image-20220429222527751" style="zoom:40%;"><h2 id="心跳检测"><a class="markdownIt-Anchor" href="#心跳检测"></a> 心跳检测</h2><p>在广播阶段，从服务器每秒会执行一次以下命令，向服务器发送自己的偏移量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">REPLCONF ACK &lt;replication_offset&gt;</span><br></pre></td></tr></table></figure><h3 id="检测网络连接状态"><a class="markdownIt-Anchor" href="#检测网络连接状态"></a> 检测网络连接状态</h3><p>主从服务器通过发送和接收<code>REPLCONF ACK</code>命令，检查两者之间的网络连接状态，如果超过一秒没有收到从服务器的<code>REPLCONF ACK</code>命令，说明从服务器的连接出现问题了。</p><h3 id="检测从服务器数量"><a class="markdownIt-Anchor" href="#检测从服务器数量"></a> 检测从服务器数量</h3><p>如果我们配置了如下属性，那么从服务器的数量小于3个，或者所有服务器的延迟都大于10秒的时候，主服务器将拒绝执行写命令，集群不可用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write 3   //最少从服务器数量为3</span><br><span class="line">min-slaves-max-lag 10   //最大延迟大于10秒</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;在主从架构的redis集群中，为了保证主从服务器数据的一致性，redis通过复制和广播，尽力保证数据的一致性。本节会介绍reids复制的具体实现。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习7-时钟周期serverCron</title>
    <link href="https://eoccc.gitee.io/2022/03/28/redis%E5%AD%A6%E4%B9%A07-%E6%97%B6%E9%92%9F%E5%91%A8%E6%9C%9FserverCron/"/>
    <id>https://eoccc.gitee.io/2022/03/28/redis%E5%AD%A6%E4%B9%A07-%E6%97%B6%E9%92%9F%E5%91%A8%E6%9C%9FserverCron/</id>
    <published>2022-03-28T04:10:32.000Z</published>
    <updated>2022-08-01T04:58:42.278Z</updated>
    
    <content type="html"><![CDATA[<p>Redis服务器的serverCron方法默认每100ms执行一次，这个方法负责管理redis的资源，保证redis能够良好的运行。本文介绍cerverCron方法的功能。</p><span id="more"></span><h2 id="更新服务器时间缓存"><a class="markdownIt-Anchor" href="#更新服务器时间缓存"></a> 更新服务器时间缓存</h2><p>Redis服务器的不少功能都需要用到时间，每使用一次时间都需要进行一次系统调用，为了减少系统调用的次数，redis缓存了时间。但是由于serverCron每100ms才执行一次，缓存的时间精度不高，只有对时间精度要求不高的功能才会使用缓存的时间，如打印日志、更行服务器LRU时钟、决定是否进行持久化任务、计算服务的上线时间等。而对于对时间精度要求较高的功能，则会直接调用系统的时间，如为键设置过期时间、添加慢查询日志等。</p><h2 id="更新lru时钟"><a class="markdownIt-Anchor" href="#更新lru时钟"></a> 更新LRU时钟</h2><p>Redis服务器的lruclock属性保存了服务器的LRU时钟。redis的每个对象都会有一个lru属性，记录了这个对象最后一次的访问时间。当需要计算键的空转时间时，就会使用服务器的lruclock减去对象的lru。</p><p>lruclock的值可以用过以下命令返回的<code>lru_clock</code>节点查看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO server</span><br></pre></td></tr></table></figure><h2 id="更新服务器每秒执行命令的次数"><a class="markdownIt-Anchor" href="#更新服务器每秒执行命令的次数"></a> 更新服务器每秒执行命令的次数</h2><p>Redis会以100ms一次的频率更新每秒执行命令的次数，计算方式为抽样计算，具体如下：</p><blockquote><ol><li>计算出上次抽样和这次抽样的时间差</li><li>计算出上次抽样和本次抽样已执行的命令数的差值（即这个时间区间执行了多少命令）</li><li>计算出这个时间区间每毫秒执行了多少个命令</li><li>将每秒执行的命令个数乘1000，得到每秒执行的次数，缓存到一个数组中</li><li>当客户端执行<code>INFO</code>命令时，redis会根据数组中记录的值计算出平均每秒执行的命令个数</li></ol></blockquote><h2 id="更新服务器内存峰值记录"><a class="markdownIt-Anchor" href="#更新服务器内存峰值记录"></a> 更新服务器内存峰值记录</h2><p>Redis的<code>stat_peak_memory</code>属性记录了服务器使用内存的峰值。serverCron每次执行都会查看当前服务器使用的内存数量，如果大于当前的<code>stat_peak_memory</code>，就会更新其值。</p><p>通过一下命令的<code>used_memory_peak</code>和<code>used_memory_peak_human</code>可以查看内存使用的峰值：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO memory</span><br></pre></td></tr></table></figure><h2 id="处理sigterm信号"><a class="markdownIt-Anchor" href="#处理sigterm信号"></a> 处理SIGTERM信号</h2><p>Redis收到SIGTERM信号时，不会立即执行，而是通过<code>sigtermHandler</code>信号处理器，打开服务器的 <code>shutdown_asap</code>标识。serverCron每次执行都会检查这个标识，决定是否关闭服务器。如果这个标识打开，服务器会先进行RDB持久化，然后再关闭服务器。</p><h2 id="管理客户端资源"><a class="markdownIt-Anchor" href="#管理客户端资源"></a> 管理客户端资源</h2><p>serverCron每次执行都会对一定数量的客户端进行检查：</p><blockquote><ol><li>如果客户端连接已经超时，关闭客户端</li><li>如果客户端上一次执行命令之后，客户端输入缓冲区已经超过一定长度，会释放当前输入缓冲区，并创建一个新的</li></ol></blockquote><h2 id="管理数据库资源"><a class="markdownIt-Anchor" href="#管理数据库资源"></a> 管理数据库资源</h2><p>serverCron每次执行都会数据库中的键进行抽样检查，删除过期的键，并在需要的时候对字典进行缩容。</p><p>具体见<a href="https://eoccc.gitee.io/blog/2022/03/24/redis%E5%AD%A6%E4%B9%A03-%E8%BF%87%E6%9C%9F%E9%94%AE%E6%B8%85%E9%99%A4%E7%AD%96%E7%95%A5/">过期键的清除策略</a></p><h2 id="执行被延迟的bgrewriteaof"><a class="markdownIt-Anchor" href="#执行被延迟的bgrewriteaof"></a> 执行被延迟的BGREWRITEAOF</h2><p>Redis在执行<code>BGSAVE</code>命令期间，如果收到<code>BGREWRITEAOF</code>的请求，会等到<code>BGSAVE</code>结束后再执行，并把等待标识<code>aof_rewrite_scheduled</code>置为1。</p><p>serverCron每次执行都会检查<code>BGSAVE</code>和<code>BGREWRITEAOF</code>有没有在执行，如果两个命令都没在执行，并且<code>aof_rewrite_scheduled</code>为1，就会执行<code>BGREWRITEAOF</code>命令。</p><h2 id="检查持久化操作状态"><a class="markdownIt-Anchor" href="#检查持久化操作状态"></a> 检查持久化操作状态</h2><p>Redis的<code>rdb_child_pid</code>和<code>aof_child_pid</code>两个属性记录了执行<code>BGSAVE</code> 和<code>BGREWRITEAOF</code>命令的子进程的pid。serverCron每次执行都会检查这两个属性，只要有一个值不为-1，就会检查有没有收到子进程的信号：</p><blockquote><ol><li>如果收到信号，说明RDB或AOF文件已经生成成功，redis会使用心的文件替换旧的文件</li><li>如果没有收到信号，说明持久化未完成，不做任何操作</li></ol></blockquote><p>如果两个值都为-1，则说明没有在执行任何持久化操作，redis会进行以下检查：</p><blockquote><ol><li>检查是否有被延迟的<code>BGREWRITEAOF</code>命令，有的话执行命令</li><li>检查数据库是否达到持久化条件，满足条件会执行<code>BGSAVE</code>命令进行RDB持久化</li><li>检查是否满足AOF重写条件，满足会执行<code>BGREWRITEAOF</code>命令重写AOF文件</li></ol></blockquote><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1qhfk4p4zj20wq0gumyq.jpg" alt="image-20220429123233767" style="zoom:40%;"><h2 id="将aof缓冲区的内容写入到文件"><a class="markdownIt-Anchor" href="#将aof缓冲区的内容写入到文件"></a> 将AOF缓冲区的内容写入到文件</h2><p>如果服务器开启了AOF持久化功能，redis每次执行serverCron会检查AOF缓冲区是否有内容，如果有，会持久化到AOF文件。</p><h2 id="关闭异步客户端"><a class="markdownIt-Anchor" href="#关闭异步客户端"></a> 关闭异步客户端</h2><p>关闭那些使用资源超限的客户端。</p><h2 id="cronloops计数器递增"><a class="markdownIt-Anchor" href="#cronloops计数器递增"></a> cronloops计数器递增</h2><p>执行完serverCron方法后，会对<code>cronloops</code>属性加1，记录执行serverCron方法的次数。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Redis服务器的serverCron方法默认每100ms执行一次，这个方法负责管理redis的资源，保证redis能够良好的运行。本文介绍cerverCron方法的功能。&lt;/p&gt;</summary>
    
    
    
    
    <category term="中间件" scheme="https://eoccc.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="redis" scheme="https://eoccc.gitee.io/tags/redis/"/>
    
  </entry>
  
</feed>
